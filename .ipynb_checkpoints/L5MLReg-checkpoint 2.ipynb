{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc4cdb9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <span style=\"color:brown\">The multiple linear regression model</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68af555-0e22-43f6-a50c-d9912e844a63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:brown\">Contents</span>\n",
    "\n",
    "In this chapter we illustrate the procedures and properties associated with conducting a multiple linear regression analysis from a sample of observations from several variables. *Multiple* refers to the fact that we will be studying the relationship between more than two variable:, one dependent variable and several (more than one) independent variables.\n",
    "\n",
    "We will describe the multiple linear regression model and its matrix representation, as well as the procedures to estimate the parameters of this model based on that matrix representation. We will also introduce different inference procedures that may be of interest for the parameters of the model or for forecasts obtained from this model. To finish, we will comment on some simple diagnostics that we may conduct to determine if our data satisfies the assumptions for the linear regression model.\n",
    "\n",
    "In the lesson we will cover the following topics:\n",
    "\n",
    "- Model representation\n",
    "  - The matrix representation of the multiple linear regression model\n",
    "- Least Square Estimators (LSE): formulas for the multiple linear regression model\n",
    "- Statistical inference on the linear regression model:\n",
    "  - Estimators and distributions\n",
    "  - Prediction for a new observation (individual value or mean value)\n",
    "- ANOVA tables for the multiple linear regression model and its interpretation\n",
    "- Diagnostics for the linear regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93fc2f-3168-4b5c-9fc6-8a45de609850",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:brown\">Introduction</span>\n",
    "\n",
    "---\n",
    "\n",
    "### <span style=color:brown;>Goals (i)</span>\n",
    "\n",
    "In this lesson we continue with the presentation of procedures and results for the study of linear relationships between random variables. In the preceding lesson we concentrated in the case when we had just one explanatory variable, but in practice we usually have several variables that may contribute to explain the values os a given dependent variable, and we would like to integrate the information from all these variables to obtain the best possible understanding of the dependent variable of interest.\n",
    "\n",
    "In this lesson we consider a situation in which we wish to estimate and to make use of a linear regression model that includes information from more than one independent variable. We will follow a similar scheme as we did in Lesson 4, while adapting the corresponding results to this case.\n",
    "\n",
    "Une of the main changes will be the relevance of using a matrix representation for the multiple linear regression model, as it will be a basic foundation for the derivation of general formulas that are applicable for any number of independent variables.\n",
    "\n",
    "To complete the lesson, we will comment briefly on procedures to check the satisfaction of the assumptions for the linear regression model, when we work with real data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580f195-aa48-4ae3-8bb0-80caf05472af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:brown\">Goals (ii)</span>\n",
    "\n",
    "Our goals for this lesson will be:\n",
    "\n",
    "- To understand the motivation to introduce a multiple linear regression model, and the information required to estimate and use such a model\n",
    "- To know how to estimate the parameters for this model, based on its matrix representation\n",
    "- To be able to conduct inference on these parameters, and in particular to test the significance of the individual coefficients of the model\n",
    "- To know how to compute the ANOVA table associated to the model, to measure its explanatory power and to test for its global significance\n",
    "- To conduct some diagnostics on the assumptions for the linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bca7c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## <span style=\"color:brown;\">The multiple linear regression model</span>\n",
    "\n",
    "---\n",
    "\n",
    "A multiple linear regression model is a model that approximates the value of a random variable $Y$, the <span style=\"color:brown;\">*dependent*</span> or <span style=\"color:brown;\">*response*</span> variable, from a linear combination of values of another set of $k \\geq 2$ variables $X_1, X_2, \\ldots, X_k$, the <span style=\"color:brown;\">*independent*</span> or <span style=\"color:brown;\">*explanatory*</span> variables. As in the simple linear regression case, in general this relationship will not be exact: it will include errors due to inaccuracies in the values of the variables, simplifications in the representation of the true relationships between the variables, etc.\n",
    "\n",
    "The multiple linear regression model we will consider has the following mathematical representation:\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_k X_k + U ,\n",
    "$$\n",
    "\n",
    "where $\\beta_0, \\beta_1, \\beta_2 , \\ldots , \\beta_k$ denote the parameters of the model corresponding to the coefficients of the variables, while $U$ denotes the random errors associated with this model. The specification of these errors will include an additional parameter, $\\sigma^2$, the variance of the errors, as we will describe below.\n",
    "\n",
    "As we did in the case of the simple linear regression model, the inference we will conduct for this model will be conducted under the assumption that the values of the independent variables are known. Formally, we will derive estimators and their distributions conditional on the values of these independent variables. For example, our estimators for the coefficients of the model will have the form\n",
    "\n",
    "$$\n",
    "\\hat \\beta_i = \\hat \\beta_i | (X_1 = x_1 , \\ldots , X_k = x_k ) .\n",
    "$$\n",
    "\n",
    "To simplify the notation, we will not indicate these conditional expressions explicitly in the rest of this lesson.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646867c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown;\">Procedure for the multiple regression model and assumptions</span>\n",
    "\n",
    "The treatment of this model starts with the analysis of the information contained in a collection of values for the variables corresponding to a s.r.s. of paired values $\\{ (x_{1i} , x_{2i}, \\ldots , x_{ki} , y_i )\\}_{i=1}^n$. As we did in lesson 4 and based on this information, we usually proceed by:\n",
    "\n",
    "- <span style=\"color:brown;\">Estimating</span> the parameters: determining the best values for the parameters $\\beta_j$ and for $\\sigma^2$ from the data.\n",
    "- Conducting <span style=\"color:brown;\">inference</span> on the parameters and on results obtained from the application of the model: interpreting the values of these estimates and of forecasts obtainef from the model with respect to the population.\n",
    "- Obtaining some measures for the explanatory power of the model, as well as for its significance, from values related to an ANOVA table.\n",
    "\n",
    "These steps, and in particular the last two, will be conducted under certain assumptions on the data and the population of interest. These assumptions will be the same ones we introduced for the simple linear regression model:\n",
    "\n",
    "1. There exists a linear relationship between the variables $X_j$ and $Y$, as opposed to these variables being related through some nonlinear relationship.\n",
    "2. The errors in the model follow a normal distribution $U \\sim N(0,\\sigma^2)$ where $\\sigma^2$, the variance of the errors, is some unknown value, independent of the values of $(X_1,\\ldots , X_k)$.\n",
    "3. The errors in the model corresponding to different values of the variables $\\{X_j\\}$ are independent, that is, $U \\, |\\, (x_1, \\ldots , x_k )$ is independent of $U \\, | \\, (x'_1, \\ldots , x'_k )$ for any pairs of values $(x_1, \\ldots , x_k ) \\not= (x'_1, \\ldots , x'_k )$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0916b559-74b5-46c8-bafb-787453d33d9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:blue;\">Examples based on external data sources</span>\n",
    "\n",
    "---\n",
    "\n",
    "To illustrate the concepts we have introduced, and to motivate possible choices of good estimators, we will consider specific examples, mostly based on real data, which we will process using <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span>.\n",
    "\n",
    "### <span style=\"color:blue;\">Preparing R and the data</span>\n",
    "\n",
    "We start by preparing <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> to read and manipulate the data mentioned above. In the following <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> <span style=\"color:brown\">code cell</span> we:\n",
    "\n",
    "1. Load the <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> libraries we are going to need for our examples.\n",
    "2. Define a function, <span style=\"color:blue;font-family:monospace;font-size:90%;\">table_prnt</span>, specifying the format for the tables that will present the numerical results in this lesson.\n",
    "3. Introduce information to work with the available data sets.\n",
    "\n",
    "The <span style=\"color:brown;\">available data sets</span> and their identifying codes are:\n",
    "\n",
    "1. Hourly prices for the Iberian electricity market\n",
    "2. Grades for a Statistics subject in UC3M\n",
    "3. Share prices for a company (Iberdrola) from the IBEX index\n",
    "4. Simulated data from a N(80,30) distribution (col 1), an Exp(lambda=1/30) distribution (col 2) and a Binom(20,0.4) distribution (col 3)\n",
    "5. Data from the Sustainable Develpment Report 2021, with the scores by country for goals 1 and 2\n",
    "\n",
    "In order to add another data set to this collection, you should include information for each of the following variables: the .csv file containing the data and a text with a short description for the data.\n",
    "\n",
    "It is also important to ensure that the <span style=\"color:brown;\">working directory</span> has been <span style=\"color:brown;\">selected correctly,</span> as the directory that includes all the data sets that could be used in this lesson.\n",
    "\n",
    "To execute the commands in the cell, select the cell by clicking on it, and then <span style=\"color:blue;\">press the **RUN** button</span> in the menu bar, or press <span style=\"color:blue;\">Shift-Enter.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302f60d-c950-4769-b812-9fe501862757",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#options(jupyter.plot_mimetypes = c(\"text/plain\",\"image/png\"))\n",
    "\n",
    "# Load libraries with R functions\n",
    "\n",
    "suppressMessages(library(tidyverse))\n",
    "suppressMessages(library(huxtable))\n",
    "library(knitr)\n",
    "suppressMessages(library(kableExtra))\n",
    "library(IRdisplay)\n",
    "suppressMessages(library(sjPlot))\n",
    "suppressMessages(library(gridExtra))\n",
    "library(grid)\n",
    "suppressMessages(library(qqplotr))\n",
    "suppressMessages(library(GGally))\n",
    "suppressMessages(library(car))\n",
    "\n",
    "# Define a function to format and print the results of interest\n",
    "\n",
    "table_prnt <- function(p.df,p.capt) {\n",
    "    # A function to control the presentation of tables with numerical results\n",
    "    p.df %>% kable(\"html\",caption=paste0('<em>',p.capt,'</em>'),align='r') %>%\n",
    "    kable_styling(full_width = F, position = \"left\") %>% as.character() %>% display_html()\n",
    "    }\n",
    "\n",
    "# Define the dataset of interest\n",
    "\n",
    "## Datasets that are available for this lesson\n",
    "\n",
    "v.pref = data.frame(file = c(\"Dat_PreciosOMIE.csv\",     # Name of the .csv data file\n",
    "                            \"Dat_Calificaciones.csv\",\n",
    "                            \"Dat_PreciosIBE_MC.csv\",\n",
    "                            \"Dat_SimulatedData.csv\",\n",
    "                            \"Dat_SDR21.csv\"))\n",
    "v.pref$title = c(\"Electricity prices\",         # Short title for the data\n",
    "                \"Grades\",\n",
    "                \"Share returns\",\n",
    "                \"Simulated data\",\n",
    "                \"SDG 2021 Scores\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b1262c-1264-4b5a-acf8-471a86c00467",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:blue;\">Selecting and dislaying the data set and the variable of interest</span>\n",
    "\n",
    "We select one of these data sets and two variables of interest in the following cell.\n",
    "\n",
    "1. We assign the corresponding number to the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">sel.data</span>, at the start of the following code cell.\n",
    "2. We read the file and include the data in a <span style=\"color:brown;\">data frame</span> with the name <span style=\"color:blue;font-family:monospace;font-size:90%;\">Data.fr</span>.\n",
    "3. We assign the numbers corresponding to the order of the different variables of interest for our linear model in the data set, to the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">sel.col</span>.\n",
    "4. The last column of <span style=\"color:blue;font-family:monospace;font-size:90%;\">sel.col</span> will correspond to the <span style=\"color:brown;\">dependent variable</span> in the linear regression model, and all the other columns will be associated with the <span style=\"color:brown;\">independent variables.</span>\n",
    "\n",
    "Finally, we print the names of the selected data set and variables, to check that these values are the correct ones. Then we display a part of the values from the <span style=\"color:blue;font-family:monospace;font-size:90%;\">.csv</span> file, keeping the same structure of the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f0e63-6408-4ce9-88af-f2b992af1a26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the data set of interest\n",
    "\n",
    "## Indicate the data set and variable to select\n",
    "## These values can be modified\n",
    "\n",
    "sel.data = 2\n",
    "sel.col = c(1,2,3)\n",
    "\n",
    "## Read the data\n",
    "\n",
    "s.pref = v.pref[sel.data,]\n",
    "Data.fr = read.csv2(s.pref$file)\n",
    "\n",
    "data.sel = as.data.frame(Data.fr[,sel.col])\n",
    "n.obs = nrow(data.sel)\n",
    "n.var = ncol(data.sel)\n",
    "n.ind.var = n.var - 1    # Number of independent variables k\n",
    "c.names = colnames(Data.fr)[sel.col]\n",
    "\n",
    "vr.1 = vr.2 = NULL\n",
    "for (i.x in 1:n.var) {\n",
    "    vr.1 = c(vr.1,rep(c.names[i.x],n.obs))\n",
    "    vr.2 = c(vr.2,c(data.sel[,i.x]))\n",
    "}\n",
    "val.melt = data.frame(variable = vr.1, value = vr.2)\n",
    "\n",
    "## Summary of the selected data\n",
    "\n",
    "descr.df = as.data.frame(c(s.pref$title,c.names))\n",
    "colnames(descr.df) <- c(\"Selection\")\n",
    "nm.0 = c(\"Data set\",\"Independent variables\")\n",
    "for (i.x in 2:n.ind.var) nm.0 = c(nm.0,\"\")\n",
    "rownames(descr.df) <- c(nm.0,\"Dependent variable\")\n",
    "\n",
    "Data.hux.0 <-\n",
    "  hux(descr.df) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "table_prnt(Data.hux.0[-1,],\"\")\n",
    "\n",
    "# Print a part of the data we have selected\n",
    "\n",
    "max.row.show = 8       # Max number of individual values to show\n",
    "max.col.show = 8       # Max number of variables to show\n",
    "\n",
    "n.row.show = min(nrow(Data.fr),max.row.show)\n",
    "n.col.show = min(ncol(Data.fr),max.col.show)\n",
    "\n",
    "Data.hux.1 <-\n",
    "  hux(Data.fr[1:n.row.show,1:n.col.show]) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "rownames(Data.hux.1) <- c(0:n.row.show)\n",
    "table_prnt(Data.hux.1[-1,],s.pref$title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d034d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Scatterplot matrix</span>\n",
    "\n",
    "Before conducting our treatment of the multiple linear regression model, we will carry out a simple exploratory analysis of our data. \n",
    "\n",
    "We will represent scatterplots for the variables, to obtain some insights on any possible linear relationship between these variables. As we have more than two variables, instead of generating a single scatterplot we will generate a matrix of scatterplots corresponding to all the different pairs of variables we have selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d325d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Drawing a scatterplot matrix\n",
    "\n",
    "#pairs(data.sel,lower.panel = NULL)\n",
    "\n",
    "ggpairs(data.sel,title=\"Scatterplots for variables\") +\n",
    "    theme(plot.title = element_text(size = 18, color = \"blue\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d724f77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## <span style=\"color:brown;\">Estimating the multiple linear regression model</span>\n",
    "\n",
    "---\n",
    "\n",
    "Following the procedure we used for the simple linear regression model, we will again apply the least squares method to estimate the values of the model parameters $\\beta_j$.\n",
    "\n",
    "As the number of independent variables in our model can be arbitrarily large ($k \\geq 2$), it is impractical to try to find specific formulas, which would depend on each of the parameter estimates and the value of $k$.\n",
    "\n",
    "Alternatively, the formulas of the least squares estimates for the multiple linear regression model are usually derived from a generic matrix representation of the linear regression model, which is valid for an arbitrary number of independent variables. The notation for this representation of the model makes use of a matrix $X$ and vectors $\\beta$, $Y$ and $U$, defined as\n",
    "\n",
    "$$\n",
    "X = \\left( \\begin{array}{ccccc} 1 & x_{11} & x_{21} & \\cdots & x_{k1} \\\\ 1 & x_{12} & x_{22} & \\cdots & x_{k2} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{1n} & x_{2n} & \\cdots & x_{kn} \\end{array} \\right) , \\qquad\n",
    "Y = \\left( \\begin{array}{c} Y_1 \\\\ Y_2 \\\\ \\vdots \\\\ Y_n \\end{array} \\right) , \\qquad \\beta = \\left( \\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_k \\end{array} \\right) , \\qquad U = \\left( \\begin{array}{c} U_1 \\\\ U_2 \\\\ \\vdots \\\\ U_n \\end{array} \\right) .\n",
    "$$\n",
    "\n",
    "The multiple linear regression model can be written in terms of these matrices and vectors as\n",
    "\n",
    "$$\n",
    "Y = X \\beta + U\n",
    "$$\n",
    "\n",
    "Using this representation, we can obtain the least squares estimators for the parameters $\\hat \\beta_j$ from\n",
    "\n",
    "$$\n",
    "\\min_{\\hat \\beta_j} \\| Y - X \\hat \\beta \\|^2 = \\min_{\\hat \\beta_j} ( Y - X \\hat \\beta )^T ( Y - X \\hat \\beta ) = \\min_{\\hat \\beta_j} Y^T Y - 2 Y^T X \\hat \\beta + \\hat \\beta^T X^T X \\hat \\beta\n",
    "$$\n",
    "\n",
    "If we define the vector of least squares estimators for the parameters, $\\hat \\beta_j$, as\n",
    "\n",
    "$$\n",
    "\\hat \\beta = \\left( \\begin{array}{c} \\hat \\beta_1 \\\\ \\hat \\beta_2 \\\\ \\vdots \\\\ \\hat \\beta_k \\end{array} \\right) ,\n",
    "$$\n",
    "\n",
    "the solution for this least squares optimization problem is given by the vector of estimators\n",
    "\n",
    "$$\n",
    "\\hat \\beta = (X^T X)^{-1} X^T Y\n",
    "$$\n",
    "\n",
    "which are defined as linear combinations of the random variables $Y$.\n",
    "\n",
    "We also define the vector of residuals for this model, $E$, as\n",
    "\n",
    "$$\n",
    "E = Y - \\hat Y = Y - X \\hat \\beta = Y - X (X^T X)^{-1} X^T Y = (I - X (X^T X)^{-1} X^T ) Y\n",
    "$$\n",
    "\n",
    "The matrices $X^T X$ and $X^T y$ corresponding to our example are given in the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aab3b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Values of relevant vectors and matrices\n",
    "\n",
    "X.mat = as.matrix(cbind(Intercept = matrix(1,n.obs,1),data.sel[,1:n.ind.var]))\n",
    "Y.mat = matrix(c(data.sel[,n.var]),n.obs,1)\n",
    "\n",
    "prod.mat = round(t(X.mat) %*% X.mat,3)\n",
    "rhs.mat = round(t(X.mat) %*% Y.mat,3)\n",
    "\n",
    "table_prnt(prod.mat,\"Matrix X^T X\")\n",
    "table_prnt(rhs.mat,\"rhs vector\")\n",
    "\n",
    "# Estimates for the parameters of the model\n",
    "\n",
    "beta.est = solve(t(X.mat) %*% X.mat,t(X.mat) %*% Y.mat)\n",
    "\n",
    "param.val = as.data.frame(rbind(c(beta.est)))\n",
    "param.val = round(param.val,3)\n",
    "rownames(param.val) = c(\"Beta estimate\")\n",
    "colnames(param.val) = c(\"Beta0\",c.names[1:n.ind.var])\n",
    "\n",
    "table_prnt(param.val,\"Least squares estimates\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a697f50f-341e-4dc4-af91-460b044fb887",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*A manufacturing company is studying the effect that both the average monthly prices of electricity ($x_1$), and the average subsidy that the administrations may offer for the purchase of one of these cars ($x_2$), may have in the sales of several electric car models ($y$). It has collected information from a total of 12 different (but similar) markets during a period of time, obtaining the following data:*\n",
    "\n",
    "| Electricity price | Subsidies | Sales |\n",
    "| ---: | ---: | ---: |\n",
    "| 177.68 | 1200 | 116 |\n",
    "| 88.08 | 2000 | 350 |\n",
    "| 235.22 | 3200 | 224 |\n",
    "| 107.92 | 3200 | 352 |\n",
    "| 190.6 | 2000 | 85 |\n",
    "| 74.32 | 1500 | 325 |\n",
    "| 132.11 | 3500 | 268 |\n",
    "| 137.41 | 2500 | 314 |\n",
    "| 104.63 | 1000 | 237 |\n",
    "| 132.99 | 3500 | 241 |\n",
    "| 165.36 | 2700 | 203 |\n",
    "| 141.3 | 800 | 98 |\n",
    "\n",
    "*Estimate the parameters of the regression line explaining the sales as a funcion of the electricity price and the subsidies.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5834f2e-9d0f-4571-be3e-280c93d3d737",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "We define our variables $X_1 =$ \"Average monthly electricity price\", $X_2 =$ \"Average subsidy\" and $Y =$ \"Monthly sales of vehicles\".\n",
    "\n",
    "To estimate this linear regression model we would start by defining the matrices and vectors of interest. We have that\n",
    "\n",
    "$$\n",
    "   X = \\left( \\begin{array}{ccc} 1 & 177.68 & 1200 \\\\ 1 & 88.08 & 2000 \\\\ 1 & 235.22 & 3200 \\\\\n",
    "   1 & 107.92 & 3200 \\\\ 1 & 190.6 & 2000 \\\\ 1 & 74.32 & 1500 \\\\ 1 & 132.11 & 3500 \\\\\n",
    "   1 & 137.41 & 2500 \\\\ 1 & 104.63 & 1000 \\\\ 1 & 132.99 & 3500 \\\\ 1 & 165.36 & 2700 \\\\\n",
    "   1 & 141.3 & 800 \\end{array} \\right) , \\qquad Y = \\left( \\begin{array}{c} 116 \\\\ 350 \\\\ 224 \\\\\n",
    "   352 \\\\ 85 \\\\ 325 \\\\ 268 \\\\ 314 \\\\ 237 \\\\ 241 \\\\ 203 \\\\ 98 \\end{array} \\right)\n",
    "$$\n",
    "\n",
    "and we obtain the matrices,\n",
    "\n",
    "$$\n",
    "   X^T X = \\left( \\begin{array}{ccc} 12 & 1687.62 & 27100 \\\\ 1687.62 & 260433.22 & 3915621 \\\\ 27100 & 3915621 & 71850000 \\end{array} \\right) , \\qquad X^T Y = \\left( \\begin{array}{c} 2813.0 \\\\ 365286.6 \\\\ 6769900.0 \\end{array} \\right)\n",
    "$$\n",
    "\n",
    "We can apply the least squares estimators formula to obtain:\n",
    "\n",
    "$$\n",
    "\\hat \\beta = (X^T X)^{-1} X^T Y = \\left( \\begin{array}{ccc} 12 & 1687.62 & 27100 \\\\ 1687.62 & 260433.22 & 3915621 \\\\ 27100 & 3915621 & 71850000 \\end{array} \\right)^{-1} \\left( \\begin{array}{c} 2813.0 \\\\ 365286.6 \\\\ 6769900.0 \\end{array} \\right) = \\left( \\begin{array}{c} 330.679 \\\\ -1.559 \\\\ 0.0545 \\end{array} \\right)\n",
    "$$\n",
    "\n",
    "Thus, the estimated regression line is given by:\n",
    "\n",
    "$$\n",
    "   \\hat y_i = 330.679 - 1.559 x_{1i} + 0.0545 x_{2i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7356e2-0272-4604-8e2b-0b5bf56380b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:brown;\">Estimators for the parameters</span>\n",
    "\n",
    "As we indicated before, the values of the <span style=\"color:brown;\">least squares estimates</span> for the parameters of the model are obtained from the following formula,\n",
    "\n",
    "$$\n",
    "\\hat \\beta = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "We will use as our estimator for the variance of the errors the <span style=\"color:brown;\">residual variance</span> $s_R^2$. Its value will be defined from the value of the variance of the residuals, corrected with the number of degrees of freedom corresponding to our model, $n - k - 1$. This number of degrees of freedom is introduced as the denominator of the corresponding formula.\n",
    "\n",
    "We define the residual variance for the multiple linear regression model as\n",
    "\n",
    "$$\n",
    "S_R^2 = \\frac{1}{n-k-1} \\sum_{i=1}^n E_i^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63078918",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Parameter estimates and standard errors\n",
    "\n",
    "hat.Y.m = beta.est[1]\n",
    "for (ix in 1:n.ind.var) hat.Y.m = hat.Y.m + beta.est[ix+1]*data.sel[,ix]\n",
    "data.sel$Yhat = hat.Y.m\n",
    "data.sel$res = data.sel[,n.var] - data.sel$Yhat\n",
    "sm.e2t = sum(data.sel$res^2)\n",
    "\n",
    "s2.y = var(Y.mat)\n",
    "\n",
    "df.m = n.ind.var\n",
    "df.r = n.obs - 1 - df.m\n",
    "\n",
    "sR.2r = sm.e2t/df.r\n",
    "se.est = sqrt(sR.2r*diag(solve(t(X.mat) %*% X.mat)))\n",
    "\n",
    "param.val = as.data.frame(rbind(c(beta.est),c(se.est)))\n",
    "param.val = round(param.val,3)\n",
    "rownames(param.val) = c(\"Estimate\",\"Std error\")\n",
    "colnames(param.val) = c(\"Beta0\",\"Beta1\",\"Beta2\")\n",
    "\n",
    "table_prnt(param.val,\"Least squares estimates\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0a76f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Regression model estimates using R functions</span>\n",
    "\n",
    "R has several functions to obtain and manipulate the estimates and results from the fitting of a linear regression model, both simple and multiple.\n",
    "\n",
    "As we mentioned in the case of the simple linear regression model, the basic function to compute these values is <span style=\"color:blue;font-family:monospace;font-size:90%;\">lm</span> (for Linear Model), which as we already indicated obtains estimates for the coefficients, their standard errors, the p-values of the significance tests, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ef0ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Regression results obtained using R functions\n",
    "\n",
    "mod.descr = paste0(c.names[n.var],\" ~ \")\n",
    "for (i.x in 1:n.ind.var) {\n",
    "    mod.descr = paste0(mod.descr,c.names[i.x])\n",
    "    if (i.x < n.ind.var) mod.descr = paste0(mod.descr,\" + \")\n",
    "}\n",
    "\n",
    "lr.xy.m = lm(mod.descr, data = data.sel)\n",
    "lr.sum <- summary(lr.xy.m)\n",
    "\n",
    "table_prnt(lr.sum[4],\"Parameter estimates\")\n",
    "\n",
    "lr.sum.2 <- round(as.data.frame(lr.sum[8:9]),3)\n",
    "colnames(lr.sum.2) <- c(\"R squared\",\"Adj R sq\")\n",
    "\n",
    "lr.sum.3 <- round(as.data.frame(lr.sum[10]),3)\n",
    "colnames(lr.sum.3) <- c(\"F statistic\")\n",
    "rownames(lr.sum.3) <- c(\"Value\",\"df num\",\"df den\")\n",
    "\n",
    "table_prnt(list(lr.sum.2,lr.sum.3),\"Coeff of determination and global significance\")\n",
    "\n",
    "lr.sum.x = huxreg(\"Values\" = lr.xy.m, number_format = \"%10.4f\")\n",
    "lr.sum.x = lr.sum.x %>% set_caption(\"Parameter estimates using huxreg\")\n",
    "colnames(lr.sum.x) <- c(\"Parameters\",\"Values\")\n",
    "v.1 = 7+2*df.m\n",
    "v.2 = v.1+1\n",
    "rownames(lr.sum.x) = c(0:(7+2*df.m))\n",
    "lr.sum.x <- lr.sum.x[c(-1,-v.2),]\n",
    "\n",
    "print(lr.sum.x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda36a5-190d-4349-80e0-cd6489fe7410",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:brown;\">Inference on the parameters</span>\n",
    "\n",
    "---\n",
    "\n",
    "In order to carry out inference on the parameters of the multiple linear regression model, we need to know the distributions of the least-squares estimators for these parameters.\n",
    "\n",
    "These distributions for the estimators of the parameters $\\beta_j$ are given by\n",
    "\n",
    "$$\n",
    "T_{\\beta_j} = \\frac{\\hat \\beta_j - \\beta_j}{\\mbox{se} (\\hat \\beta_j)} \\sim t_{n-k-1}\n",
    "$$\n",
    "\n",
    "and their standard errors are given by\n",
    "\n",
    "$$\n",
    "\\mbox{se}(\\hat \\beta_j) = \\sqrt{s_R^2 ((X^T X)^{-1} )_{jj} }\n",
    "$$\n",
    "\n",
    "where $((X^T X)^{-1} )_{jj}$ denotes the $j$-th diagonal element of the matrix $(X^T X)^{-1}$.\n",
    "\n",
    "The distribution of the estimator for the variance of the errors is\n",
    "\n",
    "$$\n",
    "T = \\frac{(n-k-1) S_R^2}{\\sigma^2} \\sim \\chi^2_{n-k-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87445666",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown;\">Confidence intervals and local significance tests for individual parameters</span>\n",
    "\n",
    "Based on the test statistics we have introduced before, we can construct confidence intervals and conduct significance tests for the parameters of the multiple linear regression model.\n",
    "\n",
    "The confidence intervals for the parameters of the model have the form\n",
    "\n",
    "$$\n",
    "\\text{CI}_{1-\\alpha} (\\beta_j) = \\left[ \\hat \\beta_j - t_{n-k-1;\\alpha/2} \\text{se} (\\hat \\beta_j ) \\ ; \\  \\hat \\beta_j + t_{n-k-1;\\alpha/2} \\text{se} (\\hat \\beta_j ) \\right]\n",
    "$$\n",
    "\n",
    "The <span style=\"color:brown;\">local significance tests</span> for each one of the parameters in the multiple linear regression model $\\beta_j$ are based on hypothesis tests defined as\n",
    "\n",
    "$$\n",
    "\\left. \\begin{array}{rl}\n",
    "H_0 : & \\beta_j = 0 \\\\\n",
    "H_1 : & \\beta_j \\not= 0\n",
    "\\end{array} \\right\\}\n",
    "$$\n",
    "\n",
    "These tests allow us to determine if a given independent variable $X_j$ has a significant linear effect on the values of the dependent variable $Y$, given the values of the remaining variables. Thus, this is a <span style=\"color:brown;\">local significance</span> test, as it only considers the significance of one variable at a time. It is different from the global significance test we will introduce later on, where the impacts of all independent variables are considered simultaneously.\n",
    "\n",
    "These local significance tests can be conducted based on the p-values for these parameters, computed from their statistics as\n",
    "\n",
    "$$\n",
    "\\mbox{p-value} (\\hat \\beta_j) = 2 \\Pr \\left( T_{n-k-1} > \\left| \\frac{\\hat \\beta_j}{\\mbox{se} (\\hat \\beta_j)} \\right| \\right) \n",
    "$$\n",
    "\n",
    "For the variance of the errors, a confidence interval for a significance level $1-\\alpha$ would be given by\n",
    "\n",
    "$$\n",
    "\\text{CI}_{1-\\alpha} (\\sigma^2) = \\left[ \\frac{(n-k-1) s_R^2}{\\chi^2_{n-k-1;\\alpha/2}} \\ ; \\  \\frac{(n-k-1) s_R^2}{\\chi^2_{n-k-1;1-\\alpha/2}} \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b7e1d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Significance tests for the parameters of the model\n",
    "\n",
    "conf.lvl = 0.95\n",
    "ref.cl = 0.5*(1 + conf.lvl)\n",
    "ref.qt = qt(ref.cl, df.r, lower.tail = TRUE)\n",
    "\n",
    "test.stats = as.matrix(param.val[1,]/param.val[2,])\n",
    "pval.test.stats = 2*pt(abs(test.stats), df.r, lower.tail=FALSE)\n",
    "ll.ci = param.val[1,] - ref.qt*param.val[2,]\n",
    "ul.ci = param.val[1,] + ref.qt*param.val[2,]\n",
    "\n",
    "par.val.1 = t(round(rbind(param.val,test.stats,pval.test.stats,ll.ci,ul.ci),3))\n",
    "colnames(par.val.1) = c(\"Estimate\",\"Std error\",\"Test Stat\",\"p value\",\"Lower CI\",\"Upper CI\")\n",
    "rownames(par.val.1) = c(\"Intercept\",c.names[1:n.ind.var])\n",
    "\n",
    "table_prnt(par.val.1,\"Estimates and p values for betas from formulas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6b030-3af0-4a00-9727-45996aba16a4",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*A manufacturing company is studying the effect that both the average monthly prices of electricity ($x_1$), and the average subsidy that the administrations may offer for the purchase of one of these cars ($x_2$), may have in the sales of several electric car models ($y$). It has collected information from a total of 12 different (but similar) markets during a period of time, obtaining the following data:*\n",
    "\n",
    "| Electricity price | Subsidies | Sales |\n",
    "| ---: | ---: | ---: |\n",
    "| 177.68 | 1200 | 116 |\n",
    "| 88.08 | 2000 | 350 |\n",
    "| 235.22 | 3200 | 224 |\n",
    "| 107.92 | 3200 | 352 |\n",
    "| 190.6 | 2000 | 85 |\n",
    "| 74.32 | 1500 | 325 |\n",
    "| 132.11 | 3500 | 268 |\n",
    "| 137.41 | 2500 | 314 |\n",
    "| 104.63 | 1000 | 237 |\n",
    "| 132.99 | 3500 | 241 |\n",
    "| 165.36 | 2700 | 203 |\n",
    "| 141.3 | 800 | 98 |\n",
    "\n",
    "- *Estimate the variance of the errors for the regression line explaining the sales as a funcion of the electricity price and the subsidies.*\n",
    "\n",
    "- *Compute confidence intervals for the coefficients of the independent variables in this regression line, for a confidence level of 99%.*\n",
    "\n",
    "- *Test if the parameters for the two independent variables are significant, at a significance level of 1%.*\n",
    "\n",
    "*To answer these questions you can use the results in the following table:*\n",
    "\n",
    "| Parameter | Coefficient | Standard error |\n",
    "| :--- | ---: | ---: |\n",
    "Intercept | 330.679 | 62.100 |\n",
    "Electricity price | -1.559 | 0.3818 |\n",
    "Subsidies | 0.05446 | 0.01778 |\n",
    "\n",
    "*as well as*\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{12} e_i^2 = 28961.71\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d0da3-3977-4599-9d32-693d8cf33fa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "From these values we can compute the residuals as\n",
    "\n",
    "$$\n",
    "E = Y - X \\hat \\beta = \\left( \\begin{array}{c} 116 - ( 330.679 - 1.559\\times 177.68 + 0.0545\\times 1200) \\\\ 350 - ( 330.679 - 1.559\\times 88.08 + 0.0545\\times 2000 ) \\\\ \\vdots \\\\ 98 - ( 330.679 - 1.559\\times 141.3 + 0.0545\\times 800 ) \\end{array} \\right) = \\left( \\begin{array}{c} -3.020 \\\\ 47.716 \\\\ 85.761 \\\\ 15.292 \\\\ -57.448 \\\\ 28.495 \\\\ -47.334 \\\\ 61.393 \\\\ 14.983 \\\\ -72.962 \\\\ -16.924 \\\\ -55.953 \\end{array} \\right)\n",
    "$$\n",
    "\n",
    "We can estimate the variance of the errors using the definition of the residual variance, where $k = 2$, to obtain\n",
    "\n",
    "$$\n",
    "s_R^2 = \\frac{\\sum_{i=1}^{12} e_i^2}{n - k - 1} = \\frac{28961.71}{9} = 3217.968\n",
    "$$\n",
    "\n",
    "To obtain the confidence intervals we can use the values given in the table. But if we wished to compute the standard errors we would need to compute\n",
    "\n",
    "$$\n",
    "(X^T X)^{-1} = \\left( \\begin{array}{ccc} 1.1984 & -5.369\\, 10^{-3} & -1.594\\, 10^{-4} \\\\ -5.369\\, 10^{-3} & 4.531\\, 10^{-5} & -4.442\\, 10^{-7} \\\\ -1.594\\, 10^{-4} & -4.442\\, 10^{-7} & 9.826\\, 10^{-8} \\end{array} \\right) , \\qquad s_R^2 (X^T X)^{-1} = \\left( \\begin{array}{ccc} 3856.414 & -17.276 & -0.5130 \\\\ -17.276 & 0.1458 & -0.001430 \\\\ -0.5130 & -0.001430 & 0.0003162 \\end{array} \\right)\n",
    "$$\n",
    "\n",
    "The standard errors are the square root of the values on the diagonal of this last matrix.\n",
    "\n",
    "The requested confidence intervals will be given by\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{CI}_{0.99} (\\beta_1 ) & = & \\left[ \\hat \\beta_1 - t_{n-k-1;\\alpha/2} \\text{se} (\\hat \\beta_1) \\, ; \\, \\hat \\beta_1 + t_{n-k-1;\\alpha/2} \\text{se} (\\hat \\beta_1) \\right] \\\\\n",
    "& = & \\left[ -1.559 - 3.2498 \\times 0.3818 \\, ; \\, -1.559 + 3.2498 \\times 0.3818 \\right] \\\\\n",
    "& = & \\left[ -2.7998 \\, ; \\, -0.3182 \\right] \\\\\n",
    "\\text{CI}_{0.99} (\\beta_2 ) & = & \\left[ \\hat \\beta_2 - t_{n-k-1;\\alpha/2} \\text{se} (\\hat \\beta_2) \\, ; \\, \\hat \\beta_2 + t_{n-k-1;\\alpha/2} \\text{se} (\\hat \\beta_2) \\right] \\\\\n",
    "& = & \\left[ 0.05446 - 3.2498 \\times 0.01778 \\, ; \\, 0.05446 + 3.2498 \\times 0.01778 \\right] \\\\\n",
    "& = & \\left[ -0.003321 \\, ; \\, 0.1122 \\right]\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The significance tests will have the form\n",
    "\n",
    "$$\n",
    "\\left. \\begin{array}{rl}\n",
    "H_0 : & \\beta_j = 0 \\\\\n",
    "H_1 : & \\beta_j \\not= 0\n",
    "\\end{array} \\right\\}\n",
    "$$\n",
    "\n",
    "We can conduct these tests by computing the corresponding p-values for these tests, as\n",
    "   \n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{p-value}_1 & = & \\displaystyle2 \\Pr \\left( T_9 < \\frac{\\hat \\beta_1}{\\text{se}(\\hat \\beta_1)} \\right) \\\\\n",
    "& = & \\displaystyle 2 \\Pr \\left( T_9 < \\frac{-1.559}{0.3818} = -4.0833 \\right) = 0.00274 \\\\\n",
    "\\text{p-value}_2 & = & \\displaystyle2 \\Pr \\left( T_9 > \\frac{\\hat \\beta_2}{\\text{se}(\\hat \\beta_2)} \\right) \\\\\n",
    "& = & \\displaystyle 2 \\Pr \\left( T_9 > \\frac{0.05446}{0.01778} = 3.0630 \\right) = 0.0135\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "   From these values, the first coefficient is significant, but the second one is not, for a significance level of 1%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c489b6-8ce2-48db-b407-b5498ed9f67f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown;\">Mean responses and forecasts</span>\n",
    "\n",
    "As we did in the case of the simple linear regression model, once we have obtained the estimates for the parameters of our multiple linear regression model, we can use them to approximate values of the dependent variable corresponding to a different set of values for the independent variables.\n",
    "\n",
    "We need to introduce the estimators and their distributions, which will allow us to obtain confidence intervals or to conduct hypothesis tests on mean responses and forecasts.\n",
    "\n",
    "Let $x_0 = (1 , x_{10} , \\ldots , x_{k0} )^T$ denote the values of the independent variables of interest to compute our forecast. Our <span style=\"color:brown;\">point estimator</span> is given by:\n",
    "\n",
    "$$\n",
    "Y_0 = \\hat \\beta^T x_0 = \\hat \\beta_0 + \\hat \\beta_1 x_{10} + \\cdots + \\hat \\beta_k x_{k0}\n",
    "$$\n",
    "\n",
    "The statistics for <span style=\"color:brown;\">mean responses and forecasts</span> are defined as:\n",
    "\n",
    "- The <span style=\"color:brown\">mean response</span> estimator satisfies\n",
    "\n",
    "$$\n",
    "T_{mr} = \\frac{\\hat Y_0 - y_0}{\\text{se}_{mr} (y_0)} \\sim t_{n-k-1}\n",
    "$$\n",
    "\n",
    "- While for the <span style=\"color:brown\">forecast</span> estimator we have that\n",
    "\n",
    "$$\n",
    "T_f = \\frac{\\hat Y_0 - y_0}{\\text{se}_f (y_0)} \\sim t_{n-k-1}\n",
    "$$\n",
    "\n",
    "These two estimators are very similar, but they differ in their standard errors, which take the values:\n",
    "  \n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\mbox{se}_{mr} (y_0) & = & s_R \\sqrt{x_0^T (X^T X)^{-1} x_0} \\\\\n",
    "\\mbox{se}_{f} (y_0) & = & s_R \\sqrt{1 + x_0^T (X^T X)^{-1} x_0}\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5440842-de1c-4cb9-97b3-8de27f4ca6a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Mean responses and forecasts\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "x.0 = c(7.5,8.0)\n",
    "\n",
    "conf.lvl = 0.95\n",
    "\n",
    "## Computation of parameter values\n",
    "\n",
    "x.0a = matrix(c(1,x.0),n.ind.var+1,1)\n",
    "\n",
    "q.p = 0.5*(1 + conf.lvl)\n",
    "q.haty0 = qt(q.p,df.r,lower.tail=T)\n",
    "haty0 = beta.est[1]\n",
    "for (ix in 1:n.ind.var) haty0 = haty0 + beta.est[ix+1]*x.0a[ix+1]\n",
    "\n",
    "ref.val = t(x.0a) %*% solve((t(X.mat) %*% X.mat),x.0a)\n",
    "se.haty0.mn = sqrt(sR.2r*ref.val)\n",
    "se.haty0.fc = sqrt(sR.2r*(1 + ref.val))\n",
    "\n",
    "## Printing the estimates\n",
    "\n",
    "val.0 <- round(c(x.0,haty0),3)\n",
    "out.0 <- as.data.frame(matrix(val.0,length(val.0),1))\n",
    "rn.0 = NULL\n",
    "for (ix in 1:n.ind.var) rn.0 = c(rn.0,sprintf(\"Value of x0%3.0f:\",ix))\n",
    "rownames(out.0) = c(rn.0,\"Point estimate for the response:\")\n",
    "colnames(out.0) = c(\"Values\")\n",
    "table_prnt(out.0,\"Point estimate\")\n",
    "\n",
    "val.1 <- c(conf.lvl)\n",
    "out.1 <- as.data.frame(matrix(val.1,1,1))\n",
    "rownames(out.1) = c(\"Selected confidence level:\")\n",
    "colnames(out.1) = c(\"Value\")\n",
    "table_prnt(out.1,\"Confidence interval parameter\")\n",
    "\n",
    "val.2 = c(sprintf('[%8.3f;%8.3f ]',\n",
    "            haty0-q.haty0*se.haty0.mn,haty0+q.haty0*se.haty0.mn),\n",
    "          sprintf('[%8.3f;%8.3f ]',\n",
    "            haty0-q.haty0*se.haty0.fc,haty0+q.haty0*se.haty0.fc))\n",
    "out.2 = as.data.frame(matrix(val.2,2,1))\n",
    "rownames(out.2) = c(\"Confidence interval for mean response:\",\"Confidence interval for forecast:\")\n",
    "colnames(out.2) = c(\"Values\")\n",
    "\n",
    "table_prnt(out.2,\"CIs mean response and forecast\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6141cab4-686b-4be9-ab9f-14bdf48aa688",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*A manufacturing company is studying the effect that both the average monthly prices of electricity ($x_1$), and the average subsidy that the administrations may offer for the purchase of one of these cars ($x_2$), may have in the sales of several electric car models ($y$). It has collected information from a total of 12 different (but similar) markets during a period of time, obtaining the following data:*\n",
    "\n",
    "| Electricity price | Subsidies | Sales |\n",
    "| ---: | ---: | ---: |\n",
    "| 177.68 | 1200 | 116 |\n",
    "| 88.08 | 2000 | 350 |\n",
    "| 235.22 | 3200 | 224 |\n",
    "| 107.92 | 3200 | 352 |\n",
    "| 190.6 | 2000 | 85 |\n",
    "| 74.32 | 1500 | 325 |\n",
    "| 132.11 | 3500 | 268 |\n",
    "| 137.41 | 2500 | 314 |\n",
    "| 104.63 | 1000 | 237 |\n",
    "| 132.99 | 3500 | 241 |\n",
    "| 165.36 | 2700 | 203 |\n",
    "| 141.3 | 800 | 98 |\n",
    "\n",
    "- *Compute a confidence interval at a 95% level for a forecast of the sales in one market in which $x_{01} = 160$ and $x_{02} = 1000$. You can use the result that $x_0^T (X^T X)^{-1} x_0 = 0.2776$.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e1a29-2933-4f24-acfd-20016557eff8",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "- To answer this question we may wish to compute the value of $x_0^T (X^T X)^{-1} x_0$. From the data that has been obtained before,\n",
    "\n",
    "$$\n",
    "x_0^T (X^T X)^{-1} x_0 = \\left( \\begin{array}{ccc} 1 & 160 & 1000 \\end{array} \\right) \\left( \\begin{array}{ccc} 1.1984 & -5.369\\, 10^{-3} & -1.594\\, 10^{-4} \\\\ -5.369\\, 10^{-3} & 4.531\\, 10^{-5} & -4.442\\, 10^{-7} \\\\ -1.594\\, 10^{-4} & -4.442\\, 10^{-7} & 9.826\\, 10^{-8} \\end{array} \\right) \\left( \\begin{array}{c} 1 \\\\ 160 \\\\ 1000 \\end{array} \\right) = 0.2776\n",
    "$$\n",
    "\n",
    "   We also have that the point estimate of interest is given by $\\hat y_0 = \\hat \\beta_0 + \\hat \\beta_1 x_{01} + \\hat \\beta_2 x_{02} = 330.679 - 1.559\\times 160 + 0.0545\\times 1000 = 135.69$.\n",
    "\n",
    "   From these values, the confidence interval will be\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\\begin{array}{rcl}\n",
    "\\text{CI}_{0.95} (y_0 ) & = & \\left[ \\hat y_0 - t_{n-k-1;\\alpha/2} s_R \\sqrt{1 + x_0^T (X^T X)^{-1} x_0} \\, ; \\, \\hat y_0 + t_{n-k-1;\\alpha/2} s_R \\sqrt{1 + x_0^T (X^T X)^{-1} x_0} \\right] \\\\\n",
    "& = & \\left[ 135.69 - 2.262 \\times \\sqrt{3217.968\\times (1 + 0.2776)} \\, ; \\, 135.69 + 2.262 \\times \\sqrt{3217.968\\times (1 + 0.2776)} \\right] \\\\\n",
    "& = & \\left[ -9.348 \\, ; \\, 280.728 \\right]\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612e08a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## <span style=\"color:brown;\">Assessing the quality of the linear regression model</span>\n",
    "\n",
    "---\n",
    "\n",
    "In order to study the quality of our multiple linear regression model, we will follow the same approach as in the simple case. We define its <span style=\"color:brown;\">coefficient of determination $R^2$</span> in terms of the sums of squares associated to the multiple linear regression model.\n",
    "\n",
    "These sums of squares are defined as we did in Lesson 4:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{SST} & = & \\sum_{i=1}^n (y_i - \\bar y)^2 = (n-1) s_y^2 \\\\\n",
    "\\text{SSR} & = & \\sum_{i=1}^n e_i^2 = (n-k-1) s_R^2 \\\\\n",
    "\\text{SSM} & = & \\sum_{i=1}^n (\\hat y_i - \\bar y)^2 = (n-1) s_y^2 - (n-k-1) s_R^2\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where it holds again that $\\text{SST} = \\text{SSR} + \\text{SSM}$.\n",
    "\n",
    "The value of the coefficient of determination is defined by comparing the sums of squares associated to the model with the total sum of squares corresponding to the variability in the dependent variable $Y$. We expect to obtain a large value for this ratio whenever our model provides a good approximation to the observed values of $Y$.\n",
    "\n",
    "The value of the <span style=\"color:brown;\">coefficient of determination</span> is given by\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\mbox{SSR}}{\\mbox{SST}} = 1 - \\frac{\\sum_i e_i^2}{\\sum_i (y_i - \\bar y)^2} = 1 - \\frac{(n-k-1) s_R^2}{(n-1) s_y^2}\n",
    "$$\n",
    "\n",
    "This coefficient of determination has the following properties:\n",
    "\n",
    "- It takes values in $[0,1]$. If its value is close to 1, the regression model provides a nearly perfect fit, while if it is close to zero, the model provides very little information obout the dependent variable.\n",
    "- It represents the proportion of the total variability of the dependent variable that is explained by the regression model and the values of the independent variable. Thus, it offers a measure with a simple interpretation in terms of the explained variability.\n",
    "\n",
    "In the multiple regression case the coefficient of determination is no longer related to a correlation coefficient, as the coefficient of determination is a measure related to the global model, while the correlation coefficients measure effects associated to pairs of variables.\n",
    "\n",
    "A modified version of the coefficient of determination that is useful when comparing the quality of the results corresponding to models with different numbers of parameters (models with more than one independent variable), is given by the <span style=\"color:brown;\">adjusted coefficient of determination,</span> defined as\n",
    "\n",
    "$$\n",
    "\\mbox{adj. } R^2 = 1 - \\frac{s_R^2}{s_y^2}\n",
    "$$\n",
    "\n",
    "The motivation for using this value is that now we compare directly the variability in the original data (for the dependent variable) with the variability in the errors, correcting for the degrees of freedom. This removes the influence of these degrees of freedom in the evaluation of the quality of the model. This is important in practice, as otherwise a model with more parameters would always provide better results than a model with fewer parameters.\n",
    "\n",
    "The following cell computes these values for our sample data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9cbc0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Measuring the quality of the model\n",
    "## Computing the sums of squares\n",
    "\n",
    "SSR = sm.e2t\n",
    "SST = (n.obs-1)*s2.y\n",
    "R.2.m = 1 - SSR/SST\n",
    "R.2.m.adj = 1 - sR.2r/s2.y\n",
    "\n",
    "out.0 <- round(as.data.frame(matrix(c(R.2.m,R.2.m.adj),1,2)),5)\n",
    "colnames(out.0) = c(\"Value\",\"Adj value\")\n",
    "rownames(out.0) = c(\"Coefficient of determination:\")\n",
    "\n",
    "table_prnt(out.0,\"R squared values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b80941-7d35-4d23-88c5-ea593f348e74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown;\">ANOVA table</span>\n",
    "\n",
    "As in the case of the simple linear regression model, the sums of squares are very useful to analyze the quality of the linear regression model. In particular, they provide information regarding the explanatory power of the model, through the value of the coefficient of determination $R^2$, and they also contain information with respect to the global significance of the model, as we describe below.\n",
    "\n",
    "We group these values into an ANOVA table, organized as in Lesson 4:\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\\begin{array}{lcccc}\n",
    "\\text{Variability source} & \\text{Sums of squares} & \\text{Degr of freedom} & \\text{Means of squares} & \\text{F ratio} \\\\\n",
    "\\hline\n",
    "\\text{Model} & \\text{SSM} = \\sum_i (\\hat y_i - \\bar y)^2 & k & \\text{SSM}/k & (\\text{SSM}/k)/s_R^2 \\\\\n",
    "\\text{Residuals} & \\text{SSR} = \\sum_i (y_i - \\hat y_i)^2 = \\sum_i e_i^2 & n-k-1 & \\text{SSR}/(n-k-1) = s_R^2 & \\\\\n",
    "\\hline\n",
    "\\text{Total} & \\text{SST} = \\sum_i (y_i - \\bar y)^2 = (n-1) s_y^2 & n-1 & & \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "To complete this table we conduct the following calculations:\n",
    "1. Start with the values of the sums of squares and the numbers of degrees of freedom\n",
    "2. Compute the means of the squares by dividing the sums of squares by their degrees of freedom\n",
    "3. Compute the <span style=\"color:brown;\">F Ratio</span> as the quotient between the mean of the squares of the model and the residual variance\n",
    "\n",
    "As in the simple linear regression model, the F ratio provides important information about the model. In the case of a multiple linear regression model, it allows us to test for its <span style=\"color:brown;\">global significance.</span> If the model is significant, we should observe a large value for the mean of squares of the model and a small value for the mean of squares of the residuals, implying a large value for the F Ratio, which we can test based on an appropriate statistic and distribution.\n",
    "\n",
    "We compute the ANOVA table for the linear regression model in the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caf1400-349a-40f9-9f07-8ee9ba9ee571",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ANOVA table\n",
    "\n",
    "## Values for the table\n",
    "\n",
    "df.m = n.ind.var\n",
    "df.r = n.obs - df.m - 1\n",
    "\n",
    "F.anova.s = (df.r/df.m)*(SST-SSR)/SSR\n",
    "xy.anova = matrix(c(SST-SSR,SSR,SST,df.m,df.r,n.obs-1,SST-SSR,SSR/df.r,NA,\n",
    "                    F.anova.s,NA,NA),3,4)\n",
    "xy.anova = as.data.frame(xy.anova)\n",
    "colnames(xy.anova) = c(\"SS\",\"DF\",\"Mean\",\"F ratio\")\n",
    "rownames(xy.anova) = c(\"Model\",\"Residuals\",\"Total\")\n",
    "\n",
    "## Print the ANOVA table\n",
    "\n",
    "xy.anova.f = xy.anova\n",
    "xy.anova.f[,1:4] = format(xy.anova[,1:4],digits = 3)\n",
    "xy.anova.f[2,4] = NA\n",
    "xy.anova.f[3,3:4] = NA\n",
    "\n",
    "options(knitr.kable.NA = ' ')\n",
    "options(align = 'r')\n",
    "table_prnt(xy.anova.f,\"ANOVA Table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a02c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown;\">Global significance of the model</span>\n",
    "\n",
    "We have seen before how to test for the significance of each one of the parameters in the linear regression model, that is, to test if there is a significant linear relationship between the dependent variable and <span style=\"color:brown;\">*one*</span> of the independent variables.\n",
    "\n",
    "But it may also be of interest to test if the model is globally significant, that is, if there is a linear relationship between the dependent variable and <span style=\"color:brown;\">*any*</span> of the independent variables. This test is conducted on the value of the <span style=\"color:brown;\">F ratio</span> from the ANOVA table.\n",
    "\n",
    "This <span style=\"color:brown;\">global significance test</span> is defined as\n",
    "\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "  H_0 & : \\ \\beta_1 = \\beta_2 = \\cdots = \\beta_k = 0 \\\\\n",
    "  H_1 & : \\mbox{ at least one } \\beta_j \\not = 0 ,\\ j \\in \\{ 1 , \\ldots , k \\}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "and the statistic we will use for this test is the F ratio in the ANOVA table.\n",
    "\n",
    "In order to conduct inference on this ratio, and to carry out the global significance test, we need to know its distribution. It holds that under $\\beta_j = 0$ for $j = 1,\\ldots , k$, that is, under the null hypothesis for the global significance test,\n",
    "\n",
    "$$\n",
    "\\text{F Ratio} = \\frac{\\text{SSM}/k}{S_R^2} \\sim F_{k,n-k-1}\n",
    "$$\n",
    "\n",
    "as the F Ratio is the ratio between two independent chi squared random variables.\n",
    "\n",
    "The p-value of this test for our example is given in the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b5282-2ff6-4684-9158-2f77d107b64c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Values for the global significance test\n",
    "\n",
    "sig.lvl = 0.05\n",
    "F.crit = qf(sig.lvl,df.m,df.r,lower.tail=FALSE)\n",
    "F.pval = pf(F.anova.s,df.m,df.r,lower.tail=FALSE)\n",
    "\n",
    "n.val.1 = 3\n",
    "val.t = c(sig.lvl,F.anova.s,F.crit,F.pval)\n",
    "out.t = as.data.frame(matrix(format(val.t[1:n.val.1],digits=4),n.val.1,1))\n",
    "out.t = rbind(out.t,format(val.t[n.val.1+1],scientific=TRUE,digits=3))\n",
    "rownames(out.t) = c(\"Significance level\",\"F Ratio\",\n",
    "                    \"Critical value F ratio\",\"P value for the test\")\n",
    "colnames(out.t) = c(\"Values\")\n",
    "\n",
    "table_prnt(out.t,\"ANOVA global significance test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94eb36-8b86-40b6-af87-1e98d01870dd",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*A manufacturing company is studying the effect that both the average monthly prices of electricity ($x_1$), and the average subsidy that the administrations may offer for the purchase of one of these cars ($x_2$), may have in the sales of several electric car models ($y$). It has collected information from a total of 12 different (but similar) markets during a period of time, obtaining the following data:*\n",
    "\n",
    "| Electricity price | Subsidies | Sales |\n",
    "| ---: | ---: | ---: |\n",
    "| 177.68 | 1200 | 116 |\n",
    "| 88.08 | 2000 | 350 |\n",
    "| 235.22 | 3200 | 224 |\n",
    "| 107.92 | 3200 | 352 |\n",
    "| 190.6 | 2000 | 85 |\n",
    "| 74.32 | 1500 | 325 |\n",
    "| 132.11 | 3500 | 268 |\n",
    "| 137.41 | 2500 | 314 |\n",
    "| 104.63 | 1000 | 237 |\n",
    "| 132.99 | 3500 | 241 |\n",
    "| 165.36 | 2700 | 203 |\n",
    "| 141.3 | 800 | 98 |\n",
    "\n",
    "*You may use the following values obtained as a summary of the results from the data and the adjusted model:*\n",
    "\n",
    "| Parameter | Value |\n",
    "| :--- | ---: |\n",
    "Quasivariance of $y$ | 8995.902 |\n",
    "Sum of squares of the residuals | 28961.71 |\n",
    "\n",
    "- *Construct the ANOVA table for this model.*\n",
    "\n",
    "- *Compute the value of the coefficient of determination and interpret this value.*\n",
    "\n",
    "- *Conduct a global significance test for the model, for a significance level of 1%.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbdc59c-5c49-4176-9539-c0658ecca574",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "1. We start with the values of the sums of squares corresponding to the model. We have that\n",
    "\n",
    "$$\n",
    "\\text{SST} = (n-1) s_y^2 = 11\\times 8995.902 = 98954.92 , \\qquad \\text{SSR} = 28961.71 , \\qquad \\text{SSM} = \\text{SST} - \\text{SSR} = 69993.21\n",
    "$$\n",
    "\n",
    "From these values we can complete the ANOVA table as\n",
    "  \n",
    "$$\n",
    "\\small\n",
    "\\begin{array}{lcccc}\n",
    "\\text{Variability source} & \\text{Sums of squares} & \\text{Degr of freedom} & \\text{Means of squares} & \\text{F ratio} \\\\\n",
    "\\hline\n",
    "\\text{Model} & 69993.21 & 2 & 34996.605 & 10.875 \\\\\n",
    "\\text{Residuals} & 28961.71 & 9 & 3217.968 & \\\\\n",
    "\\hline\n",
    "\\text{Total} & 98954.92 & 11 & & \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "2. The value of the coefficient of determination will be\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\text{SSM}}{\\text{SST}} = \\frac{69993.21}{98954.92} = 0.7073\n",
    "$$\n",
    "\n",
    "and this value implies that 70% of the total variance in $Y$ can be explained by the linear regression model.\n",
    "  \n",
    "The value of the adjusted coefficient of determination is given by\n",
    "  \n",
    "$$\n",
    "\\mbox{adj. } R^2 = 1 - \\frac{s_R^2}{s_y^2} = 1 - \\frac{3217.968}{8995.902} = 0.642\n",
    "$$\n",
    "\n",
    "slightly smaller than the preceding value.\n",
    "  \n",
    "3. For the global significance test we will compare the value of the F ratio with the critical value for a $F_{2,9}$ distribution. In our case, this value is $F_{2,9;0.01} = 8.022$. As the F ratio is larger than this value, $ 10.875 > 8.022$, we conclude that this multiple linear regression model is globally significant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d57f4-a81e-492c-be6e-8b3348ccb13f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## <span style=\"color:brown;\">Residual analysis and model diagnostics</span>\n",
    "\n",
    "---\n",
    "\n",
    "The results related to inference on the linear regression model are based on the premise that the assumptions for the regression model are satisfied by the available data. In practice, these assumptions do not need to hold exactly, and may not even be close to holding. In these cases, we should treat the preceding distributional results, and the corresponding conclusions based on them, with great caution.\n",
    "\n",
    "For practical applications, it is important to have procedures to determine when we are close to satisfying our assumptions and we may consider our results as reasonable approximations, or when this is not the case and our results will provide only poor approximations to the variable of interest. In the following paragraphs we introduce some simple checks we may perform on our data to evaluate its level of satisfaction for our assumptions.\n",
    "\n",
    "Most of these checks are based on the analysis of the residuals, to determine if (all or some of) the assumptions of the linear regression model on the errors of the model hold for them. We will look at the assumptions of: i) normality for the errors, ii) lack of dependence of their variances with respect to the values of $X$, also referred to as <span style=\"color:brown;\">homoskedasticity,</span> and iii) independence of the errors. Also, we will consider the possible presence of nonlinearities in the relationship between $Y$ and $X$.\n",
    "\n",
    "The independence of the errors is particularly difficult to verify, as there are many possible sources of dependence, with different impacts on the values of these residuals. We will describe some reasonably simple tests to determine if the data present clear violations of our assumptions.\n",
    "\n",
    "We will conduct this study by:\n",
    "\n",
    "1. Computing the <span style=\"color:brown;\">standardized residuals,</span> defined as the values $e_i / s_R$, and then plotting these residuals vs.\\ the predicted values $\\hat y_i$. This scatterplot allows us to check for the presence of nonlinearities, and also for the possible presence of heteroskedasticity.\n",
    "2. Representing a <span style=\"color:brown;\">QQplot of the residuals,</span> to study how well the assumption of normality is satisfied by these residuals.\n",
    "3. Obtaining some information on the independence of the residuals by checking the scatterplot of the residuals, and also by conducting a Durbin-Watson test to check for the presence of <span style=\"color:brown;\">autoregression in the residuals.</span>\n",
    "\n",
    "The presence of autoregression in the residuals would imply that these residuals are not independent, in the sense that they may depend on residuals corresponding to previous observations in the sample (separated by a certain number of observations). This test is not very reliable, unless there is a natural ordeering for the sample observations, such as for example if these observations are associated to different time periods.\n",
    "\n",
    "From the scatterplot, we verify if it shows any structure incompatible with (approximately) normal observations with standard deviation equal to 1. In the case of the Durbin-Watson test, we will determine if the p-value is small enough to reject the null hypothesis for this test, defined as the lack of significant autocorrelation in the residuals. \n",
    "\n",
    "These results are presented in the following cell for the data we have selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05390fe8-255f-4243-97f5-493ed9a4bdb9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Residual analysis and diagnostics\n",
    "\n",
    "std.res = as.data.frame(cbind(data.sel$Yhat,data.sel$res/sqrt(sR.2r)))\n",
    "names(std.res) = c(\"Yhat\",\"Res\")\n",
    "\n",
    "## Residual plots\n",
    "\n",
    "plt.res.1 <- std.res %>% ggplot(aes(x=Yhat,y=Res)) +\n",
    "  geom_point() + geom_hline(yintercept = 0, color = \"red\") +\n",
    "  ggtitle(\"Scatterplot residuals vs predicted values\") +\n",
    "  xlab(\"Predicted values\") + ylab(\"Residuals\")\n",
    "\n",
    "plt.res.2 <- std.res %>% ggplot(aes(sample=Res)) +\n",
    "  stat_qq_band() + stat_qq_line(color=\"red\") + stat_qq_point() +\n",
    "  ggtitle(\"QQplot for the residuals\") +\n",
    "  xlab(\"Residual quantiles\") + ylab(\"Normal distribution quantiles\")\n",
    "\n",
    "suppressWarnings(grid.arrange(plt.res.1, plt.res.2,nrow = 2,\n",
    "                              top=textGrob(\"Regression residual plots\",gp=gpar(fontsize=15,col=\"blue\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e225ffb-1747-4cdd-860c-5733368df57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Durbin-Watson test\n",
    "\n",
    "out.dw = durbinWatsonTest(lr.xy.m)\n",
    "\n",
    "out.dw.0 = as.numeric(c(1,out.dw$r,out.dw$dw,out.dw$p))\n",
    "out.dw.1 = t(as.data.frame(format(out.dw.0,digits=3)))\n",
    "colnames(out.dw.1) = c(\"lag\",\"Autocorr\",\"DW stat\",\"P value\")\n",
    "rownames(out.dw.1) = c(\"Values\")\n",
    "if (out.dw$alternative == \"two.sided\") lst.dw = c(\"Alternative hypothesis:\",\"rho <> 0\")\n",
    "alt.dw = matrix(lst.dw,1,2)\n",
    "\n",
    "table_prnt(out.dw.1,\"Durbin Watson autocorrelation test\")\n",
    "table_prnt(alt.dw,\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111da9c1-45d7-4bc8-9538-4622518a56e6",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\">Example of model diagnostics</span>\n",
    "\n",
    "This example is based on:\n",
    "\n",
    "1. The electricity prices data set. Variables in the data set considered for the multiple linear regression model:\n",
    "   - Independent variables: Hourly demand in Spain and sales from Portugal to Spain in the Iberian electricity market.\n",
    "   - Dependent variable: Hourly electricity prices for Spain.\n",
    "2. The same data and variables, but only for hours corresponding to weekends. It is well known that this data is not homogeneous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9e1f8-32cd-4579-8b6d-ad0451e3814b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define several functions to be used for the analysis of the different data sets\n",
    "\n",
    "show.data <- function(s.data,c.names,descr.txt) {\n",
    "    # A function to control the presentation of tables with numerical results\n",
    "    n.obs = nrow(s.data)\n",
    "    n.var = ncol(s.data)\n",
    "    n.ind.var = n.var - 1    # Number of independent variables k\n",
    "    ## Summary of the selected data\n",
    "    descr.df = as.data.frame(c(descr.txt,c.names))\n",
    "    colnames(descr.df) <- c(\"Selection\")\n",
    "    nm.0 = c(\"Data set\",\"Independent variables\")\n",
    "    for (i.x in 2:n.ind.var) nm.0 = c(nm.0,\"\")\n",
    "    rownames(descr.df) <- c(nm.0,\"Dependent variable\")\n",
    "    Data.hux.0 <- hux(descr.df) %>%\n",
    "       set_bold(row = 1, value = T) %>%\n",
    "       set_all_borders(TRUE)\n",
    "    table_prnt(Data.hux.0[-1,],\"\")\n",
    "    ## Drawing a scatterplot matrix\n",
    "    ggpairs(s.data,title=\"Scatterplots for variables\") +\n",
    "       theme(plot.title = element_text(size = 18, color = \"blue\"))\n",
    "    }\n",
    "\n",
    "lrmod.vals <- function(s.data,c.names) {\n",
    "    # A function to compute and show a summary of results from the linear regression model\n",
    "    n.obs = nrow(s.data)\n",
    "    n.var = ncol(s.data)\n",
    "    n.ind.var = n.var - 1    # Number of independent variables k\n",
    "    n.df = n.obs - n.ind.var - 1\n",
    "    mod.descr = paste0(c.names[n.var],\" ~ \")\n",
    "    for (i.x in 1:n.ind.var) {\n",
    "        mod.descr = paste0(mod.descr,c.names[i.x])\n",
    "        if (i.x < n.ind.var) mod.descr = paste0(mod.descr,\" + \")\n",
    "        }\n",
    "    lr.xy = lm(mod.descr, data = s.data)\n",
    "    lr.sum <- summary(lr.xy)\n",
    "    table_prnt(lr.sum[4],\"Parameter estimates\")\n",
    "    m.ssr = sum(lr.xy$residuals^2)\n",
    "    m.sst = (n.obs-1)*var(s.data[,n.var])\n",
    "    val.4 = c(n.obs,m.sst,m.ssr)\n",
    "    lr.sum.4 <- round(as.data.frame(matrix(val.4),3,1),2)\n",
    "    colnames(lr.sum.4) <- c(\"Sum of squares\")\n",
    "    rownames(lr.sum.4) <- c(\"Number of observations\",\"Total\",\"Residuals\")\n",
    "    table_prnt(lr.sum.4,\"Sums of squares\")\n",
    "    ## Values to return\n",
    "    return(lr.xy)\n",
    "    }\n",
    "\n",
    "lrmod.out <- function(s.data,lr.xy) {\n",
    "    # A function to compute and show all results from the linear regression model\n",
    "    n.obs = nrow(s.data)\n",
    "    n.var = ncol(s.data)\n",
    "    n.ind.var = n.var - 1    # Number of independent variables k\n",
    "    n.df = n.obs - n.ind.var - 1\n",
    "    lr.sum <- summary(lr.xy)\n",
    "    lr.sum.2 <- round(as.data.frame(lr.sum[8:9]),3)\n",
    "    colnames(lr.sum.2) <- c(\"R squared\",\"Adj R sq\")\n",
    "    lr.aux = lr.sum[10]$fstatistic\n",
    "    lr.aux[4] = 1 - pf(lr.aux[1],n.ind.var,n.df)\n",
    "    lr.sum.3 <- round(as.data.frame(lr.aux),3)\n",
    "    colnames(lr.sum.3) <- c(\"F statistic\")\n",
    "    rownames(lr.sum.3) <- c(\"Value\",\"df num\",\"df den\",\"P value\")\n",
    "    table_prnt(list(lr.sum.2,lr.sum.3),\"Coeff of determination and global significance\")\n",
    "    # Plots for the residuals\n",
    "    m.ssr = sum(lr.xy$residuals^2)\n",
    "    sR.2r = m.ssr/n.df\n",
    "    std.res = data.frame(res = lr.xy$residuals/sqrt(sR.2r))\n",
    "    plt.res <- std.res %>% ggplot(aes(sample = res)) +\n",
    "       stat_qq_band() + stat_qq_line(color=\"red\") + stat_qq_point() +\n",
    "       ggtitle(\"QQplot for the residuals\") +\n",
    "       xlab(\"Residual quantiles\") + ylab(\"Normal distribution quantiles\")\n",
    "    suppressWarnings(plot(plt.res))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32981c-d9fe-4d1b-8a59-0422fc6eb799",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the data set of interest, electricity prices for the Iberian market\n",
    "\n",
    "sel.data = 1\n",
    "sel.var = c(7,14,5)\n",
    "\n",
    "s.pref = v.pref[sel.data,]\n",
    "data.fr = read.csv2(s.pref$file)\n",
    "s.data.a = as.data.frame(data.fr[,sel.var])\n",
    "c.names.a = colnames(data.fr[,sel.var])\n",
    "\n",
    "## Process the data\n",
    "\n",
    "show.data(s.data.a,c.names.a,s.pref$title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889cce5-3942-4e1a-96b6-760351f6308a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Summary of results\n",
    "\n",
    "v.lv.a = lrmod.vals(s.data.a,c.names.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e552057-c8c0-47eb-8fe1-e53f56ecec09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Full information\n",
    "\n",
    "lrmod.out(s.data.a,v.lv.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0634da8f-0f7e-482b-8098-52e00924b666",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Second data set\n",
    "\n",
    "# Define the data set of interest: electricity prices for weekends\n",
    "\n",
    "sel.data = 1\n",
    "sel.var = c(7,14,5)\n",
    "\n",
    "s.pref = v.pref[sel.data,]\n",
    "data.fr = read.csv2(s.pref$file)\n",
    "s.data.b = as.data.frame(data.fr[(data.fr[,3] > 5),sel.var])\n",
    "c.names.b = colnames(data.fr[,sel.var])\n",
    "\n",
    "## Process the data\n",
    "\n",
    "show.data(s.data.b,c.names.b,s.pref$title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05278942-7636-4c97-86ef-3ec0e6671af6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Summary of results\n",
    "\n",
    "v.lv.b = lrmod.vals(s.data.b,c.names.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28af7b1-6266-45a8-be21-e070c983ec73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Full information\n",
    "\n",
    "lrmod.out(s.data.b,v.lv.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e8460-a593-45b1-8e1b-0d3c5613c972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
