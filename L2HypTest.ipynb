{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc4cdb9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <span style=\"color:brown\">Hypothesis testing on one population</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2583eff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:brown;\">Contents</span>\n",
    "\n",
    "This chapter covers the contents from Lesson 2 in the Statistics II subject, *\"Hypothesis testing in one population\"*. These contents correspond to the motivation and description of a procedure to reach conclusions for simple questions about population parameters, based on information obtained from a sample. We will refer to this procedure as <span style=\"color:brown;\">hypothesis testing</span> and in this lesson we will consider the case when we only have one population.\n",
    "\n",
    "These contents are structured as follows:\n",
    "\n",
    "- Description of a hypothesis testing procedure\n",
    "   - Definition of the test\n",
    "   - Different types of tests\n",
    "- Testing errors, significance and power of a test\n",
    "   - Critical region of a test\n",
    "- Procedure to conduct a hypothesis test\n",
    "   - Application cases for different parameters and assumptions\n",
    "- P-value of a test\n",
    "- Relationship between hypothesis tests and confidence intervals\n",
    "- Computing the power of a test for a true value of the parameter or the sample size for a desired power\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c721c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:brown;\">Introduction</span>\n",
    "\n",
    "---\n",
    "\n",
    "### <span style=\"color:brown;\">Goals (i)</span>\n",
    "\n",
    "In Statistics II we are interested in the definition, implementation and understanding of procedures to conduct statistical inference, that is, to extract information from one or several samples, in order to provide relevant knowledge about some parameters of interest in a population.\n",
    "\n",
    "This knowledge can be generated in many different forms, depending on the specific application and the relevant questions to answer based on the available data. For example, in Lesson 1 we considered the situation where we wanted to obtain a good numerical approximation to the parameter values, as well as information on the error associated to this approximation. In this Lesson we consider how to obtain information about the answers to simple (yes/no) questions on the parameters of interest for one population, based on the sample data.\n",
    "\n",
    "As we have uncertain information, in the derivation of these procedures we will pay special attention to different means of controlling the probabilities of any unavoidable errors associated to this uncertainty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d55713-5c27-489e-af04-342a5b680beb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown;\">Goals (ii)</span>\n",
    "\n",
    "Our learning goals for this lesson are:\n",
    "\n",
    "- Know how to formulate and perform a test of hypothesis in a one-population setting\n",
    "   - Know how to formulate the null and alternative hypotheses of the test in an efficient manner,\n",
    "   - And how to apply a procedure to obtain an answer using either critical regions or p-values\n",
    "      - Being able to select a suitable test statistic for the test\n",
    "   - To understand how to interpret the results of a hypothesis test\n",
    "- To understand the definition and the meaning of Type I and Type II errors, and their impact on hypothesis testing procedures\n",
    "   - Know the definitions of the significance level and the power of a test\n",
    "- To know how to calculate the power of a test and how to identify a sample size needed to achieve a desired power\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2fd6a-cf98-4add-a4cd-5f88845ef9a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## <span style=\"color:brown\">Hypothesis tests</span>\n",
    "\n",
    "---\n",
    "\n",
    "We wish to define procedures to answer simple questions about the values of population parameters, based on the information available in an observed random sample. In this lesson we will mostly study how to conduct comparisons between a given parameter and a reference value, based on the observations in the sample. More specifically, these procedures will compare the values of population means, proportions, variances or standard deviations with some specified values of interest for these parameters.\n",
    "\n",
    "For example, if our variable represents the change in a price, we may be interested in knowing if the mean of this variable is positive, that is, if the price is increasing. Or if our variable represents the voting intentions of individuals, we may be interested in comparing the population proportion of persons willing to vote for a certain party with the value of this proportion that was observed in the last election (based on a sample of voters).\n",
    "\n",
    "To answer these questions, we will proceed by determining how best to:\n",
    "1. Provide a <span style=\"color:brown;\">formal representation for the question</span> of interest.\n",
    "   - We will do this by introducing a mathematical description based on the definition of a null and an alternative hypothesis, corresponding to the true/false answers to this question.\n",
    "   - This description will be based on a mathematical comparison between our parameter and a reference value ($\\theta_0$).\n",
    "2. Define a way to <span style=\"color:brown;\">compare the information in our sample with a reference value for the parameter.</span>\n",
    "   - This summary will be based on the use of an appropriate <span style=\"color:brown;\">statistic</span> that combines a sample estimate and the reference value into a number.\n",
    "   - The statistic should provide large/small values associated to the true/false answers we have defined.\n",
    "3. Conduct an <span style=\"color:brown;\">evaluation of the evidence based on the value of the statistic</span> to determine if it is sufficiently large/small to answer yes/no to our question.\n",
    "   - We will define a critical value to define when the statistic value is sufficiently large.\n",
    "   - As the information available (our sample) is uncertain, we will make use of probability information obtained from the (known) distribution of the statistic to define the critical value.\n",
    "   - The probabilities we will use as reference will be defined from the probabilities of the errors we could make when applying this hypothesis testing procedure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa7a644-07dc-4020-b8f1-2acc1d29a987",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown\">Step 1. Defining the null and alternative hypotheses</span>\n",
    "\n",
    "In hypothesis testing we consider situations where there exist only two outcomes of interest, which we can associate to answering yes/no to a certain question comparing the values of a population parameter to some reference value. The first step in our procedure to conduct these hypothesis tests is to formally define our yes/no question.\n",
    "\n",
    "The two outcomes for the question will be represented by what we will call our <span style=\"color:brown\">null</span> and <span style=\"color:brown\">alternative hypotheses.</span> And as our main goal is to compare parameter values with some given reference values, these hypotheses will be written in terms of equalities or inequalities relating the parameter of interest and one reference value, for example, one of these hypotheses could take the form $\\theta \\geq \\theta_0$. Also, and for the purposes of this lesson, they will always be defined so that the null and alternative hypotheses are given in terms of <span style=\"color:brown\">sets of values of the parameter that are the complement of each other.</span>\n",
    "\n",
    "To illustrate this situation with an example, assume we are studying the population mean of the change in the weekly prices of a certain commodity, and we wish to determine if our sample provides sufficient evidence that the expected value of these weekly changes is larger than $0.1$%. Formally, our yes/no question can be written in one of two possible ways:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "H_0 & : & \\mu \\geq 0.001 = \\mu_0 \\\\\n",
    "H_1 & : & \\mu < 0.001\n",
    "\\end{array} \\qquad \\mbox{or} \\qquad \n",
    "\\begin{array}{rcl}\n",
    "H_0 & : & \\mu \\leq 0.001 = \\mu_0 \\\\\n",
    "H_1 & : & \\mu > 0.001\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where the population mean $\\mu$ is the parameter of interest, and $\\mu_0 = 0.001$ is our reference value.\n",
    "\n",
    "In this representation we have introduced several conventions commonly used in hypothesis testing, and that we will maintain throughout this course. Note that these conventions could be modified without significantly changing the basic procedure we will describe below.\n",
    "\n",
    "- We denote by $H_0$ the null hypothesis and by $H_1$ the alternative hypothesis.\n",
    "- We indicate each hypothesis as an equality or inequality relating the corresponding population parameter (the population mean in this case) and a reference value.\n",
    "- We write the null hypothesis including the equality between the parameter and the reference value.\n",
    "- Both hypotheses define a partition of the values of the parameter, that is, all possible values are covered between both of them, and they have no intersection.\n",
    "\n",
    "We now comment on how to choose which one of two representations indicated above is the one we prefer for our hypothesis test. A complication is that the procedure used to conduct the test does not treat both hypotheses as symmetric, that is, if we were to interchange the two hypotheses the results we would obtain would not be equivalent. Thus, the choice of one representation over the other may affect the answer provided by the test.\n",
    "\n",
    "We may think of the possible outcomes of the test as corresponding to one of three possible alternatives: i) we have enough evidence in favor of $H_0$, ii) we have enough evidence in favor of $H_1$ or iii) we do not have enough evidence in favor of either of the hypotheses. But, although we have these three situations, our procedure will be defined as having only two possible outcomes: either we reject $H_0$ or we fail to reject it. That is, we do not differentiate between situations where we should reject $H_1$ and those where we do not have enough evidence to clearly favor any of the two hypotheses.\n",
    "\n",
    "As a consequence, our conclusion will be based on determining if we have enough evidence to reject $H_0$. And if in some case the evidence is not sufficient to reject $H_0$, we will not conclude automatically that we can reject $H_1$. This implies that <span style=\"color:brown\">our procedure favors $H_0$,</span> in the sense that unless we have clear evidence to reject it, we will continue accepting $H_0$. This has clear implications for our choice of $H_0$, so that if for example we define $H_0 : \\mu \\geq 0.001$, then we will tend to accept this statement is correct unless the observed data has a value of the sample mean clearly smaller than $0.001$.\n",
    "\n",
    "As a summary, <span style=\"color:brown;\">when we do not have sufficent evidence</span> to support any of the two hypotheses, <span style=\"color:brown;\">we give the benefit of the doubt to the null hypothesis, $H_0$.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b24ad0b-e185-4be2-ac26-2b33ac95d4fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Answer the following questions:</span>\n",
    "- <span style=\"color:green\">Indicate the null and alternative hypotheses for a test on the population mean where you wish to test if the value of this parameter is larger than 5, based on sample data. Discuss your different alternatives.</span>\n",
    "- <span style=\"color:green\">Assume you have been given a test with $H_0 : p \\leq p_0$. Write down the form of $H_1$ for this test.</span>\n",
    "- <span style=\"color:green\">Given the alternative hypotesis for a test defined as $H_1 : \\sigma > \\sigma_0$, indicate if the null hypothesis would be $H_0 : \\sigma \\leq \\sigma_0$ or $H_0 : \\sigma = \\sigma_0$.</span>\n",
    "- <span style=\"color:green\">If you wish to specify only one of the two hypotheses in a test, which one would be more informative, $H_0$ or $H_1$?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73defe06-fc5c-48a5-8143-934a9acd2648",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:brown\">Selecting a null hypothesis for the test</span>\n",
    "\n",
    "Based on our preceding comments on the preference of the procedure to keep $H_0$, we present some observations and practical considerations when selecting the null and alternative hypotheses for a test.\n",
    "\n",
    "- As an initial observation, the procedure that has been described to conduct a hypothesis test can be applied to any definition of the null and alternative hypotheses, within the cases considered up to this point. In particular, the procedure is the same even if we interchange the null and alternative hypotheses in a test.\n",
    "- But this procedure introduces an asymmetry between both hypotheses, and the answers we may get depend on the way the test is defined (the way we define $H_0$). These answers would be affected if we exchange both hypotheses.\n",
    "   - And some ways to define the null hypothesis may provide answers that are more informative from a practical point of view.\n",
    "\n",
    "In some cases we need to define our test (define $H_0$) before we observe our sample values, or independently of these values.\n",
    "- This might be due to legal or ethical reasons, for example.\n",
    "   - In a clinical trial conducted as part of the approval process for a certain treatment, this approval usually is granted only if the evidence in favor of the medical benefits of the treatment is very significant (due for example to the existence of possible side effects, or its high costs). In this case we would prefer to choose our alternative hypothesis to imply that unless the evidence in favor of the treatment is very clear, it would not be approved. We would define:\n",
    "   \n",
    "$$\n",
    "H_1 : \\mbox{ the outcome of the trial shows significant clinical benefits}\n",
    "$$\n",
    "\n",
    "   - If a regulator is considering the possibility of imposing penalties on a company because of practices going against rules and regulations, it would only proceed with penalizing the company if the evidence for these practices is very clear. That is, our alternative hypothesis in this case would be:\n",
    "\n",
    "$$\n",
    "H_1 : \\mbox{ significant evidence of practices going against regulations has been found}\n",
    "$$\n",
    "\n",
    "- In general, for these cases the alternative hypothesis corresponds to an option we would only accept if the evidence from the sample would clearly favor it.\n",
    "\n",
    "In most practical cases it is possible to wait until the sample has been collected before having to specify the hypotheses for the test.\n",
    "- In these cases, the choice of hypotheses can be (should be) based on the evidence provided by the data and on the reference values of interest (the value of $\\mu_0$, for example).\n",
    "- The test will in most practical cases be defined as a one-sided test, as the evidence always lies on one side of the reference value.\n",
    "- If the evidence from the sample were aligned with the hull hypothesis (for example, if $\\bar x > \\mu_0$ and $H_0 : \\mu \\geq \\mu_0$), then $H_0$ would not be rejected, for reasonable values of the significance level, below 50\\%.\n",
    "   - To reach this conclusion we do not need to apply the testing procedure; thus, this conclusion is not very informative.\n",
    "- When the evidence from the sample is aligned with the alternative hypothesis, we have a more interesting situation, as the conclusion would depend on how far is this evidence from the reference value.\n",
    "- We must determine if this evidence is sufficiently different from the null hypothesis, in which case we would reject $H_0$, or if it is not too far away from it, and then we would fail to reject it.\n",
    "   - We carry out this study by following the procedure we have just described.\n",
    "- In these cases, the alternative hypothesis for our one-sided test goes in the direction of the evidence provided by the sample.\n",
    "\n",
    "As a final comment, we observe that failing to reject the null hypothesis of a one-sided test is not the same as accepting that our evidence supports this null hypothesis.\n",
    "- When we fail to reject $H_0$, we have two possible situations: \n",
    "   - We may not have enough information to accept or reject $H_0$, or\n",
    "   - We have enough information to be highly confident in the validity of $H_0$.\n",
    "- To verify if we have enough evidence to accept $H_0$, as opposed to the option of just not rejecting it:\n",
    "   - We must have evidence from our sample going in the direction of the null hypothesis.\n",
    "   - And additionally this evidence must be well within the range of values included in $H_0$.\n",
    "   - This would be equivalent to rewriting our test to determine if we would reject $H_1$, after we interchange $H_0$ and $H_1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47221f-e836-4bca-81e2-00e8f29bc11c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Answer the following questions:</span>\n",
    "- <span style=\"color:green\">For a given test with a null hypothesis of the form $H_0 : p \\leq p_0 = 0.3$ you have collected a sample such that $\\hat p = 0.25$. What can you say about the conclusion for this test?</span>\n",
    "- <span style=\"color:green\">You are asked to test if a population mean is equal to 0, and you have collected a sample where $\\bar x = -0.35$. Comment on the advantages or disadvantages of selecting as the null hypothesis for your test either $H_0 : \\mu = \\mu_0 = 0$, $H_0 : \\mu \\geq \\mu_0$ or $H_0 : \\mu \\leq \\mu_0$</span>\n",
    "- <span style=\"color:green\">How would the preceding remarks apply to a two-sided test?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7a8c0-16af-47be-a33c-4bfcc8c89291",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*To verify the gas mileage of a new car model, a manufacturer selects six non-professional drivers to drive six different cars of this new model between two cities. At the end of each trip, the mileage of the corresponding vehicle is measured (in liters per Km) and the resulting values are indicated in the following table:*\n",
    "\n",
    "$$\n",
    "\\begin{array}{cccccc}\n",
    "    5.82 & 5.74 & 6.25 & 5.57 & 6.13 & 5.61\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "*The manufacturer would like to conduct a publicity campaign based on the statement that the new model has a gas consumption lower than 6 liters per Km on the highway. Assuming that the gas consumption on highway trips is distributed normally, you are asked to test the manufacturer claim at a 5\\% significance level.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a650909-1e1d-4a0b-af1d-348f6708b66a",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "Let $X$ denote the random variable under consideration: the gas consumption of the new model (measured in l/Km), with mean $\\mu$. The values we have collected in our sample yield the following values and estimates\n",
    "\n",
    "$$\n",
    "\\bar x = \\frac{\\sum_{i=1}^6 x_i}{6} = 5.8533 , \\quad s = \\sqrt{\\frac{\\sum_{i=1}^6 x_i^2 - n\\bar x^2}{5}} = 0.2783, \\quad n = 6\n",
    "$$\n",
    "\n",
    "1. The test of interest is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "   H_0 & : & \\mu \\geq 6 = \\mu_0 \\\\\n",
    "   H_1 & : & \\mu < 6\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "   Note that the alternative hypothesis goes in the direction of the sample data. Also, it is reasonable to require that in order to accept a low value for the mileage we should have significant evidence supporting this claim, as a reasonable measure for customer protection.\n",
    "\n",
    "2. The statistic for this test, as we study a population mean from a sample with normal data and unknown population variance, is\n",
    "\n",
    "$$\n",
    "T = \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\sim t_{n-1}\n",
    "$$\n",
    "\n",
    "   For the sample values and the reference value used to define the null hypothesis, the test statistic takes the value:\n",
    "\n",
    "$$\n",
    "t_0 = \\frac{\\bar x - \\mu_0}{s/\\sqrt{n}} = \\frac{5.8533 - 6}{0.2783/\\sqrt{6}} = -1.2908\n",
    "$$\n",
    "\n",
    "3. We can proceed in one of two ways: i) We may compare this value $t_0$ with the relevant quantile of a Student-t distribution with five ($n-1$) degrees of freedom for a one-sided test with 5\\% significance. The critical value is $t_{5;0.95} = -t_{5;0.05} = -2.015$, obtained from the table for the Student t distribution.\n",
    "\n",
    "   Or ii) we may compute the p-value for this test using <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> as\n",
    "\n",
    "$$\n",
    "\\text{p-value} = \\Pr( T < t_0 ) = \\Pr (T_5 < -1.2908 ) = 0.1266\n",
    "$$\n",
    "\n",
    "   From the tables we can only obtain the approximation, $\\text{p-value} \\in [0.10;0.15]$. \n",
    "   \n",
    "   In the formulas for both cases we have used the inequalities given in the definition of our alternative hypothesis. \n",
    "\n",
    "4. From the preceding values, as $t_0 = -1.2908 > -2.015 = t_{5;0.95}$, we cannot reject the null hypothesis at a significance level of 5\\%, that is, we cannot state with high certainty that the gas consumption is lower than 6 l per Km. We reach the same conclusion using the p-value, as $\\text{p-value} = 0.1266 > 0.05 = \\alpha$; in general, a p-value of $0.1266$ is quite high and we would not reject $H_0$ for such a large p-value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8971d-0e33-4b12-9010-0708a19dd9f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='Step2'></a>\n",
    "\n",
    "### <span style=\"color:brown\">Step 2. Comparing the evidence and the reference value</span>\n",
    "\n",
    "Once we have specified the question of interest by defining our null and alternative hypotheses, the next step in a hypothesis test consists in conducting a meaningful comparison between our sample data and the reference value in the null hypothesis ($\\mu_0$ in our initial example).\n",
    "\n",
    "A <span style=\"color:brown\">meaningful comparison</span> should be based on a measure of the distance between the sample estimate for the parameter of interest and the reference value for this parameter. This distance should be evaluated in a manner that incorporates:\n",
    "- The relationship between these two values, that is, how close these values are.\n",
    "- The variability in the population, usually estimated from the sample, to correct the scale of the preceding distance between the values.\n",
    "- The resulting value should be easy to interpret to determine when it is large or small, that is, when the data from the sample is close or compatible with the reference value.\n",
    "\n",
    "The value we obtain at the end of this process will be used to determine if this evidence is enough to reject $H_0$, when the value is large enough compared with some critical value, or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c141e6a-09fe-4bd7-ae93-49c9250b83a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:blue;\">Preparing R and the data</span>\n",
    "\n",
    "---\n",
    "\n",
    "To illustrate the concepts we have introduced, and to motivate possible choices of good estimators, we will consider specific examples, mostly based on real data, which we will process using <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span>.\n",
    "\n",
    "We start by preparing <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> to read and manipulate the data mentioned above. In the following <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> <span style=\"color:brown\">code cell</span> we:\n",
    "\n",
    "1. Load the <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> libraries we are going to need for our examples.\n",
    "2. Define a function, <span style=\"color:blue;font-family:monospace;font-size:90%;\">table_prnt</span>, specifying the format for the tables that will present the numerical results in this lesson.\n",
    "3. Introduce information to work with the available data sets.\n",
    "\n",
    "The <span style=\"color:brown;\">available data sets</span> and their identifying codes are:\n",
    "\n",
    "1. Hourly prices for the Iberian electricity market\n",
    "2. Grades for a Statistics subject in UC3M\n",
    "3. Share prices for a company (Iberdrola) from the IBEX index\n",
    "4. Simulated data from a N(80,30) distribution (var 1), an Exp(lambda=1/30) distribution (var 2) and a Binom(20,0.4) distribution (var 3)\n",
    "5. Data from the Sustainable Develpment Report 2021, with the scores by country for goals 1 and 2\n",
    "\n",
    "In order to add another data set to this collection, you should include information for each of the following variables: the <span style=\"color:blue;font-family:monospace;font-size:90%;\">.csv</span> file containing the data and a text with a short description for the data.\n",
    "\n",
    "It is also important to ensure that the <span style=\"color:brown;\">working directory</span> has been <span style=\"color:brown;\">selected correctly,</span> as the directory that includes all the data sets that could be used in this lesson.\n",
    "\n",
    "To execute the commands in the cell, select the cell by clicking on it, and then <span style=\"color:blue;\">press the **RUN** button</span> in the menu bar, or press <span style=\"color:blue;\">Shift-Enter.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c3db2-b450-4824-a28b-a2d008a0a219",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#options(jupyter.plot_mimetypes = c(\"text/plain\",\"image/png\"))\n",
    "\n",
    "# Load libraries with R functions\n",
    "\n",
    "suppressMessages(library(tidyverse))\n",
    "suppressMessages(library(huxtable))\n",
    "library(knitr)\n",
    "suppressMessages(library(kableExtra))\n",
    "library(IRdisplay)\n",
    "suppressMessages(library(gridExtra))\n",
    "suppressMessages(library(qqplotr))\n",
    "suppressMessages(library(GGally))\n",
    "suppressMessages(library(car))\n",
    "library(grid)\n",
    "\n",
    "# Define a function to format and print the results of interest\n",
    "\n",
    "outp.type = 0   # = 1 for html output, = 0 for Jupyter Books\n",
    "\n",
    "if (outp.type == 1) {\n",
    "    table_prnt <- function(p.df,p.capt) {\n",
    "    # A function to control the presentation of tables with numerical summaries\n",
    "    p.df %>% kable(\"html\",caption=paste0('<em>',p.capt,'</em>'),align='r') %>%\n",
    "    kable_styling(full_width = F, position = \"left\") %>% as.character() %>% display_html()\n",
    "    }\n",
    "    } else {\n",
    "    table_prnt <- function(p.df,p.capt) {\n",
    "    # A function to control the presentation of tables with numerical summaries\n",
    "    p.df %>% kable(\"simple\",caption=p.capt,align='r')\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d706b9e8-f582-47ab-8968-52049880d4d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:blue;\">Examples based on selected data sets</span>\n",
    "\n",
    "---\n",
    "\n",
    "To illustrate the concepts we have introduced, and to motivate possible choices of good estimators, we will consider specific examples, mostly based on real data, which we will process using <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a5822-53bb-4522-adfd-4a0287d34d7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Selecting and displaying the data set and the variable of interest</span>\n",
    "\n",
    "We select one of these data sets and the variable of interest in the following cell.\n",
    "\n",
    "1. We assign the corresponding number to the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">sel.data</span>, at the start of the following code cell.\n",
    "2. We read the file and include the data in a <span style=\"color:brown;\">data frame</span> with the name <span style=\"color:blue;font-family:monospace;font-size:90%;\">Data.fr</span>.\n",
    "3. We assign the number corresponding to the order of the variable of interest in the data set, to the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">sel.col</span>.\n",
    "4. We assign the values of the variable to an <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> data frame with the name <span style=\"color:blue;font-family:monospace;font-size:90%;\">data.sel</span>. This data frame will contain a single variable (column) with the name <span style=\"color:blue;font-family:monospace;font-size:90%;\">Val</span>.\n",
    "\n",
    "Finally, we print the names of the selected data set and variable, to check that these values are correct. Then we display some of the values from the <span style=\"color:blue;font-family:monospace;font-size:90%;\">.csv</span> file, keeping the same structure of the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b2c07-cf11-4ca8-9a8c-ce0f0e732248",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the data set of interest\n",
    "\n",
    "## Datasets that are available for this lesson\n",
    "\n",
    "v.pref = data.frame(file = c(\"Dat_PreciosOMIE.csv\",     # Name of the .csv data file\n",
    "                            \"Dat_Calificaciones.csv\",\n",
    "                            \"Dat_PreciosIBE_MC.csv\",\n",
    "                            \"Dat_SimulatedData.csv\",\n",
    "                            \"Dat_SDR21.csv\"))\n",
    "v.pref$title = c(\"Electricity prices\",         # Short title for the data\n",
    "                \"Grades\",\n",
    "                \"Share returns\",\n",
    "                \"Simulated data\",\n",
    "                \"SDG 2021 Scores\")\n",
    "\n",
    "## Indicate the data set and variable to select\n",
    "## These values can be modified\n",
    "\n",
    "sel.data = 5\n",
    "sel.col = 6\n",
    "\n",
    "## Read the data\n",
    "\n",
    "s.pref = v.pref[sel.data,]\n",
    "\n",
    "Data.fr = read.csv2(s.pref$file)\n",
    "data.sel = as.data.frame(Data.fr[,sel.col])\n",
    "colnames(data.sel) = c(\"Val\")\n",
    "\n",
    "## Summary of the selected data\n",
    "\n",
    "descr.df = as.data.frame(c(s.pref$title,colnames(Data.fr)[sel.col]))\n",
    "colnames(descr.df) <- c(\"Selection\")\n",
    "rownames(descr.df) <- c(\"Data set\",\"Variable\")\n",
    "\n",
    "Data.hux.0 <-\n",
    "  hux(descr.df) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "table_prnt(Data.hux.0[-1,],\"\")\n",
    "\n",
    "# Print a part of the data we have selected\n",
    "\n",
    "max.row.show = 8       # Max number of individual values to show\n",
    "max.col.show = 8       # Max number of variables to show\n",
    "\n",
    "n.row.show = min(nrow(Data.fr),max.row.show)\n",
    "n.col.show = min(ncol(Data.fr),max.col.show)\n",
    "\n",
    "Data.hux.1 <-\n",
    "  hux(Data.fr[1:n.row.show,1:n.col.show]) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "rownames(Data.hux.1) <- c(0:n.row.show)\n",
    "table_prnt(Data.hux.1[-1,],s.pref$title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d369355-2954-468e-be94-0037312eab42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Summaries for the sample data</span>\n",
    "\n",
    "In the following cell we conduct some simple exploratory analysis of the data from the variable we have selected: we compute some of its most relevant numerical summaries, such as its mean, standard deviation and median.\n",
    "\n",
    "We also draw a boxplot of the sample data corresponding to this variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c8beb3-881e-46eb-91a6-647c8a757ad9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print summaries from the selected data set\n",
    "\n",
    "smp0.sz = nrow(data.sel)\n",
    "smp0.mn = mean(data.sel$Val)\n",
    "smp0.sd = sd(data.sel$Val)\n",
    "smp0.var = smp0.sd^2\n",
    "smp0.med = median(data.sel$Val)\n",
    "Sum.fr = as.data.frame(round(matrix(c(smp0.sz,smp0.mn,smp0.sd,smp0.med),4,1),3))\n",
    "\n",
    "Data.hux.2 <-\n",
    "  hux(Sum.fr) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux.2) <- c(\"\",\"Sample size\",\"Mean\",\"Standard deviation\", \"Median\")\n",
    "colnames(Data.hux.2) <- c(\"Values\")\n",
    "table_prnt(Data.hux.2[-1,],sprintf(\"%s summary\",s.pref$title))\n",
    "\n",
    "## Boxplot for the data\n",
    "\n",
    "plt.1 = data.sel %>% ggplot(aes(y=Val)) + geom_boxplot() +\n",
    "  ggtitle(sprintf(\"%s\",s.pref$title)) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  theme(axis.title.x = element_blank(),axis.text.x=element_blank(),axis.ticks.x=element_blank())\n",
    "plot(plt.1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16892743-6c73-4c14-ae74-05935e37ef1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:brown\">Example of evidence evaluation for a hypothesis test</span>\n",
    "\n",
    "Our aim with this example is to motivate the use of statistics with known distributions to evaluate the evidence from the sample and to compare it to the reference value.\n",
    "\n",
    "Assume we are interested in conducting a hypothesis test of the form:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "H_0 & : & \\mu \\leq \\mu_0 \\\\\n",
    "H_1 & : & \\mu > \\mu_0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "for some reasonable reference value $\\mu_0$, to be specified in the following cell, on the data set and the variable we have selected previously.\n",
    "\n",
    "As in Lesson 1, we do not know the values of the population parameters. We will assume that our population corresponds to all the data we have available, and the values of the population parameters are the sample values for the full sample and the associated estimators.\n",
    "\n",
    "In our experiment, we will generate subsamples of a given size from the data, and we will compute the sample means for each of the subsamples. These mean values aim to represent the different samples and sample estimates that we might have obtained in a practical case.\n",
    "\n",
    "Our aim is to illustrate the complexity of reaching a conclusion regarding these hypotheses, based on the limited information available in one random sample. We will consider a situation where, in order to decide on the validity of $H_0$, we only take into account the value of our estimate for the parameter, computed from the sample; in our case, the sample mean. Our aim is to show that this value by itself provides very limited information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b2706-050a-42b1-ad70-d3a8049439ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "##### <span style=\"color:blue\">Numerical example of evidence evaluation (i)</span>\n",
    "\n",
    "In the following cell we present the values of the means obtained from different samples in shades of blue/green, while the reference value, $\\mu_0$, is shown in red. We have also plotted the population value $\\mu$ in black, although it is important to remember that in a practical case this value would be unknown.\n",
    "\n",
    "As we have the true value of the population mean and the reference value, we know what answer is the correct one in this case, and this answer does not depend on the chosen sample. But in a practical situation we would need to reach this common conclusion by taking into account only two values: i) one of the blue/green bars (sample means) and ii) the red bar corresponding to the reference value.\n",
    "\n",
    "We note that:\n",
    "- In some cases our conclusion from the data may seem to be clear, as the difference between these two values is large, although in other cases the comparison may not be as clear.\n",
    "  - But it would be important to have some indication of which of the sample values can be considered to be close to the reference value and which values are not so close.\n",
    "- In general, we may make mistakes when reaching a conclusion based on the data, as we get conflicting answers for the different samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517459e-c87c-4286-9d57-c650888d3058",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: Values obtained from different samples\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "n.samples = 500\n",
    "smp.sz.prop = 0.2\n",
    "\n",
    "q.val = pmin(0.99,c(0.05,0.35,0.915) + 0.1*runif(1))\n",
    "\n",
    "## Parameters\n",
    "\n",
    "smp.sz = floor(smp.sz.prop*smp0.sz)\n",
    "\n",
    "frac.disp = 0.25\n",
    "mu.0 = smp0.mn - frac.disp*smp0.sd/sqrt(smp.sz)\n",
    "\n",
    "col.v.gen = c(\"#619CFF\", \"#00BFC4\", \"#00BF7D\", \"#33CCCC\", \"#33FFCC\", \"#99CCFF\")\n",
    "\n",
    "## Generate samples and estimates\n",
    "\n",
    "mn.smp = s.smp = NULL\n",
    "for (i in 1:n.samples) {\n",
    "    v.smp = sample(data.sel$Val, smp.sz, replace = FALSE)\n",
    "    mn.smp = c(mn.smp,mean(v.smp))\n",
    "    s.smp = c(s.smp,sd(v.smp))\n",
    "}\n",
    "s.mn = data.frame(vm = mn.smp, vs = s.smp)\n",
    "\n",
    "st.ord = order(s.mn$vm)\n",
    "st.vv = floor(q.val*n.samples)\n",
    "st.ix = st.ord[st.vv]\n",
    "st.val = s.mn$vm[st.ix]\n",
    "st.vsd = s.mn$vs[st.ix]\n",
    "\n",
    "q.mn = as.data.frame(cbind(q.val,st.val,st.vsd))\n",
    "colnames(q.mn) = c(\"quantiles\",\"valm\",\"vals\")\n",
    "\n",
    "l.mx = 1\n",
    "l.sz = 0.5\n",
    "col.vals = col.v.gen[1:length(q.val)]\n",
    "plt.l.1 = q.mn %>% ggplot(aes(x=valm)) +\n",
    "  ggtitle(\"Sample means\") + ylim(-l.mx,l.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_segment(aes(x = mu.0, xend = mu.0, y = -l.sz, yend = l.sz), color = \"red\", linewidth = 0.75) +\n",
    "  geom_point(aes(x = mu.0, y = 0), color = \"red\") +\n",
    "  geom_segment(aes(x = smp0.mn, xend = smp0.mn, y = -l.sz, yend = l.sz), color = \"black\", linewidth = 0.75) +\n",
    "  geom_point(aes(x = smp0.mn, y = 0), color = \"black\") +\n",
    "  geom_segment(aes(x = valm, xend = valm, y = -l.sz, yend = l.sz), color = col.vals, linewidth = 0.5) +\n",
    "  geom_point(aes(x = valm, y = 0), color = col.vals) +\n",
    "  scale_colour_discrete()\n",
    "plot(plt.l.1)\n",
    "\n",
    "## Summary of numerical values\n",
    "\n",
    "q.mn.0 = c(rbind(st.val,st.vsd))\n",
    "q.mn.v = data.frame(round(c(smp.sz,q.mn.0,mu.0,smp0.mn),3))\n",
    "\n",
    "Data.hux.1 <-\n",
    "  hux(q.mn.v) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "r.nm = \"Sample size\"\n",
    "for (i in 1:length(q.val)) {\n",
    "    r.nm = c(r.nm,sprintf(\"Mean Sample %2.0f\",i),sprintf(\"Std dev Sample %2.0f\",i))\n",
    "}\n",
    "r.nm = c(\" \",r.nm,\"mu 0\",\"Population mean\")\n",
    "rownames(Data.hux.1) <- r.nm\n",
    "colnames(Data.hux.1) <- c(\"Values\")\n",
    "table_prnt(Data.hux.1[-1,],\"Sample means and ref value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc132913-918b-4259-a048-40227ed68fb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "##### <span style=\"color:blue\">Numerical example of evidence evaluation (ii)</span>\n",
    "\n",
    "In the preceding example we did not take into account the variability in the data to scale the distances between the different values. From a more general point of view, we did not consider the form of the distribution of our sample mean values. As a consequence, it was not easy to determine when these values were close to the reference value, or if they were not.\n",
    "\n",
    "In the following cell we show the preceding values, together with information about the means obtained for a very large number of samples, which we summarize in a histogram for the sample means. This plot should motivate the relevance of having information about the distribution of our statistic, when conducting our comparisons. For example, the plot shows that the values from the samples we have selected have different probabilities of being observed in any random sample, implying that making an error for one of the values may not have the same relevance as making the same mistake for another (more central) sample.\n",
    "\n",
    "In practical applications this information will not be available. Our next best alternative will be to rely in assumptions on our data to derive a statistic with a known distribution that will allow us to approximate this distribution and to conduct meaningful comparisons between our data and the reference value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc394e-a0e5-495a-a34a-dd6a914ddc1b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: Values obtained from different samples\n",
    "\n",
    "n.bins = 20\n",
    "\n",
    "plt.h.1 = s.mn %>% ggplot(aes(x=vm)) + geom_histogram(bins = n.bins,alpha = 0.6) +\n",
    "  ggtitle(\"Histogram of sample means\") +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=mu.0,color = \"red\",linewidth=0.5) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"black\",linewidth=0.5)\n",
    "\n",
    "for (i in 1:length(q.val)) {\n",
    "    plt.h.1 = plt.h.1 + geom_vline(xintercept=q.mn$valm[i],color = col.v.gen[i],size=0.5)\n",
    "}\n",
    "\n",
    "## Second histogram with shaded region for a p-value\n",
    "\n",
    "x.mn = min(s.mn$vm)\n",
    "x.val = seq(x.mn,min(s.mn$vm))\n",
    "v.sd = st.vsd[1]/sqrt(smp.sz)\n",
    "dens.val = data.frame(x=x.val,y=dnorm(x.val,mean = mu.0,sd = v.sd))\n",
    "\n",
    "plt.h.2 = s.mn %>% ggplot(aes(x=vm)) + geom_histogram(aes(y = ..density..),bins = n.bins,alpha=0.3) +\n",
    "  ggtitle(\"Sample mean and test statistic density - mu_0 true\") +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_function(fun = dnorm, args = list(mean = mu.0, sd = v.sd), color = \"red\") +\n",
    "  geom_vline(xintercept=mu.0,color = \"red\", linewidth = 0.5) +\n",
    "  geom_vline(xintercept=q.mn$valm[1],color = col.v.gen[1], linewidth = 0.5) +\n",
    "  stat_function(fun = dnorm, args = list(mean = mu.0, sd = v.sd),\n",
    "                xlim = c(x.mn,q.mn$valm[1]), color = \"grey\", alpha = 0.3, geom = \"area\")\n",
    "\n",
    "suppressWarnings(grid.arrange(plt.h.1,plt.h.2,nrow = 2,\n",
    "                              top=textGrob(\"Distributional information\",gp=gpar(fontsize=15,col=\"blue\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c0b7d-049f-4663-8be3-ca20175461b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:brown\">Example of evidence evaluation for a hypothesis test</span>\n",
    "\n",
    "We continue with our example to motivate the use of statistics with known distributions to compare the evidence from the sample information and the reference value.\n",
    "\n",
    "In general, a measure of this distance between the data and the reference value will be obtained from a statistic for the test that incorporates information on the variability of the data (the [second step](#Step2) in our general procedure). \n",
    "\n",
    "It will be similar to the statistics we used for the computation of confidence intervals, where we also wished to incorporate variability information into our estimates. These statistics, if they are evaluated assuming that $H_0$ is true, should take small values when our sample is compatible with this null hypothesis, and large values when it is not compatible with it.\n",
    "\n",
    "The distribution of these statistics will allow us to include probability values as a measure for this distance, as part of a [third step](#Step3) in our procedure we will define below. These probabilities will be used to evaluate the magnitude of the errors associated to this procedure. Due to the random nature of our sample, it will always be possible to make a mistake when providing an answer for a hypothesis test, but we would like to design a procedure where these mistakes take place with low probability.\n",
    "\n",
    "Before we define a formal procedure to conduct this evaluation of the evidence, we will present in the following cells examples to illustrate the different aspects involved in this evaluation, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a3814f-9af8-4ff3-b96c-d94b1cfd85f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:brown\">Comparing the evidence and the reference value</span>\n",
    "\n",
    "We have already discussed that having information about distribution properties for our estimator can be very useful to reach a conclusion for a hypothesis test. We obtain this information by selecting an appropriate <span style=\"color:brown\">test statistic</span> for our parameter, given some reasonable assumptions on our data.\n",
    "\n",
    "This statistic should satisfy the following conditions:\n",
    "- It should incorporate data from our sample estimate for the parameter of interest, and the value of this parameter.\n",
    "- It should also incorporate variability information, to provide a value in a scale that can be interpreted to determine when these values are small or large.\n",
    "- And it should follow a known distribution, independent of the value of the parameter, so that we can use probability information to define some critical value that will determine when to reject $H_0$.\n",
    "\n",
    "These characteristics are similar to the ones we considered in Lesson 1 for the choice of a statistic to construct confidence intervals. In fact, we will use in our hypothesis testing procedure the same statistics we introduced in that lesson.\n",
    "\n",
    "As an example to illustrate the procedure we wish to define, we will continue assuming that our hypothesis test of interest is\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "H_0 & : & \\mu \\leq \\mu_0 \\\\\n",
    "H_1 & : & \\mu > \\mu_0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "To compute the distance between the sample data, in particular $\\bar x$, and the reference value $\\mu_0$ we need to select a statistic. If we assume that the CLT applies to our sample (if it is large enough), we define our <span style=\"color:brown\">test statistic</span> as\n",
    "\n",
    "$$\n",
    "T \\equiv \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\sim_{\\scriptsize \\text{approx.}} N(0,1) ,\n",
    "$$\n",
    "\n",
    "which we already used in Lesson 1, as in both cases we would like to define which values of the parameter are extreme ones, as opposed to values that are reasonable, given a certain distribution and the sample value.\n",
    "\n",
    "To evaluate this statistic $T$ for our sample values, we need to assign a value to our parameter, $\\mu$. As we wish to compare the evidence from the sample with our null hypothesis, we will use as a value for our parameter the reference value used to define this null hypothesis, $\\mu_0$ in our example. That is, we will assume that $H_0$ is true when we evaluate the test statistic for our sample.\n",
    "\n",
    "In this case, we compute the value of our test statistic as\n",
    "\n",
    "$$\n",
    "t_0 = \\frac{\\bar x - \\mu_0}{s/\\sqrt{n}} \n",
    "$$\n",
    "\n",
    "and this value can be compared with values from a standard normal distribution to determine if it is large or small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d98e4-23ee-4b2f-a4be-df890d3ef636",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "##### <span style=\"color:blue\">Numerical example of evidence evaluation (iii)</span>\n",
    "\n",
    "The following cell computes the values of the test statistic for the samples we generated in our example, assuming that the parameter of interest is the population mean and the samples we have collected are large enough to support the application of the CLT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3d2b0-347f-41d0-b8eb-be1c193fb5c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: Values of the test statistic\n",
    "\n",
    "## Computing the values of the test statistic\n",
    "\n",
    "q.mn$t = (q.mn$valm - mu.0)/(q.mn$vals/sqrt(smp.sz))\n",
    "\n",
    "## Printing these values\n",
    "\n",
    "q.mn.v = data.frame(round(c(q.mn$t),3))\n",
    "\n",
    "Data.hux.t <-\n",
    "  hux(q.mn.v) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "r.nm = \" \"\n",
    "for (i in 1:nrow(q.mn)) {\n",
    "    r.nm = c(r.nm,sprintf(\"Sample %2.0f\",i))\n",
    "}\n",
    "r.nm = c(r.nm)\n",
    "rownames(Data.hux.t) <- r.nm\n",
    "colnames(Data.hux.t) <- c(\"T values\")\n",
    "table_prnt(Data.hux.t[-1,],\"Test statistic values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a191a-ee0c-40c1-bcc2-7cb3b18a907c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Answer the following questions:</span>\n",
    "- <span style=\"color:green\">Which of the preceding values would lead you to reject $H_0$</span>\n",
    "- <span style=\"color:green\">How would you define which are significantly large values of the statistic?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65877c7-a0cb-48f0-b6ad-e5850c64e593",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<a id='Step3'></a>\n",
    "\n",
    "### <span style=\"color:brown\">Step 3. Evaluating the evidence based on test statistic values</span>\n",
    "\n",
    "The remaining step in our procedure to conduct a hypothesis test consists on comparing the value of our test statistic to some <span style=\"color:brown;\">critical value,</span> which will define when our statistic should lead us to reject $H_0$ and when that would not be the case. That is, we will transform our scale of distances associated to the value of our statistic, a continuous scale of values, to a zero/one result that will tell us when to reject/fail to reject our null hypothesis. And we will do this by defining a critical value selected to provide some control over the errors associated to our procedure.\n",
    "\n",
    "We start with the value of the distance between our data and the null hypothesis that we have obtained from our test statistic. This distance can be measured by using two scales:\n",
    "\n",
    "- In our example, we may work with the value of the statistic $T$ for our sample when $\\mu = \\mu_0$, and determine if it is reasonably close to 0. That is, we determine if the true value $\\mu$, approximated by $\\bar x$, is close to $\\mu_0$. We will base our decision on the values of a $N(0,1)$ distribution, the distribution of our statistic, comparing them to the value of\n",
    "\n",
    "$$\n",
    "t_0 = \\frac{\\bar x - \\mu_0}{s/\\sqrt{n}} ,\n",
    "$$\n",
    "\n",
    "   where $\\bar x$ denotes the sample mean and $s$ is the sample quasi-standard deviation.\n",
    "\n",
    "- Or we can compute the probability of observing the value $t_0$, or values that are even further from the null hypothesis (the center of our distribution) than this value, under a $N(0,1)$ distribution. We call this probability the <span style=\"color:brown\">p-value</span> of our statistic for our sample. This probability is a measure of how close our data is to $H_0$ (how close $\\mu$ is to $\\mu_0$), and it has the advantage of having a scale that is easy to interpret.\n",
    "\n",
    "  In our example we would compute our p-value as\n",
    "\n",
    "$$\n",
    "\\mbox{p-value} = \\Pr (T > t) = \\Pr \\left( Z > \\frac{\\bar x - \\mu_0}{s/\\sqrt{n}} \\right) .\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b626bd-0794-4de2-baf3-6f9e434ae9a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "##### <span style=\"color:blue\">Numerical example of evidence evaluation (iv)</span>\n",
    "\n",
    "In the following cell we indicate the p-values for our reference samples, and we represent the values of the distances obtained using the two preceding formulas, values of the test statistic and p-values, as well as the histograms corresponding to the sample means for a large collection of samples.\n",
    "\n",
    "Note that in the case of the values of $T$, the resulting histogram is approximately normal, while for the p-values we have a histogram that should correspond approximately to a uniform distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fef516-67da-40d5-97a1-8dbb2cada61a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: Values obtained from different samples\n",
    "\n",
    "## Computing the p-values\n",
    "\n",
    "q.mn$pv = pnorm(q.mn$t,lower.tail = FALSE)\n",
    "\n",
    "## Printing these values\n",
    "\n",
    "q.mn.p = data.frame(round(c(q.mn$pv),3))\n",
    "\n",
    "Data.hux.p <-\n",
    "  hux(q.mn.p) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "r.nm = \" \"\n",
    "for (i in 1:nrow(q.mn)) {\n",
    "    r.nm = c(r.nm,sprintf(\"Sample %2.0f\",i))\n",
    "}\n",
    "r.nm = c(r.nm)\n",
    "rownames(Data.hux.p) <- r.nm\n",
    "colnames(Data.hux.p) <- c(\"P values\")\n",
    "table_prnt(Data.hux.p[-1,],\"P values for the test\")\n",
    "\n",
    "## Distances based on the value of the statistic\n",
    "\n",
    "t.s.mn = data.frame(val = (s.mn$vm - mu.0)/(s.mn$vs/sqrt(smp.sz)))\n",
    "t.smp0.mn = (smp0.mn - mu.0)/(smp0.sd/sqrt(smp.sz))\n",
    "t.q.mn = (s.mn$vm[st.ix] - mu.0)/(s.mn$vs[st.ix]/sqrt(smp.sz))\n",
    "\n",
    "## Histogram for test statistic values\n",
    "\n",
    "n.bins = 20\n",
    "\n",
    "plt.h.1 = t.s.mn %>% ggplot(aes(x=val)) + geom_histogram(bins = n.bins) +\n",
    "  ggtitle(\"Histogram of statistic values\") +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=0,color = \"red\", linewidth = 0.5) +\n",
    "  geom_vline(xintercept=t.smp0.mn,color = \"black\", linewidth = 0.5)\n",
    "\n",
    "for (i in 1:length(q.val)) {\n",
    "    plt.h.1 = plt.h.1 + geom_vline(xintercept=t.q.mn[i],color = col.v.gen[i], linewidth = 0.5)\n",
    "}\n",
    "\n",
    "## Histogram based on the value of the probability (p-values)\n",
    "\n",
    "p.s.mn = data.frame(val = pnorm(t.s.mn$val, lower.tail = FALSE))\n",
    "p.smp0.mn = pnorm(t.smp0.mn, lower.tail = FALSE)\n",
    "p.q.mn = pnorm(t.q.mn, lower.tail = FALSE)\n",
    "\n",
    "plt.h.2 = p.s.mn %>% ggplot(aes(x=val)) + geom_histogram(bins = n.bins) +\n",
    "  ggtitle(\"Histogram of p-values\") +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=0.5,color = \"red\", linewidth = 0.5) +\n",
    "  geom_vline(xintercept=p.smp0.mn,color = \"black\", linewidth = 0.5)\n",
    "\n",
    "for (i in 1:length(q.val)) {\n",
    "    plt.h.2 = plt.h.2 + geom_vline(xintercept=p.q.mn[i],color = col.v.gen[i], linewidth = 0.5)\n",
    "}\n",
    "\n",
    "suppressWarnings(grid.arrange(plt.h.1,plt.h.2,nrow = 2,\n",
    "                              top=textGrob(\"Distances to H0 from different samples\",gp=gpar(fontsize=15,col=\"blue\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85881e7-46bd-4dbb-bd40-bc8b469b1868",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:brown\">Errors associated with a hypothesis testing procedure</span>\n",
    "\n",
    "Our measures of the distance between our data and the reference value in the hypothesis test, $\\mu_0$, must be compared to some value that will determine when to accept (fail to reject) or reject $H_0$. This threshold value, our <span style=\"color:brown\">critical value,</span> will transform our continous scale of distances into an accept/reject decision about the hypotheses in the test.\n",
    "\n",
    "Our choice of this threshold value will be based on the errors associated to our decision to accept/reject $H_0$. We will base our definition on the errors related to $H_0$, as the definition of $H_0$ is usually given in a manner that is easier to analyze from a formal point of view.\n",
    "\n",
    "Any reasonable procedure we might define will give rise to errors in some cases, due to the uncertainty in the information available from our sample. To define these errors in a more precise manner, and to understand their sources and relationships, we will compare what we do not know but we would like to approximate, that is, wether the value of our parameter satisfies the condition in $H_0$ or not, and the decision we make to reject $H_0$ or not. In the following table we present all four possible comparisons and outcomes associated to these two situations:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc|cc}\n",
    " & & \\text{Our decision} & \\\\\n",
    " & & \\text{Do not reject } H_0 & \\text{Reject } H_0 \\\\\n",
    "\\hline\n",
    "\\text{True situation} & H_0 \\text{ is correct} & \\text{Ok} & \\text{Type I error} \\\\\n",
    " & H_0 \\text{ is not correct} & \\text{Type II error} & \\text{Ok}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "In this table we identify two possible errors in the outcome of a hypothesis test, that we will identify as:\n",
    "- A <span style=\"color:brown\">type I error</span>, when we conclude from the evidence that $H_0$ should be rejected, but the (unknown) population value satisfies $H_0$.\n",
    "- A <span style=\"color:brown\">type II error</span>, when we conclude from the evidence that $H_0$ should not be rejected, but the (unknown) population value satisfies $H_1$.\n",
    "\n",
    "In a practical case we cannot know if we have made one of these errors or not, but we would like to control the probability of making them. We will use the following notation\n",
    "\n",
    "$$\n",
    "\\alpha = \\Pr(\\text{making a type I error}) , \\qquad \\beta = \\Pr(\\text{making a type II error})\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is known as the <span style=\"color:brown\">significance level</span> of the test, while $1 - \\beta$ denotes the <span style=\"color:brown\">power</span> of the test. We wish to define and use hypothesis tests with low values of $\\alpha$ and high values of $1 - \\beta$, that is, with low error probabilities.\n",
    "\n",
    "These two values are related in the sense that to reduce the value of $\\alpha$ we must also reduce $1 - \\beta$ and increase $\\beta$. For example, if we set a threshold for the values of the statistic beyond which we would reject $H_0$ as a very extreme (large in our example) value, then the probability of a Type I error will be very low, but the probability of a type II error will be very large. And the opposite situation would apply if we were to set this threshold at a very low value.\n",
    "\n",
    "The usual compromise between these two values consists on fixing the value of $\\alpha$ to a reasonable quantity, and to accept the value of $\\beta$ that will result from this choice, for a given test and its associated test statistic. The motivation for this compromise is based on the fact that it is easier to define $\\alpha$ for one relevant value of the parameter, the reference value $\\theta_0$, while the value of $\\beta$ will depend on the true value of the parameter under $H_1$, and there are many possible values of $\\theta$ in this region \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f0635-44db-4475-b8e1-1acd8719e90d",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:brown\">Using the probabilities of the errors to define critical values for a test</span>  \n",
    "\n",
    "Based on either the value of the test statistic $t_0$ or the p-value for our test, we will select a <span style=\"color:brown\">critical value</span> for these quantities, and we will reject $H_0$ whenever we are beyond this critical value.\n",
    "\n",
    "In both cases, this value will be selected to ensure that the probability of a type I error is equal to a <span style=\"color:brown\">significance level</span> that we will specify. We will denote the significance level as $\\alpha$, the same notation as the probability of a type I error, as both values coincide.\n",
    "\n",
    "Our choice of a critical value will depend on the measure we wish to use:\n",
    "\n",
    "- If we work with the value of the test statistic, assuming that the parameter is equal to the reference value, $t_0$, we will define the critical value to ensure that the type I error has a probability $\\alpha$ (the significance level) of happening. If we denote a r.v. with the distribution of our statisticby $T$ and our critical value as $\\text{cv}$, for the example we are considering this probability is given by\n",
    "\n",
    "$$\n",
    "\\Pr(\\text{type I error}) = \\Pr( T > \\text{cv} )\n",
    "$$\n",
    "\n",
    "  and if we impose the condition that the error has to have a probability equal to the significance level, we obtain\n",
    "\n",
    "$$\n",
    "\\Pr( T_0 > \\text{cv} ) = \\alpha \\quad \\Rightarrow \\quad \\text{cv} = z_{\\alpha} ,\n",
    "$$\n",
    "\n",
    "  that is, the critical value is the $\\alpha$ quantile for the distribution of the test statistic, a standard normal distribution in this case. The value $T_0$ denotes the test statistic defined for the value of the parameter equal to its reference value, $\\mu = \\mu_0$ in our example.\n",
    "\n",
    "  In our example, we would reject $H_0$ if $t_0 > z_\\alpha$, as this choice ensures that if $H_0$ is true, the error associated to rejecting $H_0$ (a type I error) will be equal to $\\alpha$.\n",
    "  \n",
    "- If we work with p-values, we have that\n",
    "\n",
    "$$\n",
    "\\text{p-value} = \\Pr( T > t_0 )\n",
    "$$\n",
    "\n",
    "  and we will reject $H_0$ when $\\text{p-value} < \\alpha$. This choice of a critical value for the p-value implies that the condition we use to reject $H_0$ satisfies\n",
    "\n",
    "$$\n",
    "\\text{p-value} = \\Pr ( T > t_0 ) \\leq \\alpha = \\Pr( T_0 > z_{\\alpha} ) \\Rightarrow t_0 \\leq z_{\\alpha} \n",
    "$$\n",
    "\n",
    "  the same condition as before. As a consequence, the probability of a type I error is again equal to $\\alpha$.\n",
    "\n",
    "  Note that we reject $H_0$ when the $\\text{p-value}$ is small, as it is a measure of the compatibility between the information in our sample, and the reference value of the parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f45e39-18e2-4cfa-bbd5-827935c80349",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Answer the following questions:</span>\n",
    "- <span style=\"color:green\">Comment if the value of the power of a test, $1 - \\beta$, should be a small value.</span>\n",
    "- <span style=\"color:green\">Can the value of the power of a test $1 - \\beta$ be equal to the significance level of the test $\\alpha$? Discuss.</span>\n",
    "- <span style=\"color:green\">Comment what happens to the significance level of a test when the sample size increases. How would the power of the test change with the sample size?</span>\n",
    "- <span style=\"color:green\">Consider a test to determine if a certain medical diagnostic has detected some serious condition, where the null hypothesis is that the treatment provides no indication of that condition. Indicate the errors for this test. Which of the two error probabilities would be more relevant?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cd6fa2-71a4-400c-b6c6-93007bdcc522",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "##### <span style=\"color:blue\">Numerical example of evidence evaluation (v)</span>\n",
    "\n",
    "The following cell shows the values of the test statistic, its p-values and the critical values for the statistic and for the p-values (the significance level), for the example we have been studying up to this point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02afea-29c6-4846-acfd-f64715fe889e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: Conclusions\n",
    "\n",
    "## Computing the critical value\n",
    "\n",
    "sig.lvl = 0.05\n",
    "crit.val = qnorm(sig.lvl,lower.tail = FALSE)\n",
    "\n",
    "## Printing these values\n",
    "\n",
    "q.col.1 = round(c(q.mn$t,crit.val),3)\n",
    "q.col.2 = round(c(q.mn$pv,sig.lvl),3)\n",
    "q.mn.p1 = data.frame(cbind(q.col.1,q.col.2))\n",
    "\n",
    "Data.hux.p1 <-\n",
    "  hux(q.mn.p1) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "r.nm = \" \"\n",
    "for (i in 1:nrow(q.mn)) {\n",
    "    r.nm = c(r.nm,sprintf(\"Sample %2.0f\",i))\n",
    "}\n",
    "r.nm = c(r.nm,\"Critical values\")\n",
    "rownames(Data.hux.p1) <- r.nm\n",
    "colnames(Data.hux.p1) <- c(\"Test values\",\"P values\")\n",
    "table_prnt(Data.hux.p1[-1,],\"Statistic and p values for the test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb2a77-fed8-46b2-b4e8-d9ccd6074d3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*An industrial production line is supposed to fill out containers with a substance to a target weight of 16 grams. An excessive over- or under-weight are considered to be serious problems and should lead to the suspension and recalibration of the production line. A quality control inspector selects a sample of forty containers, based on which she is supposed to decide whether the production line should be stopped or not.*\n",
    "\n",
    "*If this sample yields a mean weight of $16.31$ grams and a quasi-variance of $0.82$ grams${}^2$, which action should the inspector take at a 5% significance level?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e20d4b-4df1-4896-af49-b27547b2191b",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "For the population of packages produced in this line, we define the continuous random variable $X =$ \"fill weight of a container\".\n",
    "\n",
    "We will base our decision on the operation of the line in the results of a hypothesis test on the mean of the population $\\mu_X$, for a significance level $\\alpha = 0.05.$ Our null hypothesis will be that the population mean is equal to the desired weight value, $H_0 : \\mu_X = 16$, as both an excess and a defect in the weight are considered serious problems.\n",
    "\n",
    "1. The hypotheses of the test will be\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "   H_0 & : & \\mu_X = 16 = \\mu_0 \\\\\n",
    "   H_1 & : & \\mu_X \\not= 16\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "2. The statistic for this test, as we study a population mean from a large sample ($n = 40$), is\n",
    "\n",
    "$$\n",
    "T = \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\sim_{\\scriptsize\\text{approx.}} N(0,1)\n",
    "$$\n",
    "\n",
    "For the sample values and the reference value used to define the null hypothesis, the test statistic takes the value:\n",
    "\n",
    "$$\n",
    "t_0 = \\frac{16.31 - 16}{\\sqrt{0.82/40}} = 2.165\n",
    "$$\n",
    "\n",
    "3. We may proceed by computing the critical region of the test, or the p-value of this test.\n",
    "\n",
    "   The critical value corresponding to a significance level $\\alpha = 0.05$ will be $z_{\\alpha/2} = 1.96$, and the critical region will be\n",
    "\n",
    "$$\n",
    "\\text{RR}_{0.05} = \\{ (x_1, \\ldots , x_n ) | \\{ t_0 < -1.96 \\} \\cup \\{ t_0 > 1.96 \\} \\}\n",
    "$$\n",
    "\n",
    "For the p-value, we have\n",
    "\n",
    "$$\n",
    "\\text{p-value} = 2 \\Pr \\left( Z > | t_0 | \\right) = 2 \\Pr (Z > 2.165 ) = 0.0304\n",
    "$$\n",
    "\n",
    "4. From the preceding values, as $t_0 = 2.165 > 1.96$, the sample lies in the critical region and we reject $H_0$, that is, we can state with high certainty that the containers have an average weight different from 16 grams. We would reach the same conclusion using the p-value, as $\\text{p-value} = 0.0304 < 0.05$. Thus, we would reject the null hypothesis for any significance level larger than 3\\%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5969fa0c-de9b-404b-b1ca-05a57aea027a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### <span style=\"color:brown;\">Steps to conduct a hypothesis testing procedure</span>\n",
    "\n",
    "The following steps summarize the procedure to conduct a hypothesis test, adapted to the particular case we have been using before.\n",
    "\n",
    "<span style=\"color:brown;\">· Step 0.</span> Identify the parameter of interest. Assume in our case that we wish to conduct a test for the population mean.\n",
    "\n",
    "  Select the reference value for the test, $\\mu_0$. Also, select a significance level $\\alpha$ for the test.\n",
    "\n",
    "<span style=\"color:brown;\">· Step 1.</span> Define the null and alternative hypotheses. Assume again that for this example we wish to test the following hypotheses:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "H_0 & : & \\mu \\leq \\mu_0 \\\\\n",
    "H_1 & : & \\mu > \\mu_0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<span style=\"color:brown;\">· Step 2.</span> Identify the test statistic to use and its distribution, from the choice of parameter to study and the properties of the sample and the population. If we assume that $n$ is large enough, we have\n",
    "  \n",
    "$$\n",
    "T = \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\sim_{\\scriptsize\\text{approx.}} N(0,1)\n",
    "$$\n",
    "\n",
    "Compute the required statistics from the sample; in this case we will need the values of $\\bar x$, $s$ and $n$. From these values and the reference value for $\\mu$, compute the value of the test statistic,\n",
    "\n",
    "$$\n",
    "t_0 = \\frac{\\bar x - \\mu_0}{s/\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "<span style=\"color:brown;\">· Step 3.</span> Compute the critical value and/or the p-value for this test, as\n",
    "  \n",
    "$$\n",
    "\\text{cv} = z_{\\alpha} , \\qquad \\text{p-value} = \\Pr( Z > t )\n",
    "$$\n",
    "\n",
    "<span style=\"color:brown;\">· Step 4.</span> Reach a conclusion for the test, by checking either if $t > \\text{cv}$ or if $\\text{p-value} < \\alpha$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c86ac9f-4322-45ce-bb7b-491207b1979a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "##### <span style=\"color:blue;\">An illustration of the general hypothesis testing procedure</span>\n",
    "\n",
    "In the following cell we present the numerical results corresponding to the preceding steps, obtained from a random subsample of the data we have selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207264a-a9c9-4181-a3dc-a0f5550bb0c4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: a simple example\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "sig.lvl = 0.05\n",
    "smp.sz.prop = 0.2\n",
    "q.val = 0.4 + 0.2*runif(1)\n",
    "\n",
    "## General parameters\n",
    "\n",
    "smp.sz = max(30,floor(smp.sz.prop*smp0.sz))\n",
    "\n",
    "## Generate our sample and the reference value\n",
    "\n",
    "f.dsp = 1 + 1.5*runif(1)\n",
    "\n",
    "v.smp = sample(data.sel$Val, smp.sz, replace = FALSE)\n",
    "mu.0 = mean(v.smp) - f.dsp*sd(v.smp)/sqrt(smp.sz)\n",
    "\n",
    "## Display de values of the general parameters\n",
    "\n",
    "dat.a = data.frame(round(c(mu.0,sig.lvl),2))\n",
    "Data.hux.a <-\n",
    "  hux(dat.a) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "rownames(Data.hux.a) <- c(\"\",\"Reference value mu0\",\"Significance level\")\n",
    "colnames(Data.hux.a) <- c(\"Values\")\n",
    "table_prnt(Data.hux.a[-1,],\"Step 3 - Ref values for the test\")\n",
    "\n",
    "## Obtain the summary values for the sample\n",
    "\n",
    "sv.smp = sum(v.smp)\n",
    "ss.smp = sum(v.smp^2)\n",
    "mn.smp = mean(v.smp)\n",
    "s.smp = sd(v.smp)\n",
    "\n",
    "## Print summary values from our sample\n",
    "\n",
    "dat.b = data.frame(round(c(smp.sz, sv.smp, ss.smp, mn.smp, s.smp),3))\n",
    "Data.hux.b <-\n",
    "  hux(dat.b) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "rownames(Data.hux.b) = c(\"\",\"Sample size\",\"Sum of values\",\"Sum of squares\",\"Sample mean\",\"Sample quasi-std dev\")\n",
    "colnames(Data.hux.b) = c(\"Values\")\n",
    "table_prnt(Data.hux.b[-1,],\"Step 5 - sample values\")\n",
    "\n",
    "## Compute the value of the statistic for the data in the sample and the given reference value\n",
    "\n",
    "t.val = (mn.smp - mu.0)/(s.smp/sqrt(smp.sz))\n",
    "\n",
    "dat.c = data.frame(round(t.val,3))\n",
    "Data.hux.c <-\n",
    "  hux(dat.c) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "rownames(Data.hux.c) = c(\"\",\"Test statistic\")\n",
    "colnames(Data.hux.c) = c(\"Value\")\n",
    "table_prnt(Data.hux.c[-1,],\"Step 6 - test statistic\")\n",
    "\n",
    "## Compute and print the critical value and the p-value\n",
    "\n",
    "v.crit = qnorm(sig.lvl, lower.tail = FALSE)\n",
    "p.val = pnorm(t.val, lower.tail = FALSE)\n",
    "\n",
    "dat.d = data.frame(round(c(v.crit,p.val),3))\n",
    "Data.hux.d <-\n",
    "  hux(dat.d) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "rownames(Data.hux.d) <- c(\"\",\"Critical value for the test\",\"P-value of the test\")\n",
    "colnames(Data.hux.d) <- c(\"Values\")\n",
    "table_prnt(Data.hux.d[-1,],\"Step 7 - Critical value and p-value\")\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "if (p.val < sig.lvl) c.txt = \"Reject H_0\" else c.txt = \"Fail to reject H_0\"\n",
    "    \n",
    "dat.e = data.frame(c.txt)\n",
    "Data.hux.e <-\n",
    "  hux(dat.e) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "rownames(Data.hux.e) <- c(\"\",\"Conclusion for the test  \")\n",
    "colnames(Data.hux.e) <- c(\" \")\n",
    "table_prnt(Data.hux.e[-1,],\"Step 8 - Conclusion\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf2cf8-8d8c-497b-9d2b-816c9c754bca",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:brown\">Summary of a hypothesis testing procedure</span>\n",
    "\n",
    "Summarizing the contents of the preceding cells, in order to carry out a hypothesis testing process we need to:\n",
    "\n",
    "<span style=\"color:brown\">· Step 1.</span> Define our null and alternative hypotheses. We will mostly consider hypotheses defined as inequalities relating the parameter and a reference value, which we will call <span style=\"color:brown\">one-sided</span> hypotheses,\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "H_0 & : & \\mu \\geq \\mu_0 \\\\\n",
    "H_1 & : & \\mu < \\mu_0\n",
    "\\end{array} \\qquad \\mbox{or} \\qquad \n",
    "\\begin{array}{rcl}\n",
    "H_0 & : & \\mu \\leq \\mu_0 \\\\\n",
    "H_1 & : & \\mu > \\mu_0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "In some special cases (mostly theoretical ones) we may consider <span style=\"color:brown\">two-sided</span> hypotheses, based on equality relationships of the form\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "H_0 & : & \\mu = \\mu_0 \\\\\n",
    "H_1 & : & \\mu \\not= \\mu_0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<span style=\"color:brown\">· Step 2.</span> Select a test statistic with a known distribution, to evaluate the distance between our data and the reference value. These statistics will depend on the parameter to compare, the properties of the data and the sample characteristics. We will consider statistics similar to the ones introduced in Lesson 1.\n",
    "\n",
    "Compute the value of the test statistic under the null hypothesis, using our reference value $\\mu_0$ as the value of the parameter.\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\\begin{array}{lllccc}\n",
    "\\text{Parameter} & \\text{Estimator} & \\text{Assumptions} & \\text{Statistic} & \\text{Distribution} & \\text{Statistic under } H_0 \\\\\n",
    "\\hline\n",
    "\\text{Mean } \\mu & \\text{Sample mean } \\bar X & \\text{Large sample size} & \\frac{\\bar X - \\mu}{\\frac{S}{\\sqrt{n}}} & N(0,1) & t_0 = \\frac{\\bar x - \\mu_0}{\\frac{s}{\\sqrt{n}}} \\\\\n",
    "& & \\text{Normal data} & \\frac{\\bar X - \\mu}{\\frac{S}{\\sqrt{n}}} & t_{n-1} & t_0 = \\frac{\\bar x - \\mu_0}{\\frac{s}{\\sqrt{n}}} \\\\\n",
    "\\text{Proportion } p & \\text{Sample proportion } \\hat P & \\text{Large sample size} & \\frac{\\hat P - p}{\\sqrt{\\frac{p(1 - p)}{n}}} & N(0,1) & t_0 = \\frac{\\hat p - p_0}{\\sqrt{\\frac{p(1 - p)}{n}}} \\\\\n",
    "\\text{Variance } \\sigma^2 & \\text{Sample quasivariance } S^2 & \\text{Normal data} & \\frac{(n-1)S^2}{\\sigma^2} & \\chi^2_{n-1} & t_0 = \\frac{(n-1)s^2}{\\sigma_0^2}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<span style=\"color:brown\">· Step 3.</span> If you wish to conduct the test in the space of probabilities, compute a p-value for the test and compare it with the significance level. Otherwise, if you work with the value of the test statistic, compute a critical value as a quantile from the distribution of the test statistic, and compare these values. \n",
    "\n",
    "The following table presents the conditions under which you should reject the null hypothesis, for a certain significance level $\\alpha$.\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\\begin{array}{cccc}\n",
    "H_1 & \\text{Critical value} & \\text{Rejection region} & \\text{P-value def} \\\\\n",
    "\\hline\n",
    "\\mu > \\mu_0 & z_{\\alpha},t_{n-1;\\alpha} & \\{ t > \\text{cv} \\} & \\Pr(T > t) \\\\\n",
    "\\mu < \\mu_0 & -z_{\\alpha},-t_{n-1;\\alpha} & \\{ t < \\text{cv} \\} & \\Pr(T < t) \\\\\n",
    "\\mu \\not= \\mu_0 & z_{\\alpha/2},t_{n-1;\\alpha/2} & \\{ t < -\\text{cv} \\}\\cup \\{ t > \\text{cv} \\} & \\min(1,2\\Pr(T > t)) \\\\\n",
    "\\sigma^2 > \\sigma_0^2 & \\chi^2_{n-1;\\alpha} & \\{ t > \\mbox{cv} \\} & \\Pr(T > t) \\\\\n",
    "\\sigma^2 < \\sigma_0^2 & \\chi^2_{n-1;1-\\alpha} & \\{ t < \\mbox{cv} \\} & \\Pr(T < t) \\\\\n",
    "\\sigma^2 \\not= \\sigma_0^2 & \\chi^2_{n-1;\\alpha/2},\\chi^2_{n-1;1-\\alpha/2} & \\{ t < \\chi^2_{n-1;1-\\alpha} \\}\\cup \\{ t > \\chi^2_{n-1;\\alpha} \\} & \\min(1,2\\Pr(T > t))\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Comments on this table:\n",
    "\n",
    "  - The symbol $t$ represents the value of the test statistic for the available sample, under the null hypothesis.\n",
    "  - The symbol $\\mbox{cv}$ represents the critical value as specified in the corresponding column of the table.\n",
    "  - When two critical values from different distributions are indicated, you should use the one corresponding to the assumptions reasonable for your test.\n",
    "  - For the p-value you always reject when $\\mbox{p-value} < \\alpha$.\n",
    "  - All quantiles are right-quantiles, for example, $\\Pr(Z > z_\\alpha ) = \\alpha$.\n",
    "  - For tests on the proportion, just replace $\\mu$ with $p$ in the preceding formulas and use the quantiles from a Normal distribution.\n",
    "\n",
    "<span style=\"color:brown\">· Step 4.</span> Interpret and explain your conclusion for the data you have collected and for the definition of the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a4d97-fa44-483b-9e86-13b3e21dc85c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Answer the following questions, for some reasonable significance level:</span>\n",
    "- <span style=\"color:green\">For a given sample with $\\bar x = 12.4$, $s = 5.8$ and $n = 36$, conduct a test of the form $H_1 : \\mu < \\mu_0 = 14$ and indicate your conclusion.</span>\n",
    "- <span style=\"color:green\">Conduct a test of the form $H_0 : p = p_0 = 0.25$ based on a sample with $\\hat p = 0.2$ and $n = 100$.Indicate your conclusion.</span>\n",
    "- <span style=\"color:green\">You have a sample of normal observations that satisfies $\\bar x = -3.4$, $s = 1.2$ and $n = 16$. Conduct a test of the form $H_1 : \\mu > \\mu_0 = -4$ and indicate your conclusion.</span>\n",
    "- <span style=\"color:green\">A sample of normal observations satisfies $s = 4$ and $n = 20$. Conduct a test of the form $H_0 : \\sigma \\leq \\sigma_0 = 3$ and indicate your conclusion.</span>\n",
    "- <span style=\"color:green\">Comment the following statement: \"For a given sample and the same definition of a test, conducting a two-sided test is equivalent to conducting the equivalent one-sided test but replacing the significance level by a value twice as large\".</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1006f58-5b65-4924-b96f-437d56225934",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*The manufacturer of a certain precision component is required to ensure that the variability (standard deviation) in one of the characteristics of a given component does not exceed $0.2$ mm. The manufacturer has collected a sample of 12 measurements from different components, with values for the characteristic given in the following table:*\n",
    "\n",
    "$$\n",
    "\\begin{array}{cccccccccccc}\n",
    "13.13 & 13.29 & 13.34 & 13.24 & 12.89 & 13.17 & 12.68 & 13.35 & 13.07 & 12.78 & 13.32 & 12.69\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "*The manufacturer would like to test if the information in the sample would imply that the manufacturing process is not working within the desired tolerance. Should the factory stop this process and recalibrate it?*\n",
    "\n",
    "*You may assume that the data follow a normal distribution.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d483ca1c-6d44-4023-938e-ecad9edf44a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "Let $X$ denote the random variable corresponding to the value of the characteristic of interest. We wish to conduct a hypothesis test on the value of $\\sigma_X$, or on $\\sigma_X^2$, as this second option is slightly simpler.\n",
    "\n",
    "The data we have collected in our sample yield the following values and estimates\n",
    "\n",
    "$$\n",
    "\\bar x = \\frac{\\sum_{i=1}^{12} x_i}{12} = 13.0683 , \\quad s^2 = \\frac{\\sum_{i=1}^{12} x_i - n\\bar x^2}{11} = 0.06562, \\quad n = 12\n",
    "$$\n",
    "\n",
    "1. The test of interest is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "   H_0 & : & \\sigma_X^2 \\leq 0.2^2 = \\sigma_0^2 \\\\\n",
    "   H_1 & : & \\sigma_X^2 > 0.04\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The alternative hypothesis in this case has been selected in the direction of the sample data. Its interpretation would be that we do not wish to stop the production unless we have clear evidence that the tolerance is being exceeded, when considering all the maufactured components.\n",
    "\n",
    "2. The statistic for this test, as we study a population variance from a sample with normal data, is\n",
    "\n",
    "$$\n",
    "T = \\frac{(n-1)S_x^2}{\\sigma^2} \\sim \\chi^2_{n-1}\n",
    "$$\n",
    "\n",
    "For the sample values and the reference value used to define the null hypothesis, the test statistic takes the value:\n",
    "\n",
    "$$\n",
    "t_0 = \\frac{(n-1)s^2}{\\sigma_0^2} = \\frac{11\\times 0.06562}{0.04} = 18.044\n",
    "$$\n",
    "\n",
    "3. We can proceed in one of two ways. We may compare this value $t_0$ with the relevant quantile of a chi squared distribution with eleven ($n-1$) degrees of freedom for a one-sided test, using a reasonable significance level, for example, $\\alpha = 0.05$. This critical value is $\\chi^2_{n-1;0.05} = \\chi^2_{11;0.05} = 19.675$, obtained from the table for the chi squared distribution.\n",
    "\n",
    "Alternatively, we may compute the p-value for this test using <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span>, as\n",
    "\n",
    "$$\n",
    "\\text{p-value} = \\Pr( T > t_0 ) = \\Pr (\\chi^2_{11} > 18.044 ) = 0.08057\n",
    "$$\n",
    "\n",
    "From the tables we can only obtain the approximation, $\\text{p-value} \\in [0.05;0.10]$.\n",
    "\n",
    "4. From the preceding values, as $t_0 = 18.044 < 19.675 = \\chi^2_{11;0.05}$, we cannot reject the null hypothesis at a significance level of 5\\%, that is, we cannot state with high certainty that the variability in the value of the characteristic is larger than $0.2$ mm. \n",
    "\n",
    "We reach the same conclusion using the p-value, as $\\text{p-value} = 0.08057 > 0.05 = \\alpha$. But in this case we would have rejected the null hypothesis if we would have chosen a significance level of 10\\%, for example, or in general for any significance level larger than 8\\%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6374c43-9d8f-44b1-b631-070b37e8bff4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:blue;\">Numerical application of hypothesis testing procedures</span>\n",
    "\n",
    "---\n",
    "\n",
    "In the following cells we define a group of R commands that will allow us to conduct different hypothesis tests for predefined data sets or for randomly selected data. These cells are structured as a sequence of tasks to be conducted on the data, to select it, preprocess it, apply the hypothesis testing procedure and show the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f17f02-4f1d-4553-8ca0-fce2732a623a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:blue;\">1. Define the data to be used for the example</span>\n",
    "\n",
    "In the following cell we indicate both the dataset and the variable that you would like to study. You have two options to work with this data:\n",
    "1. Conduct a test on all the data, or\n",
    "2. Conduct a test on a random subsample obtained from the data.\n",
    "\n",
    "This second case is introduced to allow for the generation of random examples of hypothesis tests. The two cases are controlled by specifying the value of a variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">smp.sz.frac</span>. If this value is set equal to 1, all the selected data are used, otherwise, a random subsample with the specified size is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430cc73-93a2-4252-adfe-b719f039edae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the data set and variable of interest\n",
    "\n",
    "f.pref = 5\n",
    "sel.col = 6\n",
    "\n",
    "## Read the data set\n",
    "\n",
    "s.pref = v.pref[f.pref,]\n",
    "Data.fr <- read.csv2(s.pref$file)\n",
    "\n",
    "## Extract variable of interest\n",
    "\n",
    "data.sel = as.data.frame(Data.fr[,sel.col])\n",
    "colnames(data.sel) = c(\"Val\")\n",
    "\n",
    "# Define the subsample you would like to use for the example (use the value 1 to specify the full sample)\n",
    "\n",
    "smp.sz.frac = 0.2\n",
    "\n",
    "## Define the variable with the data for the test\n",
    "\n",
    "smp0.sz = nrow(data.sel)\n",
    "if (smp.sz.frac == 1) {\n",
    "    smp.sz.lbl = \"No\"\n",
    "    smp.sz.2 = smp0.sz\n",
    "    v.smp.2 = data.sel\n",
    "} else {\n",
    "    smp.sz.lbl = \"Yes\"\n",
    "    smp.sz.2 = floor(smp.sz.frac*smp0.sz)\n",
    "    v.smp.2 = sample(data.sel$Val, smp.sz.2, replace = FALSE)\n",
    "}\n",
    "\n",
    "## Summary of values from the full sample and the subsample\n",
    "\n",
    "smp0.mn = mean(data.sel$Val)\n",
    "smp0.var = var(data.sel$Val)\n",
    "\n",
    "smp.sz.2 = length(v.smp.2)\n",
    "mn.smp.2 = mean(v.smp.2)\n",
    "var.smp.2 = var(v.smp.2)\n",
    "\n",
    "# Print information on the selected data\n",
    "\n",
    "descr.df = as.data.frame(c(s.pref$title,colnames(Data.fr)[sel.col],smp.sz.lbl))\n",
    "colnames(descr.df) <- c(\"Selection\")\n",
    "rownames(descr.df) <- c(\"Data set\",\"Variable\",\"Random subsample?\")\n",
    "\n",
    "Data.hux.0 <-\n",
    "  hux(descr.df) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "table_prnt(Data.hux.0[-1,],\"Selected data set and variables\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8091abb2-0105-484b-bd3e-faf4b9e8fdfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:blue;\">2. Define the type of test that you would like to conduct</span>\n",
    "\n",
    "We select the significance level of the test as the value of the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">sig.lvl</span>, at the beginning of the cell.\n",
    "\n",
    "We then specify the test we would like to carry out, by indicating:\n",
    "- The parameter on which we wish to conduct the test, in the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">ht.par</span>.\n",
    "- The assumptions we are willing to make about the test, also in the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">ht.par</span>.\n",
    "- The form of the null hypothesis of the test, as well as the reference value, in the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">ht.type</span>..\n",
    "\n",
    "The reference value is generated randomly, based on the (full) sample data. It can be introduced directly by giving a value to the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">ref.val</span> in the following cell.\n",
    "\n",
    "At the end of the cell we print a summary with all the preceding values plus some of the basis sample statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee06ce-46d0-43ab-89f4-beb58610b5da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Significance level for the test\n",
    "\n",
    "sig.lvl = 0.05\n",
    "\n",
    "# Choice of type of hypothesis test to conduct\n",
    "\n",
    "ht.par = 3         # = 1, test for the mean (CLT)\n",
    "                    # = 2, test for the mean (normal data)\n",
    "                    # = 3, test for a proportion\n",
    "                    # = 4, test for the variance\n",
    "ht.type = 2        # = 1, one-sided, left-hand test, H_1 : mu > mu_0 (for example)\n",
    "                   # = 2, one-sided, right-hand test, H_1 : mu < mu_0 (for example)\n",
    "                   # = 3, two-sided, H_1 : mu <> mu_0 (for example)\n",
    "\n",
    "# Reference value for the test\n",
    "\n",
    "if (ht.par <= 2) {\n",
    "    frac.shft = 1 + runif(1)\n",
    "    ref.val.v = smp0.mn + c(-1,1)*frac.shft*sqrt(smp0.var/smp0.sz)\n",
    "} else if (ht.par == 3) {\n",
    "    frac.shft = 1 + runif(1)\n",
    "    ref.cutoff = smp0.mn - frac.shft*sqrt(smp0.var/smp0.sz)\n",
    "    smp0.pr = mean(data.sel$Val < ref.cutoff)\n",
    "    pr.smp.2 = mean(v.smp.2 < ref.cutoff)\n",
    "    ref.val.v = smp0.pr + c(-1,1)*frac.shft*sqrt(smp0.pr*(1-smp0.pr)/smp0.sz)\n",
    "} else {\n",
    "    frac.shft = 0.75 + 0.5*runif(1)\n",
    "    ref.val.v = c(1/frac.shft,frac.shft)*smp0.var\n",
    "}\n",
    "\n",
    "## You may specify the reference value directly by giving a value to ref.val\n",
    "\n",
    "if (ht.type <= 2) {\n",
    "    ref.val = ref.val.v[ht.type]\n",
    "} else if (ht.type == 3) {\n",
    "    ref.val = ref.val.v[1+rbinom(1,1,0.5)]\n",
    "}\n",
    "\n",
    "# Output of sample data summaries and reference values\n",
    "\n",
    "df.c.1 = c(\"Test\",\" \",\" \",\" \",\"Sample\")\n",
    "df.c.2 = c(\"Population Parameter\",\"Alternative hypothesis\", \"Reference value\",\"Significance level\",\n",
    "            \"Sample size\")\n",
    "\n",
    "if (ht.par <= 2) {\n",
    "    df.c.3.1 = \"Mean\"\n",
    "    add.vals = as.data.frame(rbind(c(\" \",\"Mean\",sprintf(\"%9.3f\",mn.smp.2)),c(\" \",\"Quasivariance\",sprintf(\"%9.3f\",var.smp.2))))\n",
    "    if (ht.type == 1) df.c.3.2 = \"$$H_1 : \\\\mu > \\\\mu_0$$\" else\n",
    "        if (ht.type == 2) df.c.3.2 = \"$$H_1 : \\\\mu < \\\\mu_0$$\" else\n",
    "            df.c.3.2 = \"$$H_1 : \\\\mu \\\\not= \\\\mu_0$$\"\n",
    "} else if (ht.par == 3) {\n",
    "    df.c.3.1 = \"Proportion\"\n",
    "    add.vals = as.data.frame(rbind(c(\" \",\"Proportion\",sprintf(\"%5.3f\",pr.smp.2))))\n",
    "    if (ht.type == 1) df.c.3.2 = \"$$H_1 : p > p_0$$\" else\n",
    "        if (ht.type == 2) df.c.3.2 = \"$$H_1 : p < p_0$$\" else\n",
    "            df.c.3.2 = \"$$H_1 : p \\\\not= p_0$$\"\n",
    "} else {\n",
    "    df.c.3.1 = \"Variance\"\n",
    "    add.vals = as.data.frame(rbind(c(\" \",\"Variance\",sprintf(\"%9.3f\",var.smp.2))))\n",
    "    if (ht.type == 1) df.c.3.2 = \"$$H_1 : \\\\sigma^2 > \\\\sigma^2_0$$\" else\n",
    "        if (ht.type == 2) df.c.3.2 = \"$$H_1 : \\\\sigma^2 < \\\\sigma^2_0$$\" else\n",
    "            df.c.3.2 = \"$$H_1 : \\\\sigma^2 \\\\not= \\\\sigma^2_0$$\"\n",
    "}\n",
    "\n",
    "df.c.3 = c(df.c.3.1,df.c.3.2,sprintf(\"%9.3f\",ref.val),sprintf(\"%5.2f\",sig.lvl),sprintf(\"%5.0f\",smp.sz.2))\n",
    "\n",
    "mn.val = as.data.frame(cbind(df.c.1,df.c.2,df.c.3))\n",
    "mn.val = data.frame(Map(c,mn.val,add.vals))\n",
    "\n",
    "Data.hux <-\n",
    "  hux(mn.val) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "Data.hux = Data.hux[-1,]\n",
    "rownames(Data.hux) = NULL\n",
    "colnames(Data.hux) = NULL\n",
    "            \n",
    "table_prnt(Data.hux,\"Test and sample values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3091b17-7c89-4e59-8341-29c88d6c67f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:blue;\">3. Perform the required calculations for the test</span>\n",
    "\n",
    "The following cell presents the calculations required for the test, that is, the value of the statistic, the critical value, and the p-value of the test. The conclusion for this test is also shown at the end of the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f4a476-cd87-4c8d-b39a-164a66e97ab9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: Conducting the test and printing the results\n",
    "\n",
    "## Computing the values required for the testing procedure\n",
    "\n",
    "if (ht.par == 1) {\n",
    "    ht.val.1 = (mn.smp.2 - ref.val)/sqrt(var.smp.2/smp.sz.2)\n",
    "    if (ht.type == 1) {\n",
    "        ht.val.2 = qnorm(sig.lvl,lower.tail = FALSE)\n",
    "        ht.val.3 = pnorm(ht.val.1, lower.tail = FALSE)\n",
    "    } else if (ht.type == 2) {\n",
    "        ht.val.2 = qnorm(sig.lvl,lower.tail = TRUE)\n",
    "        ht.val.3 = pnorm(ht.val.1, lower.tail = TRUE)\n",
    "    } else {\n",
    "        ht.val.2a = qnorm(sig.lvl,lower.tail = FALSE)\n",
    "        ht.val.2b = -ht.val.2a\n",
    "        ht.val.3 = min(1,2*pnorm(abs(ht.val.1), lower.tail = FALSE))\n",
    "    }\n",
    "} else if (ht.par == 2) {\n",
    "    ht.val.1 = (mn.smp.2 - ref.val)/sqrt(var.smp.2/smp.sz.2)\n",
    "    if (ht.type == 1) {\n",
    "        ht.val.2 = qt(sig.lvl,smp.sz.2-1,lower.tail = FALSE)\n",
    "        ht.val.3 = pt(ht.val.1,smp.sz.2-1, lower.tail = FALSE)\n",
    "    } else if (ht.type == 2) {\n",
    "        ht.val.2 = qt(sig.lvl,smp.sz.2-1, lower.tail = TRUE)\n",
    "        ht.val.3 = pt(ht.val.1,smp.sz.2-1, lower.tail = TRUE)\n",
    "    } else {\n",
    "        ht.val.2a = qt(sig.lvl/2,smp.sz.2-1, lower.tail = FALSE)\n",
    "        ht.val.2b = -ht.val.2a\n",
    "        ht.val.3 = min(1,2*pt(abs(ht.val.1),smp.sz.2-1, lower.tail = FALSE))\n",
    "    }\n",
    "} else if (ht.par == 3) {\n",
    "    ht.val.1 = (pr.smp.2 - ref.val)/sqrt(ref.val*(1-ref.val)/smp.sz.2)\n",
    "    if (ht.type == 1) {\n",
    "        ht.val.2 = qnorm(sig.lvl,lower.tail = FALSE)\n",
    "        ht.val.3 = pnorm(ht.val.1, lower.tail = FALSE)\n",
    "    } else if (ht.type == 2) {\n",
    "        ht.val.2 = qnorm(sig.lvl,lower.tail = TRUE)\n",
    "        ht.val.3 = pnorm(ht.val.1, lower.tail = TRUE)\n",
    "    } else {\n",
    "        ht.val.2a = qnorm(sig.lvl/2,lower.tail = FALSE)\n",
    "        ht.val.2b = -ht.val.2a\n",
    "        ht.val.3 = min(1,2*pnorm(abs(ht.val.1), lower.tail = FALSE))\n",
    "    }\n",
    "} else {\n",
    "    ht.val.1 = (smp.sz.2-1)*var.smp.2/ref.val\n",
    "    if (ht.type == 1) {\n",
    "        ht.val.2 = qchisq(sig.lvl,smp.sz.2-1,lower.tail = FALSE)\n",
    "        ht.val.3 = pchisq(ht.val.1,smp.sz.2-1, lower.tail = FALSE)\n",
    "    } else if (ht.type == 2) {\n",
    "        ht.val.2 = qchisq(sig.lvl,smp.sz.2-1, lower.tail = TRUE)\n",
    "        ht.val.3 = pchisq(ht.val.1,smp.sz.2-1, lower.tail = TRUE)\n",
    "    } else {\n",
    "        ht.val.2a = qchisq(sig.lvl/2,smp.sz.2-1, lower.tail = FALSE)\n",
    "        ht.val.2b = qchisq(sig.lvl/2,smp.sz.2-1, lower.tail = TRUE)\n",
    "        ht.val.3a = pchisq(ht.val.1,smp.sz.2-1, lower.tail = FALSE)\n",
    "        ht.val.3b = pchisq(ht.val.1,smp.sz.2-1, lower.tail = TRUE)\n",
    "        ht.val.3 = min(1,2*min(ht.val.3a,ht.val.3b))\n",
    "    }\n",
    "}\n",
    "\n",
    "## Printing a summary of the results\n",
    "\n",
    "if (ht.val.3 < sig.lvl) ht.val.4 = \"Reject H0\" else ht.val.4 = \"Fail to reject H0\"\n",
    "\n",
    "if (ht.type <= 2) {\n",
    "    df.c.1 = c(\"Value of the test statistic\",\"Critical value\",\"P-value for the test\",\"Test result\")\n",
    "    df.c.2 = c(sprintf(\"%7.3f\",ht.val.1),sprintf(\"%7.3f\",ht.val.2), sprintf(\"%5.3f\",ht.val.3),ht.val.4)\n",
    "} else {\n",
    "    df.c.1 = c(\"Value of the test statistic\",\"Critical value 1\",\"Critical value 2\",\"P-value for the test\",\"Test result\")\n",
    "    df.c.2 = c(sprintf(\"%7.3f\",ht.val.1),sprintf(\"%7.3f\",ht.val.2b),sprintf(\"%7.3f\",ht.val.2a),sprintf(\"%5.3f\",ht.val.3),ht.val.4)\n",
    "}\n",
    "mn.val = as.data.frame(cbind(df.c.1,df.c.2))\n",
    "\n",
    "Data.hux <-\n",
    "  hux(mn.val) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "Data.hux = Data.hux[-1,]\n",
    "rownames(Data.hux) = NULL\n",
    "colnames(Data.hux) = NULL\n",
    "\n",
    "table_prnt(Data.hux,\"Test results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e77432-a4bc-4b8f-9d9f-cea007949e07",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:brown\">The errors in a hypothesis test</span>\n",
    "\n",
    "---\n",
    "\n",
    "The errors in a hypothesis test play a crucial role in the definition of the test, and also in the choice of different statistics for a given test. In the following cells we will explore in some detail the characteristics and behavior of a test with respect to these errors.\n",
    "\n",
    "As an illustration of the preceding comments, we will assume we are applying the procedure we have introduced to a test defined as \n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "H_0 & : & \\mu \\leq \\mu_0 \\\\\n",
    "H_1 & : & \\mu > \\mu_0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "An important goal is to illustrate that these errors cannot be avoided, but they can be controlled up to a point, in the case of the type II errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a215a61-60d5-4404-8424-0ec0d9d9d5a0",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Numerical example for type I errors</span>\n",
    "\n",
    "The following cell shows the values of the statistic and the p-value for different samples, indicating with a red dot the cases in which we would be making a type I error.\n",
    "\n",
    "This error is particularly relevant, as it is the one we wish to control in our design of the procedure. To study this error we have selected values of $\\mu_0$ such that $\\mu < \\mu_0$, that is, where $H_0$ is true for our example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb26914-7bef-4de1-9856-10a7da14a61a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: type I errors\n",
    "\n",
    "## Parameters for the test (can be modified)\n",
    "\n",
    "n.samples = 100\n",
    "smp.sz.prop = 0.2\n",
    "alpha = 0.1\n",
    "\n",
    "fr.dist = 0.25\n",
    "\n",
    "## Other parameters\n",
    "\n",
    "smp.sz.1 = floor(smp.sz.prop*smp0.sz)\n",
    "mu.0.1 = smp0.mn + fr.dist*smp0.sd/sqrt(smp.sz)\n",
    "t.q.1 = qnorm(alpha, lower.tail = FALSE)\n",
    "\n",
    "## Generate samples and estimates\n",
    "\n",
    "mn.smp.1 = s.smp.1 = NULL\n",
    "for (i in 1:n.samples) {\n",
    "    v.smp.1 = sample(data.sel$Val, smp.sz.1, replace = FALSE)\n",
    "    mn.smp.1 = c(mn.smp.1,mean(v.smp.1))\n",
    "    s.smp.1 = c(s.smp.1,sd(v.smp.1))\n",
    "}\n",
    "s.mn.1 = data.frame(vm = mn.smp.1, vs = s.smp.1)\n",
    "\n",
    "## Distances based on the value of the statistic and the p-value\n",
    "\n",
    "v.t.1 = (s.mn.1$vm - mu.0.1)/(s.mn.1$vs/sqrt(smp.sz.1))\n",
    "err.v.t.1 = as.numeric(v.t.1 > t.q.1) + 1\n",
    "\n",
    "t.s.mn.1 = data.frame(val = v.t.1, errv = err.v.t.1)\n",
    "v.p.1 = pnorm(v.t.1, lower.tail = FALSE)\n",
    "err.v.p.1 = as.numeric(v.p.1 < alpha) + 1\n",
    "p.s.mn.1 = data.frame(val = v.p.1, errv = err.v.p.1)\n",
    "\n",
    "plt.j.1 = t.s.mn.1 %>% ggplot(aes(x=val,y=\"\")) + geom_jitter(color=t.s.mn.1$errv) +\n",
    "  ggtitle(\"Values of test statistic\") +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=t.q.1,color = \"red\",size=0.5)\n",
    "\n",
    "plt.j.2 = p.s.mn.1 %>% ggplot(aes(x=val,y=\"\")) + geom_jitter(color=p.s.mn.1$errv) +\n",
    "  ggtitle(\"p-values\") +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=alpha,color = \"red\",size=0.5)\n",
    "\n",
    "suppressWarnings(grid.arrange(plt.j.1,plt.j.2,nrow = 2,\n",
    "                              top=textGrob(\"Distances to H0 from different samples\",gp=gpar(fontsize=15,col=\"blue\"))))\n",
    "\n",
    "## Summary of numerical values\n",
    "\n",
    "mn.val = data.frame(round(c(mu.0.1,smp0.mn,smp0.sd,alpha,t.q.1),3))\n",
    "Data.hux <-\n",
    "  hux(mn.val) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux) <- c(\"\",\"mu 0\",\"Population mean\",\"Pop std dev\",\"Significance level\",\"Critical value\")\n",
    "colnames(Data.hux) <- c(\"Values\")\n",
    "table_prnt(Data.hux[-1,],\"Values for the example\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0802b-7ac7-4b10-8df8-79a7a6948054",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Numerical example for type II errors</span>\n",
    "\n",
    "We repeat the preceding example for the case when $H_0$ is not true, that is, when we select $\\mu_0$ so that $\\mu > \\mu_0$. In the following plot we show the type II errors that we obtain for different samples, that is, we show as red dots the values corresponding to situations in which we would fail to reject the null hypothesis when we should, as $H_0$ is false in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7389ff-94c9-4754-baa0-06228f2618e2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: type I errors\n",
    "\n",
    "## Parameters for the test (can be modified)\n",
    "\n",
    "n.samples = 100\n",
    "smp.sz.prop = 0.2\n",
    "alpha = 0.1\n",
    "\n",
    "fr.dist = 2\n",
    "\n",
    "## Other parameters\n",
    "\n",
    "smp.sz.1 = floor(smp.sz.prop*smp0.sz)\n",
    "mu.0.1 = smp0.mn - fr.dist*smp0.sd/sqrt(smp.sz)\n",
    "t.q.1 = qnorm(alpha, lower.tail = FALSE)\n",
    "\n",
    "## Generate samples and estimates\n",
    "\n",
    "mn.smp.1 = s.smp.1 = NULL\n",
    "for (i in 1:n.samples) {\n",
    "    v.smp.1 = sample(data.sel$Val, smp.sz.1, replace = FALSE)\n",
    "    mn.smp.1 = c(mn.smp.1,mean(v.smp.1))\n",
    "    s.smp.1 = c(s.smp.1,sd(v.smp.1))\n",
    "}\n",
    "s.mn.1 = data.frame(vm = mn.smp.1, vs = s.smp.1)\n",
    "\n",
    "## Distances based on the value of the statistic and the p-value\n",
    "\n",
    "v.t.1 = (s.mn.1$vm - mu.0.1)/(s.mn.1$vs/sqrt(smp.sz.1))\n",
    "err.v.t.1 = as.numeric(v.t.1 < t.q.1) + 1\n",
    "\n",
    "t.s.mn.1 = data.frame(val = v.t.1, errv = err.v.t.1)\n",
    "v.p.1 = pnorm(v.t.1, lower.tail = FALSE)\n",
    "err.v.p.1 = as.numeric(v.p.1 > alpha) + 1\n",
    "p.s.mn.1 = data.frame(val = v.p.1, errv = err.v.p.1)\n",
    "\n",
    "plt.j.1 = t.s.mn.1 %>% ggplot(aes(x=val,y=\"\")) + geom_jitter(color=t.s.mn.1$errv) +\n",
    "  ggtitle(\"Values of test statistic\") +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=t.q.1,color = \"red\",size=0.5)\n",
    "\n",
    "plt.j.2 = p.s.mn.1 %>% ggplot(aes(x=val,y=\"\")) + geom_jitter(color=p.s.mn.1$errv) +\n",
    "  ggtitle(\"p-values\") +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=alpha,color = \"red\",size=0.5)\n",
    "\n",
    "suppressWarnings(grid.arrange(plt.j.1,plt.j.2,nrow = 2,\n",
    "                              top=textGrob(\"Distances to H0 from different samples\",gp=gpar(fontsize=15,col=\"blue\"))))\n",
    "\n",
    "## Summary of numerical values\n",
    "\n",
    "mn.val = data.frame(round(c(mu.0.1,smp0.mn,smp0.sd,alpha,t.q.1),3))\n",
    "Data.hux <-\n",
    "  hux(mn.val) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux) <- c(\"\",\"mu 0\",\"Population mean\",\"Pop std dev\",\"Significance level\",\"Critical value\")\n",
    "colnames(Data.hux) <- c(\"Values\")\n",
    "table_prnt(Data.hux[-1,],\"Values for the example\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480106a-7eb7-47a4-a98b-568f45f372f2",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:brown\">The power function of a test</span>\n",
    "\n",
    "In the preceding cells we have described how to conduct a hypothesis test to reach a conclusion for a given null hypothesis, based on the available data. The outcome of this procedure is affected by a series of choices:\n",
    "- The definition of the null and alternative hypotheses, which we have commented before.\n",
    "- The significance level of the test.\n",
    "- Our selection of a test statistic (and its distribution), based on our assumptions on the data or on theoretical results. Different alternatives may be available for a given parameter, as we discussed in Lesson 1.\n",
    "\n",
    "In this section we will comment (briefly) on the criteria to select these two last items in the best possible manner. We will differentiate between better or poorer choices by looking at the magnitude of the errors associated both to our choices and the test procedure.\n",
    "\n",
    "Remember that there are two possible types of errors in a test: the <span style=\"color:brown\">type I error</span>, which happens when we reject $H_0$ while it is true, and the <span style=\"color:brown\">type II error</span>, when we fail to reject $H_0$ but it is not true. Our preference would be to select a test that would yield very small probabilities for these two errors. It is important to remember that these probabilities change in opposite ways, that is, if we decrease one of the two probabilities, the other one will in general increase.\n",
    "\n",
    "To find a balance between these two values, the usual approach is to fix the probability of a type I error for a given test, by setting this probability equal to some preferred value, the significance level. That is, when we specify the significance level for a test we are indicating how large a probability of a type I error we are willing to accept. Or in other words, what is an acceptable proportion of cases in which we would end up rejecting the null hypothesis when it is true.\n",
    "\n",
    "Given this option, the second probability, that of a type II error, will take a value that is also a consequence of the particular type of test we have selected. And this value cannot be controlled beyond our choice of a test statistic, given the characteristics of the data.\n",
    "\n",
    "If we wish to analyze how efficient a test is, we need to determine the value of this probability of a type II error, which we have denoted as $\\beta$. The smaller it is, the better the test. In practice it is more common to work with the <span style=\"color:brown\">power of the test</span>, a function defined as the value of $1 - \\beta$, one minus the probability of a type II error. Given this definition, we would prefer to use a test having the largest possible value of the power.\n",
    "\n",
    "The power of a test is defined as a function of the true value of the parameter, as the probability of this error depends on how far this value is from the null hypothesis of the test. We expect this probability to be higher when we are very far from the null hypothesis, as in that case, when $\\mu = \\mu_1$ and $\\mu_1$ is very different from $\\mu_0$, it should be much easier to obtain evidence showing that (with high probability) the data cannot have been generated from a population having $\\mu = \\mu_0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60427af8-20f6-4cd6-ae2c-af6743a824f8",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:brown\">Computing the power of a test</span>\n",
    "\n",
    "The power of a test is a probability which depends on the test statistic and the definition of the test, as well as on the true value of the parameter. We now present some examples of procedures to compute the value of this function, depending on the true value of $\\mu$.\n",
    "\n",
    "To compute this function we start from the definition of the power of a test: the probability of rejecting the null hypothesis if the true value of the parameter $\\theta$ is not in the region corresponding to that null hypothesis. As we have commented, this probability will be a function of the true value of the parameter $\\theta = \\theta_1$. In particular, if the true value of the parameter $\\theta_1$ is very far from the reference value defining the null hypothesis, $\\theta_0$, it should be very easy to identify this situation by looking at the data, as our sample observations should take values close to $\\theta_1$ and far from $\\theta_0$. While if the true value $\\theta_1$ is very close to $\\theta_0$, it may be difficult to differentiate between $\\theta_1$ and $\\theta_0$ based on the sample data, as the values in the sample will be close to $\\theta_1$, but they will also be close to $\\theta_0$.\n",
    "\n",
    "Formally, for a value of the parameter $\\theta_1$ corresponding to the alternative hypothesis, we define the power of the test as\n",
    "\n",
    "$$\n",
    "\\mbox{power} (\\theta_1) = \\Pr( \\mbox{reject } H_0 | \\theta = \\theta_1 ) .\n",
    "$$\n",
    "\n",
    "For example, in the particular case when the null hypothesis is given by $H_0 : \\mu \\leq \\mu_0$ and we have normal data, the definition would be:\n",
    "\n",
    "$$\n",
    "\\mbox{power} (\\mu_1) = \\Pr\\left( \\frac{\\bar X - \\mu_0}{S/\\sqrt{n}} > t_{n-1;\\alpha} \\; \\Bigl| \\; \\mu = \\mu_1 \\right) , \\qquad \\frac{\\bar X - \\mu_1}{S/\\sqrt{n}} \\sim t_{n-1}\n",
    "$$\n",
    "\n",
    "where $\\mu_1$ denotes the true value of the parameter $\\mu$.\n",
    "\n",
    "The computation of this power function requires following several steps:\n",
    "\n",
    "1. Write the probability of interest in terms of the test statistic and the definition of the rejection region for the test.\n",
    "2. Identify the distribution to be used to compute this probability. \n",
    "3. In the evaluation of the test we assume a distribution for the statistic when $\\theta = \\theta_0$, that is, we assume that $H_0$ is true. The rejection region is then defined in terms of this statistic and the quantiles of its distribution.\n",
    "\n",
    "   But to compute the power, the distribution for the test statistic will be correct when $\\theta = \\theta_1$, that is, when the parameter takes its true value. We need to rewrite the probability used to define the power, based on the rejection region and written in terms of $\\theta = \\theta_0$, as another probability in terms of the corresponding statistic when $\\theta = \\theta_1$.\n",
    "4. The last step is to compute the desired probability, the power, from the distribution of the statistic and the values of the parameters and estimates.\n",
    "\n",
    "For example, for the case when $H_0 : \\sigma^2 \\leq \\sigma_0^2$ and assuming normal observations, the power of the test for $\\sigma^2 = \\sigma_1^2$ can be obtained through the following steps:\n",
    "\n",
    "1. Using the definition of the rejection rgion, the probability we wish to compute is:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\mbox{power} (\\sigma_1^2) & = & \\Pr( \\mbox{reject } H_0 | \\sigma^2 = \\sigma_1^2 ) \\\\\n",
    "& = & \\displaystyle \\Pr\\left( \\frac{(n-1)S^2}{\\sigma_0^2} > \\chi^2_{n-1;\\alpha} \\; \\Bigl| \\; \\sigma^2 = \\sigma^2_1 \\right)\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "2. The distribution we will use to compute this probability, corresponding to the true value of the parameter $\\sigma_1^2$, is:\n",
    "\n",
    "$$\n",
    "\\frac{(n-1)S^2}{\\sigma_1^2} \\sim \\chi^2_{n-1}\n",
    "$$\n",
    "\n",
    "3. and 4. The probability defining the power, written in terms of this distribution, is\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\mbox{power} (\\sigma_1^2) & = & \\displaystyle \\Pr\\left( \\frac{(n-1)S^2}{\\sigma_0^2} > \\chi^2_{n-1;\\alpha} \\right) = \\Pr\\left( \\frac{(n-1)S^2}{\\sigma_1^2} \\frac{\\sigma_1^2}{\\sigma_0^2} > \\chi^2_{n-1;\\alpha} \\right) \\\\\n",
    "& = & \\displaystyle \\Pr\\left( \\frac{(n-1)S^2}{\\sigma_1^2} > \\chi^2_{n-1;\\alpha} \\frac{\\sigma_0^2}{\\sigma_1^2} \\right) = \\Pr\\left( \\chi^2_{n-1} > \\chi^2_{n-1;\\alpha} \\frac{\\sigma_0^2}{\\sigma_1^2} \\right)\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Summarizing our previous comments, the power of a test will in general depend on the hypotheses of the test, the statistic we use and its distribution (and in particular on the sample size), the confidence level of the test and the true value of the parameter $\\theta_1$. It will also be an increasing function as the true value of the parameter moves away from the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01cd475-6936-4887-8d06-6d092a5a5064",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Answer the following questions:</span>\n",
    "- <span style=\"color:green\">Compute the power of the test for a one-sided hypothesis test on the population variance, when $\\sigma^2_0 = 2$ and the true value of the parameter is $\\sigma^2_1 = 3$. Repeat the calculation for $\\sigma^2_1 = 4$.</span>\n",
    "- <span style=\"color:green\">What is the value of the power of a test when $\\theta_1 \\rightarrow \\theta_0$?</span>\n",
    "- <span style=\"color:green\">Compute the power of the test for a ons-sided hypothesis test on the population proportion, when $p = p_0$ and the true value is $p = p_1 > p_0$.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f19298-8239-4c6d-8582-bcbda9014312",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*The manufacturer of a certain precision component is required to ensure that the variability (standard deviation) in one of the characteristics of a given component does not exceed $0.2$ mm. The manufacturer has collected a sample of 12 measurements from different components, with a sample quasivariance equal to $s^2 = 0.06562$.*\n",
    "\n",
    "*The manufacturer would like to test if the information in the sample would imply that the manufacturing process is not working within the desired tolerance, with a significance level of 5%. To understand the errors associated to this test, the manufacturer would like to know what is the power of the test if the true value of $\\sigma$ is $0.25$.*\n",
    "\n",
    "*You may assume that the data follow a normal distribution.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a0a5e-6f34-401f-bf0b-51698a0e7703",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "Let $X$ denote the random variable corresponding to the value of the characteristic of interest. We wish to conduct a hypothesis test on the value of $\\sigma_X$, or on $\\sigma_X^2$, as this is an slightly simpler option. The hypothesis test we wish to study is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "   H_0 & : & \\sigma_X^2 \\leq 0.2^2 = \\sigma_0^2 \\\\\n",
    "   H_1 & : & \\sigma_X^2 > 0.04\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The alternative hypothesis for this test has been selected in the direction of the sample data, and also in the direction of the (assumed) true value of the parameter.\n",
    "\n",
    "The statistic for this test, as we study a population variance from a sample with normal data, is\n",
    "\n",
    "$$\n",
    "T = \\frac{(n-1)S_x^2}{\\sigma^2} \\sim \\chi^2_{n-1}\n",
    "$$\n",
    "\n",
    "and the rejection region for the test, for a significance level $\\alpha = 0.05$, is\n",
    "\n",
    "$$\n",
    "\\text{RR}_{0.05} = \\left\\{ (x_1,\\ldots ,x_n) \\; | \\; t_0 > \\chi^2_{n-1;\\alpha} = \\chi^2_{11;0.05} = 19.675 \\right\\}\n",
    "$$\n",
    "\n",
    "where $t_0 = (n-1)s_x^2/\\sigma_0^2$, the value of the test statistic assuming that $H_0$ is true.\n",
    "\n",
    "The power for this test for $\\sigma = \\sigma_1 = 0.25$, or equivalently $\\sigma^2 = \\sigma_1^2 = 0.0625$, is defined as\n",
    "\n",
    "$$\n",
    "\\text{power} (\\mu) = \\Pr \\left( \\text{reject } H_0 \\; |\\; \\sigma^2 = \\sigma_1^2 = 0.0625 \\right) = \\Pr \\left( \\frac{(n-1)S_x^2}{\\sigma_0^2} > 19.675 \\; |\\; \\sigma^2 = 0.0625 \\right)\n",
    "$$\n",
    "\n",
    "If the true value of the parameter is $\\sigma_1^2 = 0.0625$, it is no longer true that $(n-1)S_x^2/\\sigma_0^2 \\sim \\chi^2_{n-1}$, and now it holds that\n",
    "\n",
    "$$\n",
    "\\frac{(n-1)S_x^2}{\\sigma_1^2} \\sim \\chi^2_{11}\n",
    "$$\n",
    "\n",
    "We need to use this distribution to compute the probability defining the power. We rewrite the condition in the definition of the power in terms of the known distribution (which now is the statistic written using $\\sigma_1^2$ instead of $\\sigma_0^2$),\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{power} (\\mu) & = & \\displaystyle \\Pr \\left( \\frac{(n-1)S_x^2}{\\sigma_1^2} \\frac{\\sigma_1^2}{\\sigma_0^2} > 19.675 \\right) = \\Pr \\left( \\chi_{11} > 19.675 \\frac{\\sigma_0^2}{\\sigma_1^2} \\right) \\\\\n",
    "& = & \\Pr \\left( \\chi_{11} > 12.592 \\right) = 0.3208\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "In this case our null hypothesis is incorrect, as $\\sigma_1^2 = 0.0625 > \\sigma_0^2 = 0.04$.\n",
    "The probability of rejecting the null hypothesis when $\\sigma^2 = \\sigma_1^2$ equals $0.3208$, which is not a very high probability. Note that we would like this value to be close to one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196d76c-a85b-4d1e-a451-e2ad28b70812",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:blue;\">Examples of power functions</span>\n",
    "\n",
    "We represent in the following cell the shape of the power functions for a few cases corresponding to situations we have covered in this lesson.\n",
    "\n",
    "These results are based on exact representations of the power functions, although in the case of the tests on the population mean some special procedures have been required to obtain these values, see [Appendix 1](#App2_1).\n",
    "\n",
    "The cases presented in the following plots are:\n",
    "\n",
    "- Tests on the population mean, for the normal case (with $\\sigma^2 = 2$), simulated,\n",
    "   - Plot 1. A one-sided left test $H_0 : \\mu \\leq 4$\n",
    "   - Plot 2. A one-sided right test $H_0 : \\mu \\geq 4$\n",
    "   - Plot 3. A two-sided test $H_0 : \\mu = 4$\n",
    "- Tests on the population variance, for the normal case\n",
    "   - Plot 4. A one-sided left test $H_0 : \\sigma^2 \\leq 2$\n",
    "   - Plot 5. A one-sided right test $H_0 : \\sigma^2 \\geq 2$\n",
    "   - Plot 6. A two-sided test $H_0 : \\sigma^2 = 2$\n",
    "   \n",
    "In the following code cell, the value of the significance level for the test can be modified in the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">sig.lvl</span>, and the sample size can be modified in the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">smp.sz</span>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7a7c15-1862-4bf5-ba13-eae6d30c8c85",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: Power functions\n",
    "\n",
    "# Tests on the mean\n",
    "\n",
    "## These parameters can be modified\n",
    "\n",
    "sig.lvl = 0.05\n",
    "smp.sz = 20\n",
    "\n",
    "mu.0 = 4\n",
    "sig2.0 = 2\n",
    "\n",
    "## Results obtained by conditioning of the value of the quasivariance\n",
    "\n",
    "crit.val.r = qt(sig.lvl,smp.sz-1,lower.tail = FALSE)\n",
    "crit.val.l = qt(sig.lvl,smp.sz-1,lower.tail = TRUE)\n",
    "crit.val.bu = qt(sig.lvl/2,smp.sz-1,lower.tail = FALSE)\n",
    "crit.val.bl = qt(sig.lvl/2,smp.sz-1,lower.tail = TRUE)\n",
    "\n",
    "int.lim = 2\n",
    "xlm.l = mu.0 - int.lim\n",
    "xlm.u = mu.0 + int.lim\n",
    "x.seq = seq(xlm.l,xlm.u,length.out=100)\n",
    "\n",
    "int.fn.r = function(x,delta,sig2,sm.s,cv) {pt(cv - delta/sqrt(sig2*x/(sm.s*(sm.s-1))),sm.s-1,lower.tail=FALSE)*dchisq(x,sm.s-1)}\n",
    "int.fn.l = function(x,delta,sig2,sm.s,cv) {pt(cv - delta/sqrt(sig2*x/(sm.s*(sm.s-1))),sm.s-1,lower.tail=TRUE)*dchisq(x,sm.s-1)}\n",
    "int.fn.b = function(x,delta,sig2,sm.s,cv.u,cv.l) {(pt(cv.u - delta/sqrt(sig2*x/(sm.s*(sm.s-1))),sm.s-1,lower.tail=FALSE) +\n",
    "                              pt(cv.l - delta/sqrt(sig2*x/(sm.s*(sm.s-1))),sm.s-1,lower.tail=TRUE))*dchisq(x,sm.s-1)}\n",
    "\n",
    "pwr.val = NULL\n",
    "for (mu.1 in x.seq) {\n",
    "    pwr.val.r = integrate(int.fn.r, lower = 0, upper = Inf, delta = mu.1 - mu.0, sig2 = sig2.0, sm.s = smp.sz, cv = crit.val.r)$value\n",
    "    pwr.val.l = integrate(int.fn.l, lower = 0, upper = Inf, delta = mu.1 - mu.0, sig2 = sig2.0, sm.s = smp.sz, cv = crit.val.l)$value\n",
    "    pwr.val.b = integrate(int.fn.b, lower = 0, upper = Inf, delta = mu.1 - mu.0, sig2 = sig2.0, sm.s = smp.sz, cv.u = crit.val.bu, cv.l = crit.val.bl)$value\n",
    "    pwr.val = rbind(pwr.val,c(mu.1,pwr.val.r,pwr.val.l,pwr.val.b))\n",
    "}\n",
    "pwr.mu = as.data.frame(pwr.val)\n",
    "colnames(pwr.mu) = c(\"val\",\"tr\",\"tl\",\"tb\")\n",
    "\n",
    "## Plots of power functions for the mean\n",
    "\n",
    "plt.1 = pwr.mu %>%\n",
    "   ggplot(aes(x=val,y=tr)) + geom_line(color=\"black\") +\n",
    "   geom_vline(xintercept=c(mu.0),linetype=c(\"solid\"),color=c(\"red\")) +\n",
    "   annotate(geom=\"text\",label=c(\"mu_0\"),\n",
    "            x=c(mu.0),y=c(0.5),angle = 90,vjust = -1.5) +\n",
    "   geom_hline(yintercept=sig.lvl,linetype=\"dashed\",color=\"red\") +\n",
    "   annotate(geom=\"text\",label=\"Significance level\",\n",
    "            x=xlm.l+0.3,y=sig.lvl,vjust = -1) +\n",
    "   ggtitle(\"Power function for a left one-sided test (mean)\") +\n",
    "   xlab(\"True value of the parameter\") + ylab(\" \") +\n",
    "   theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "plt.2 = pwr.mu %>%\n",
    "   ggplot(aes(x=val,y=tl)) + geom_line(color=\"black\") +\n",
    "   geom_vline(xintercept=c(mu.0),linetype=c(\"solid\"),color=c(\"red\")) +\n",
    "   annotate(geom=\"text\",label=c(\"mu_0\"),\n",
    "            x=c(mu.0),y=c(0.5),angle = 90,vjust = -1.5) +\n",
    "   geom_hline(yintercept=sig.lvl,linetype=\"dashed\",color=\"red\") +\n",
    "   annotate(geom=\"text\",label=\"Significance level\",\n",
    "            x=xlm.l+0.3,y=sig.lvl,vjust = -1) +\n",
    "   ggtitle(\"Power function for a right one-sided test (mean)\") +\n",
    "   xlab(\"True value of the parameter\") + ylab(\" \") +\n",
    "   theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "plt.3 = pwr.mu %>%\n",
    "   ggplot(aes(x=val,y=tb)) + geom_line(color=\"black\") +\n",
    "   geom_vline(xintercept=c(mu.0),linetype=c(\"solid\"),color=c(\"red\")) +\n",
    "   annotate(geom=\"text\",label=c(\"mu_0\"),\n",
    "            x=c(mu.0),y=c(0.5),angle = 90,vjust = -1.5) +\n",
    "   geom_hline(yintercept=sig.lvl,linetype=\"dashed\",color=\"red\") +\n",
    "   annotate(geom=\"text\",label=\"Significance level\",\n",
    "            x=xlm.l+0.3,y=sig.lvl,vjust = -1) +\n",
    "   ggtitle(\"Power function for a two-sided test (mean)\") +\n",
    "   xlab(\"True value of the parameter\") + ylab(\" \") +\n",
    "   theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "suppressWarnings(grid.arrange(plt.1,plt.2,plt.3,nrow = 3,\n",
    "                              top=textGrob(\"Power functions for a test on the population mean\",gp=gpar(fontsize=15,col=\"blue\"))))\n",
    "\n",
    "## Plots of power functions for the variance\n",
    "\n",
    "plt.fct = 2\n",
    "xlm.l = 0\n",
    "xlm.u = plt.fct*sig2.0\n",
    "xlm.inc = (xlm.u - xlm.l)/100\n",
    "\n",
    "cv.1 = qchisq(sig.lvl,smp.sz-1,lower.tail=FALSE)\n",
    "cv.2 = qchisq(1-sig.lvl,smp.sz-1,lower.tail=FALSE)\n",
    "cv.3l = qchisq(1-sig.lvl/2,smp.sz-1,lower.tail=FALSE)\n",
    "cv.3u = qchisq(sig.lvl/2,smp.sz-1,lower.tail=FALSE)\n",
    "\n",
    "sim.p.2 = NULL\n",
    "for (v.mu in seq(xlm.l,xlm.u,xlm.inc)) {\n",
    "    p.smp.1 = pchisq(cv.1*sig2.0/v.mu,smp.sz-1,lower.tail=FALSE)\n",
    "    p.smp.2 = pchisq(cv.2*sig2.0/v.mu,smp.sz-1,lower.tail=TRUE)\n",
    "    p.smp.3 = pchisq(cv.3u*sig2.0/v.mu,smp.sz-1,lower.tail=FALSE) + pchisq(cv.3l*sig2.0/v.mu,smp.sz-1,lower.tail=TRUE)\n",
    "    sim.p.2 = rbind(sim.p.2,c(v.mu,p.smp.1,p.smp.2,p.smp.3))\n",
    "}\n",
    "pwr.sig = as.data.frame(sim.p.2)\n",
    "names(pwr.sig) = c(\"val\",\"tl\",\"tr\",\"tb\")\n",
    "\n",
    "plt.1 = pwr.sig %>%\n",
    "   ggplot(aes(x=val,y=tl)) + geom_line() +\n",
    "   geom_vline(xintercept=c(sig2.0),linetype=c(\"solid\"),color=c(\"red\")) +\n",
    "   annotate(geom=\"text\",label=c(\"sigma2_0\"),\n",
    "            x=c(sig2.0),y=c(0.5),angle = 90,vjust = -1.5) +\n",
    "   geom_hline(yintercept=sig.lvl,linetype=\"dashed\",color=\"red\") +\n",
    "   annotate(geom=\"text\",label=\"Significance level\",\n",
    "            x=xlm.l+0.3,y=sig.lvl,vjust = -1) +\n",
    "   ggtitle(\"Power function for a left one-sided test (variance)\") +\n",
    "   xlab(\"True value of the parameter\") + ylab(\" \") +\n",
    "   theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "plt.2 = pwr.sig %>%\n",
    "   ggplot(aes(x=val,y=tr)) + geom_line() +\n",
    "   geom_vline(xintercept=c(sig2.0),linetype=c(\"solid\"),color=c(\"red\")) +\n",
    "   annotate(geom=\"text\",label=c(\"sigma2_0\"),\n",
    "            x=c(sig2.0),y=c(0.5),angle = 90,vjust = -1.5) +\n",
    "   geom_hline(yintercept=sig.lvl,linetype=\"dashed\",color=\"red\") +\n",
    "   annotate(geom=\"text\",label=\"Significance level\",\n",
    "            x=xlm.l+0.3,y=sig.lvl,vjust = -1) +\n",
    "   ggtitle(\"Power function for a right one-sided test (variance)\") +\n",
    "   xlab(\"True value of the parameter\") + ylab(\" \") +\n",
    "   theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "plt.3 = pwr.sig %>%\n",
    "   ggplot(aes(x=val,y=tb)) + geom_line() +\n",
    "   geom_vline(xintercept=c(sig2.0),linetype=c(\"solid\"),color=c(\"red\")) +\n",
    "   annotate(geom=\"text\",label=c(\"sigma2_0\"),\n",
    "            x=c(sig2.0),y=c(0.5),angle = 90,vjust = -1.5) +\n",
    "   geom_hline(yintercept=sig.lvl,linetype=\"dashed\",color=\"red\") +\n",
    "   annotate(geom=\"text\",label=\"Significance level\",\n",
    "            x=xlm.l+0.3,y=sig.lvl,vjust = -1) +\n",
    "   ggtitle(\"Power function for a two-sided test (variance)\") +\n",
    "   xlab(\"True value of the parameter\") + ylab(\" \") +\n",
    "   theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "suppressWarnings(grid.arrange(plt.1,plt.2,plt.3,nrow = 3,\n",
    "                              top=textGrob(\"Power functions for a test on the population variance\",gp=gpar(fontsize=15,col=\"blue\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c925e14-dbb8-4d3c-bad3-0996b40499b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown\">Impact of the sample size on the power function of a test</span>\n",
    "\n",
    "We have mentioned in the preceding cells that the power of a test depends on the sample size. Intuitively, if we would have more information available we should make smaller errors, everything else being the same.\n",
    "\n",
    "Formally, for the particular case of a test on the variance with normal data and $H_0 : \\sigma^2 \\leq \\sigma_0^2$, we have seen that the power of the test for $\\sigma^2 = \\sigma_1^2 > \\sigma_0^2$ will be given by\n",
    "\n",
    "$$\n",
    "\\mbox{power} (\\sigma_1^2) = \\Pr\\left( \\chi^2_{n-1} > \\chi^2_{n-1;\\alpha} \\frac{\\sigma_0^2}{\\sigma_1^2} \\right)\n",
    "$$\n",
    "\n",
    "Assume we would like to have a power of the test larger than a certain value $\\beta$, for given values of $\\alpha$, $\\sigma_0^2$ and $\\sigma_1^2$. We need\n",
    "\n",
    "$$\n",
    "\\Pr\\left( \\chi^2_{n-1} > \\chi^2_{n-1;\\alpha} \\frac{\\sigma_0^2}{\\sigma_1^2} \\right) > \\beta \\ \\Rightarrow \\ \\chi^2_{n-1;\\alpha} \\frac{\\sigma_0^2}{\\sigma_1^2} < \\chi^2_{n-1;\\beta} \\ \\Rightarrow \\ \\frac{\\chi^2_{n-1;\\alpha}}{\\chi^2_{n-1;\\beta}} < \\frac{\\sigma_1^2}{\\sigma_0^2} \n",
    "$$\n",
    "\n",
    "and we could find acceptable values of the sample size by trying values of the quantiles of a chi squared distribution for different values of $n$ until we find the first value that satisfies the preceding condition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b5f14-310e-4b6c-ad23-12315df5d79f",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*The manufacturer of a certain precision component is required to ensure that the variability (standard deviation) in one of the characteristics of a given component does not exceed $0.2$ mm. The manufacturer has collected a sample of 12 measurements from different components, with a sample quasivariance equal to $s^2 = 0.06562$.*\n",
    "\n",
    "*The manufacturer would like to increase the power of the test (reduce the probability of a type II error) when the true value of $\\sigma$ is $0.25$, to a value of at least $0.7$, for a significance level of 5%. To achieve this, they are willing to increase the sample size of the sample used in the study. Which would be the smallest sample size that will ensure this power for the test?*\n",
    "\n",
    "*You may assume that the data follow a normal distribution.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a14238-b5a6-482e-a1a2-a296879cd1da",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "Let $X$ denote the random variable corresponding to the value of the characteristic of interest. Our hypothesis test is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "   H_0 & : & \\sigma_X^2 \\leq 0.2^2 = \\sigma_0^2 \\\\\n",
    "   H_1 & : & \\sigma_X^2 > 0.04\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The statistic for this test is\n",
    "\n",
    "$$\n",
    "T = \\frac{(n-1)S_x^2}{\\sigma^2} \\sim \\chi^2_{n-1}\n",
    "$$\n",
    "\n",
    "and the rejection region for the test, for a significance level $\\alpha = 0.05$ and for any sample size $n$, is\n",
    "\n",
    "$$\n",
    "\\text{RR}_{0.05} = \\left\\{ (x_1,\\ldots ,x_n) \\; | \\; t_0 > \\chi^2_{n-1;\\alpha} = \\chi^2_{n-1;0.05} \\right\\}\n",
    "$$\n",
    "\n",
    "where $t_0 = (n-1)s_x^2/\\sigma_0^2$.\n",
    "\n",
    "The power for this test for $\\sigma = \\sigma_1 = 0.25$, or equivalently $\\sigma^2 = \\sigma_1^2 = 0.0625$, is defined as\n",
    "\n",
    "$$\n",
    "\\text{power} (\\mu) = \\Pr \\left( \\text{reject } H_0 \\; |\\; \\sigma^2 = \\sigma_1^2 = 0.0625 \\right) = \\Pr \\left( \\frac{(n-1)S_x^2}{\\sigma_0^2} > \\chi^2_{n-1;0.05} \\; |\\; \\sigma^2 = 0.0625 \\right)\n",
    "$$\n",
    "\n",
    "If the true value of the parameter is $\\sigma_1^2 = 0.0625$, it is no longer true that $(n-1)S_x^2/\\sigma_0^2 \\sim \\chi^2_{n-1}$, and now it holds that\n",
    "\n",
    "$$\n",
    "\\frac{(n-1)S_x^2}{\\sigma_1^2} \\sim \\chi^2_{n-1}\n",
    "$$\n",
    "\n",
    "We rewrite the condition in the probability defining the power in terms of the known distribution (which now is the statistic written using $\\sigma_1^2$ instead of $\\sigma_0^2$),\n",
    "$$\n",
    "\\text{power} (\\mu) = \\Pr \\left( \\frac{(n-1)S_x^2}{\\sigma_1^2} \\frac{\\sigma_1^2}{\\sigma_0^2} > \\chi^2_{n-1;0.05} \\right) = \\Pr \\left( \\chi_{n-1} > \\chi^2_{n-1;0.05} \\frac{\\sigma_0^2}{\\sigma_1^2} \\right)\n",
    "$$\n",
    "\n",
    "If we now impose the condition that the power should be at least $0.7$, we have (we translate the condition on the probability to a condition on quantiles),\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{power} (\\mu) & = & \\displaystyle \\Pr \\left( \\chi_{n-1} > \\chi^2_{n-1;0.05} \\frac{\\sigma_0^2}{\\sigma_1^2} \\right) \\geq 0.7 \\Rightarrow \\chi^2_{n-1;0.05} \\frac{\\sigma_0^2}{\\sigma_1^2} \\leq \\chi^2_{n-1;0.7} \\Rightarrow \\frac{\\chi^2_{n-1;0.05}}{\\chi^2_{n-1;0.7}} \\\\\n",
    "& \\leq & \\displaystyle \\frac{\\sigma_1^2}{\\sigma_0^2} = \\frac{0.0625}{0.04} = 1.5625\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Using R to generate the values of the quantiles in the preceding formula, we obtain (see the following cell) that the requested answer is $n \\geq 46$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ec64b5-fc3a-4bdf-9995-4d3cf5b80808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise calculations. Sample sizes and power of hypothesis tests\n",
    "\n",
    "pwr.d = 0.7\n",
    "sig.l = 0.05\n",
    "\n",
    "sg.0 = 0.2^2\n",
    "sg.1 = 0.25^2\n",
    "ref.v = sg.1/sg.0\n",
    "\n",
    "n.mn = 40\n",
    "n.mx = 50\n",
    "pwr.res = NULL\n",
    "for (i.n in n.mn:n.mx) {\n",
    "    q.n = qchisq(sig.l,i.n-1,lower.tail=FALSE)\n",
    "    q.d = qchisq(pwr.d,i.n-1,lower.tail=FALSE)\n",
    "    pwr.res = rbind(pwr.res,c(i.n,ref.v,q.n/q.d))\n",
    "}\n",
    "pwr.res = as.data.frame(pwr.res)\n",
    "colnames(pwr.res) = c(\"Sample size\",\"Ratio of variances\",\"Ratio of quantiles\")\n",
    "\n",
    "table_prnt(pwr.res,\"Exercise results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d36d4-9b94-41fc-a900-d6c42cacc5da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Power functions and sample sizes</span>\n",
    "\n",
    "As a practical illustration, the following cell plots the power functions for two cases (one-sided tests for the mean and the variance with normal data) and different sample sizes.\n",
    "\n",
    "In these plots, the value of the significance level of the test can be modified in the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">sig.lvl</span>, and the sample sizes used in the comparison can be modified in the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">smp.sz.v</span>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741a56f-452e-4818-98c6-f36f7746706a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis testing: Power functions and sample sizes. \n",
    "\n",
    "## Tests on the mean\n",
    "\n",
    "### These parameters can be modified\n",
    "\n",
    "sig.lvl = 0.05\n",
    "smp.sz.v = c(15,40,100)\n",
    "\n",
    "mu.0 = 4\n",
    "sig2.0 = 2\n",
    "\n",
    "### Colors for the plots\n",
    "\n",
    "col.v.gen = c(\"#619CFF\", \"#00BFC4\", \"#00BF7D\", \"#33CCCC\", \"#33FFCC\", \"#99CCFF\")\n",
    "col.v = col.v.gen[1:length(smp.sz.v)]\n",
    "\n",
    "### Computing the power by conditioning on the values of the quasivariance\n",
    "\n",
    "int.lim = 1.2\n",
    "xlm.l = mu.0 - int.lim\n",
    "xlm.u = mu.0 + int.lim\n",
    "x.seq = seq(xlm.l,xlm.u,length.out=100)\n",
    "\n",
    "int.fn = function(x,delta,sig2,sm.s,cv) {pt(cv - delta/sqrt(sig2*x/(sm.s*(sm.s-1))),sm.s-1,lower.tail=FALSE)*dchisq(x,sm.s-1)}\n",
    "\n",
    "sim.pl = NULL\n",
    "for (i.s in 1:length(smp.sz.v)) {\n",
    "    smp.sz = smp.sz.v[i.s]\n",
    "    crit.val = qt(sig.lvl,smp.sz-1,lower.tail=FALSE)\n",
    "    for (mu.1 in x.seq) {\n",
    "        pwr.v = integrate(int.fn, lower = 0, upper = Inf, delta = mu.1 - mu.0, sig2 = sig2.0, sm.s = smp.sz, cv = crit.val)$value\n",
    "        sim.pl = rbind(sim.pl,c(mu.1,i.s,pwr.v))\n",
    "    }\n",
    "}\n",
    "sim.pl = as.data.frame(sim.pl)\n",
    "names(sim.pl) = c(\"val\",\"smp.size\",\"test\")\n",
    "sim.pl$smp.size = as.factor(sim.pl$smp.size)\n",
    "\n",
    "### Drawing the plot\n",
    "\n",
    "plt.1 = sim.pl %>%\n",
    "   ggplot(aes(x=val,y=test,color=smp.size)) + geom_line() +\n",
    "   geom_vline(xintercept=c(mu.0),linetype=c(\"solid\"),color=c(\"red\")) +\n",
    "   annotate(geom=\"text\",label=c(\"mu_0\"),\n",
    "            x=c(mu.0),y=c(0.5),angle = 90,vjust = -1.5) +\n",
    "   geom_hline(yintercept=sig.lvl,linetype=\"dashed\",color=\"red\") +\n",
    "   annotate(geom=\"text\",label=\"Significance level\",\n",
    "            x=xlm.l+0.3,y=sig.lvl,vjust = -1) +\n",
    "   ggtitle(\"Power functions for a left one-sided test (mean)\") +\n",
    "   xlab(\"True value of the parameter\") + ylab(\" \") +\n",
    "   scale_colour_manual(\"sample sizes\", values = col.v, labels = smp.sz.v) +\n",
    "   theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "## Plots of power functions for the variance\n",
    "\n",
    "plt.fct = 2.5\n",
    "xlm.l = 0\n",
    "xlm.u = plt.fct*sig2.0\n",
    "xlm.inc = (xlm.u - xlm.l)/100\n",
    "\n",
    "sim.p = NULL\n",
    "for (i.s in 1:length(smp.sz.v)) {\n",
    "    smp.sz = smp.sz.v[i.s]\n",
    "    cv.1 = qchisq(sig.lvl,smp.sz-1,lower.tail=FALSE)\n",
    "    \n",
    "    sim.p.2 = NULL\n",
    "    for (v.mu in seq(xlm.l,xlm.u,xlm.inc)) {\n",
    "        v.tst = pchisq(cv.1*sig2.0/v.mu,smp.sz-1,lower.tail=FALSE)\n",
    "        sim.p.2 = rbind(sim.p.2,c(v.mu,i.s,v.tst))\n",
    "    }\n",
    "    sim.p = rbind(sim.p,sim.p.2)\n",
    "}\n",
    "sim.p = as.data.frame(sim.p)\n",
    "names(sim.p) = c(\"val\",\"smp.size\",\"test\")\n",
    "sim.p$smp.size = as.factor(sim.p$smp.size)\n",
    "\n",
    "### Drawing the plot\n",
    "\n",
    "plt.2 = sim.p %>%\n",
    "   ggplot(aes(x=val,y=test,color=smp.size)) + geom_line() +\n",
    "   geom_vline(xintercept=c(sig2.0),linetype=c(\"solid\"),color=c(\"red\")) +\n",
    "   annotate(geom=\"text\",label=c(\"sigma2_0\"),\n",
    "            x=c(sig2.0),y=c(0.5),angle = 90,vjust = -1.5) +\n",
    "   geom_hline(yintercept=sig.lvl,linetype=\"dashed\",color=\"red\") +\n",
    "   annotate(geom=\"text\",label=\"Significance level\",\n",
    "            x=xlm.l+0.5,y=sig.lvl,vjust = -1) +\n",
    "   ggtitle(\"Power functions for a left one-sided test (variance)\") +\n",
    "   xlab(\"True value of the parameter\") + ylab(\" \") +\n",
    "   scale_colour_manual(\"sample sizes\", values = col.v, labels = smp.sz.v) +\n",
    "   theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "suppressWarnings(grid.arrange(plt.1,plt.2,nrow = 2,\n",
    "                              top=textGrob(\"Power functions for a test on the population mean\",gp=gpar(fontsize=15,col=\"blue\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f0e77-50dd-42d9-b252-a5cda920911c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Answer the following questions:</span>\n",
    "- <span style=\"color:green\">Compute the minimum sample size needed to ensure that the power of a one-sided hypothesis test on the population variance, when $\\sigma^2_0 = 2$ and the true value of the parameter is $\\sigma^2_1 = 3$, equals $0.5$ or more.</span>\n",
    "- <span style=\"color:green\">Does the power of a test depend on the sample you have collected? Provide some intuitive explanation for this fact.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d251b7-1177-4638-b71c-acb6946c30d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## <span style=\"color:brown\">Hypothesis testing and data science terminology</span>\n",
    "\n",
    "---\n",
    "\n",
    "Many practical cases involve applying a procedure to predict a certain outcome, which is represented with two possible values. This procedure can be interpreted as a hypothesis test based on data, but it is also common in practice for data scientists to interpret this situation as the outcome of a mathematical computation that returns either a 0 or a 1 value.\n",
    "\n",
    "Data scientists have a specific terminology to refer to this approach, which in many ways replicates the concepts we have seen in this lesson. In the following paragraphs we establish a relationship between these two collections of terms, the ones we have seen in this class and those commonly used in data science (machine learning), with the aim of familiarizing you with these terms.\n",
    "\n",
    "- <span style=\"color:brown\">Confusion matrix</span>. Given a model which has been applied $m$ times, and assuming we know the correct answer in each case, we can classify these $m$ outcomes using a <span style=\"color:brown\">confusion matrix</span>, defined as follows\n",
    "\n",
    "$$\n",
    "\\begin{array}{cc|cc}\n",
    "& & \\text{Prediction} & \\\\\n",
    "& & \\text{Positive} & \\text{Negative} \\\\\n",
    "\\hline\n",
    "\\text{Actual value} & \\text{Positive} & \\text{True positive (TP)} & \\text{False negative (FN)} \\\\\n",
    "& \\text{Negative} & \\text{False positive (FP)} & \\text{True negative (TN)}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "> A <span style=\"color:brown\">false negative (FN)</span> corresponds to what we have called a Type I error, while a <span style=\"color:brown\">false positive (FP)</span> would be equivalent to our Type II error. Note that this matrix represents what we would call a <span style=\"color:brown\">contingency table</span> in Statistics.</li></ul>\n",
    "\n",
    "- <span style=\"color:brown\">Accuracy</span>. It is defined as the sum of true positives and true negatives, divided by the total number of applications of the model. It estimates the probability of the model providing a correct answer, corresponding to one minus the probability of making an error, $1 - \\alpha - \\beta$.\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{TP} + \\mbox{TN}}{\\mbox{TP} + \\mbox{TN} + \\mbox{FP} + \\mbox{FN}}\n",
    "$$\n",
    "\n",
    "- <span style=\"color:brown\">Precision</span>. It is the number of true positives (TP), divided by the total number of predicted positives, that is, $\\mbox{TP} + \\mbox{FP}$,\n",
    "\n",
    "$$\n",
    "\\mbox{precision} = \\frac{\\mbox{TP}}{\\mbox{TP} + \\mbox{FP}}\n",
    "$$\n",
    "\n",
    "> It estimates the probability of $H_0$ being true conditioned on us failing to reject $H_0$.</li></ul>\n",
    "\n",
    "- <span style=\"color:brown\">Recall</span>. The number of true positives (TP) divided by the total number of actual positives, that is, $\\mbox{TP} + \\mbox{FN}$,\n",
    "\n",
    "$$\n",
    "\\mbox{recall} = \\frac{\\mbox{TP}}{\\mbox{TP} + \\mbox{FN}}\n",
    "$$\n",
    "\n",
    "> It estimates the probability of $H_0$ not being rejected conditioned on $H_0$ being true, that is, $1 - \\alpha$.</li></ul>\n",
    "\n",
    "- <span style=\"color:brown\">Specificity</span>. The number of true negatives (TN) divided by the total number of actual negatives, that is, $\\mbox{FP} + \\mbox{TN}$,\n",
    "\n",
    "$$\n",
    "\\mbox{specificity} = \\frac{\\mbox{TN}}{\\mbox{FP} + \\mbox{TN}}\n",
    "$$\n",
    "\n",
    "> It estimates the probability of rejecting $H_0$ conditioned on $H_0$ being false, that is, $1 - \\beta$, the power of the test.</li></ul>\n",
    "\n",
    "- <span style=\"color:brown\">F1 score</span>. In some cases we wish to measure both types of errors simultaneously. Although we could add both errors, similarly to what we did for the accuracy, the most usual way to combine this information consists in using the F1 score, defined as the harmonic mean of precision and recall, that is\n",
    "\n",
    "$$\n",
    "F_1 = \\frac{2\\times \\mbox{precision}\\times \\mbox{recall}}{\\mbox{precision} + \\mbox{recall}}\n",
    "$$\n",
    "\n",
    "> This definition takes into account that the number of observations that have an actual positive or negative value may be very different, and combines information for both cases in relative and approximately equivalent terms.</li></ul>\n",
    "\n",
    "- <span style=\"color:brown\">ROC curve</span>. In many cases we wish to study the behavior of a model for different values of a parameter. For example, the behavior of the errors in a hypothesis test as we change the critical value of the test, etc. In these cases it is common to use some graphical representations for the performance of the model, and one of the most common ones is the ROC curve.\n",
    "\n",
    "> This curve can be used to identify a better method when its area under the curve (AUC) is larger. It is defined as the curve plotting the false positive rate vs. the true positive rate (recall). The false positive rate is defined as</li></ul>\n",
    "\n",
    "$$\n",
    "\\mbox{false positive rate} = \\frac{\\mbox{FP}}{\\mbox{FP} + \\mbox{TN}} = 1 - \\mbox{specificity}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a0058-55ae-471c-bc54-d09c6919a78d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "<a id='App2_1'></a>\n",
    "\n",
    "## <span style=\"color:orange;\">Appendix 1: Power functions for normal data</span>\n",
    "\n",
    "---\n",
    "\n",
    "### <span style=\"color:orange;\">Computing the power for the mean of a normal population</span>\n",
    "\n",
    "Consider the case when we have a normal population, and we wish to compute the power of a test on the value of the population mean, with $H_0 \\, :\\, \\mu \\leq \\mu_0$. The value of the power function for this case is given by\n",
    "\n",
    "$$\n",
    "\\mbox{power} (\\mu_1) = \\Pr\\left( \\frac{\\bar X - \\mu_0}{S/\\sqrt{n}} > t_{n-1;\\alpha} \\; \\Bigl| \\; \\mu = \\mu_1 \\right) , \\qquad \\frac{\\bar X - \\mu_1}{S/\\sqrt{n}} \\sim t_{n-1}\n",
    "$$\n",
    "\n",
    "We compute this function by conditioning on all the possible values of $S$, and using the property that $(n-1)S^2/\\sigma^2 \\sim \\chi^2_{n-1}$. In the particular case with an alternative hypothesis $H_1 : \\mu > \\mu_0$,\n",
    "\n",
    "$$\n",
    "\\mbox{power} (\\mu_1; \\sigma^2) = \\Pr\\left( \\frac{\\bar X - \\mu_1}{S/\\sqrt{n}} + \\frac{\\mu_1 - \\mu_0}{S/\\sqrt{n}} > t_{n-1;\\alpha} \\; \\Bigl| \\; \\mu_1 \\right) = \\Pr\\left( T_{n-1} + \\frac{\\mu_1 - \\mu_0}{\\displaystyle \\sqrt{\\frac{\\chi^2_{n-1}\\sigma^2}{n(n-1)}}} > t_{n-1;\\alpha} \\right)\n",
    "$$\n",
    "\n",
    "and the function can be computed as\n",
    "\n",
    "$$\n",
    "\\mbox{power} (\\mu_1;\\sigma^2) = \\int_0^\\infty \\Pr\\left( T_{n-1} + \\frac{\\delta}{\\displaystyle \\sqrt{\\frac{\\sigma^2 x}{n(n-1)}}} > t_{n-1;\\alpha} \\right) f_{\\chi^2_{n-1}} (x) dx\n",
    "$$\n",
    "\n",
    "where $f_{\\chi^2_{n-1}} (x)$ denotes the density of a chi squared distribution with $n-1$ degrees of freedom computed at $x$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b16824-f065-461a-9e46-45c5c89aaf60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  },
  "rise": {
   "font-size": "0.5em",
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
