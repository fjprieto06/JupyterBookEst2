{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc4cdb9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <span style=\"color:brown\">Statistical inference: Confidence intervals</span>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2583eff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:brown;\">Contents</span>\n",
    "\n",
    "This chapter covers the contents from Lesson 1 in the subject, *\"Point estimators and confidence intervals\"*. These contents are related to the estimation of population parameters in one population, and are structured as follows:\n",
    "\n",
    "- Statistical inference: general definitions\n",
    "- Point estimators\n",
    "   - Estimation of the population mean and variance\n",
    "- Estimating the population mean using confidence intervals\n",
    "   - Confidence intervals for the mean in large samples\n",
    "   - Confidence intervals for the population proportion\n",
    "   - Confidence intervals for the mean of a normal population with unknown variance\n",
    "- Estimating the population variance using confidence intervals\n",
    "   - Confidence intervals for the variance of a normal population\n",
    "- Distributions of interest related to the normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c721c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:brown;\">Introduction</span>\n",
    "\n",
    "---\n",
    "\n",
    "### <span style=\"color:brown;\">Goals (i)</span>\n",
    "\n",
    "The main aims of the Statistics II course are to introduce and provide understanding of different procedures to conduct statistical inference, that is, to extract information from one or several samples, which might provide relevant knowledge about the parameters of a population. \n",
    "\n",
    "From a practical point of view, most questions of interest posed in real-life applications of Statistics to data analysis can be answered using some (approximate) knowledge of the distribution of the relevant variables. Using this knowledge would require identifying an appropriate law for the available data, as well as obtining good approximations to the values of the parameters associated with this law.\n",
    "\n",
    "In this course we will center on the second part of this problem, that is, the definition of efficient procedures for the approximation of the values of relevant population parameters, based on the information available in a sample of the variables of interest.\n",
    "\n",
    "These parameter values, used jointly with their associated probability distributions, allow us to estimate different measures of interest to understand real-life situations, and to make decisions based on our best possible information for uncertain variables. Also, these values in isolation provide basic but relevant information to explain, and to help to understand, the properties of the population of interest.\n",
    "\n",
    "This lesson will center on the problem of approximating the value of an individual population parameter. We will concentrate on the most common numerical summaries defined in Statistics I as measures of location and scale: the mean, the proportion, the variance or the standard deviation of a population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c14b3-1a0a-4278-a1f7-c0b8cc6a4460",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown;\">Goals (ii)</span>\n",
    "\n",
    "Our learning goals for this lesson are:\n",
    "\n",
    "- To understand what it means to estimate unknown population parameters from the sample data.\n",
    "- To understand why some estimators may be better than others, and to know some good estimators for the most usual parameters.\n",
    "- To provide a motivation to construct confidence intervals for population parameters from the sample data.\n",
    "   - And to be able to apply a general procedure to obtain these intervals.\n",
    "- For large samples: \n",
    "   - To know how to construct confidence intervals for the population mean and proportion.\n",
    "- In the case of a normal distribution:\n",
    "   - To know how to construct confidence intervals for the population mean and variance.\n",
    "- To know how to interpret a confidence interval.\n",
    "   - To understand the impact of the sample size, confidence level, etc. on the size of the confidence interval.\n",
    "   - To know how to calculate a sample size needed to ensure a given interval width.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cccda53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:brown;\">Keywords in statistics and statistical inference</span>\n",
    "\n",
    "We start by defining some basic concepts related to inference, which we will use throughout the course:\n",
    "\n",
    "- <span style=\"color:brown\">*Population:*</span> the complete set of numerical information on an uncertain quantity in which we may be interested.\n",
    "  - We identify the concept of the population with that of a random variable $X$.\n",
    "  - This concept is also associated to that of the law or the distribution of the population, or the distribution of $X$, $F_X$.\n",
    "- <span style=\"color:brown\">*Sample:*</span> an observed subset (say, of size $n$) of the population values.\n",
    "  - In practice, it is a set of $n$ numbers or lists of values having the same structure. It may contain outliers or it may have missing data.\n",
    "  - From a theoretical point of view, we will represent it as a collection of $n$ random variables $(X_1,X_2,\\ldots,X_n)$.\n",
    "- <span style=\"color:brown\">*Parameter:*</span> a constant characterizing $X$ or $F_X$.\n",
    "- <span style=\"color:brown\">*Statistical inference:*</span> the process of drawing conclusions about a population on the basis of measurements or observations made on a sample of individuals from the population.\n",
    "- <span style=\"color:brown\">*Statistic:*</span> a random variable obtained as a function of a random sample, $\\underline X_n \\equiv (X_1,X_2,\\ldots,X_n)$.\n",
    "- <span style=\"color:brown\">*Estimator of a parameter:*</span> a random variable obtained as a function, say $T (\\underline X_n ) = T(X_1,\\ldots,X_n)$, $T: \\mathbb{R}^n\\rightarrow \\mathbb{R}$, of a random sample, which is used to obtain information about an unknown population parameter of interest.\n",
    "- <span style=\"color:brown\">*Estimate:*</span> a specific realization of that random variable, i.e., $T$ evaluated at the observed sample, $(x_1,x_2,\\ldots,x_n)$, that provides an approximation to the unknown parameter of interest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a39a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:brown;\">Point estimators</span>\n",
    "\n",
    "---\n",
    "\n",
    "Our goal in this lesson is to define procedures that provide good approximations to the (unknown) values of population parameters, from the observed values in a random sample. In general, for any given parameter there exist many ways (different statistics) to combine the sample values to obtain an approximation for a parameter of interest. We would like to identify estimators that provide the best possible approximations, as functions of the observations in an available sample, where these samples are in general random collections of values from the population.\n",
    "\n",
    "We will approach this problem in two steps, by considering:\n",
    "1. How to obtain the best possible approximation given as a single value, from the information in our sample, by defining good <span style=\"color:brown\">*point estimators*</span>.\n",
    "2. How to use the information from our sample to obtain an approximation that is relevant, and coherent with the information available in most other possible samples, by incorporating to our estimator information about <span style=\"color:brown\">*the variability in all the samples*</span> from our sample/population. We will identify an interval that should contain the correct value of the parameter with high confidence. These approximations will be known as <span style=\"color:brown\">*confidence intervals*</span>.\n",
    "\n",
    "We start by commenting on the first of these steps, and in particular on:\n",
    "- Examples of estimators that we may use to approximate different parameters.\n",
    "- Desirable properties for these estimators, taking into account not only the possible errors in the approximation due to the limited information in our sample, but also the variability in these errors, due to the randomness of our samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27344ba0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:brown;\">Selecting a good point estimator</span>\n",
    "\n",
    "We wish to combine the information given in a sample to obtain a value that approximates an unknown population parameter. We formally define a <span style=\"color:brown\">point estimator</span> of the population parameter as a function, $T$, of a sample $\\underline X_n = (X_1,\\ldots,X_n)$ that yields a number approximating the value of the parameter of interest, $\\tilde T = T(\\underline X_n)$. Or alternatively, we can think of the estimator as the formula we will use to compute our approximation for the parameter.\n",
    "\n",
    "Our aim is to obtain a good approximation, as close as possible to the correct value. Our estimator $T$ is a random variable, as it depends on the available sample and our samples are in general random. As a consequence, it will take different values depending on the sample. A good estimator should achieve good results for any, or at least for most, of the possible random samples, as we do not control which sample will be available in a given case. As a consequence of the variability in these samples, it is not possible to guarantee that any given estimator will be able to provide, or even to be very close to the correct value. Our aim will have to be limited: to define estimators that have errors as small as possible over all possible samples.\n",
    "\n",
    "To define what a small error means in our setting, we will take into consideration the properties of these random variables, and their impact on the quality of the values they provide when trying to approximate the unknown value of the parameter. In this lesson we will consider the two most basic characterizations of the behavior of a random variable: its <span style=\"color:brown\">location</span> and <span style=\"color:brown\">spread</span> properties, and their impact on our approximations.\n",
    "\n",
    "*See the cell [Comparing different estimators](#Comparing_estimators) below for some examples motivating these properties.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5e7a8-1fd9-419f-86a4-7db57b6afb38",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:brown\">Theoretical properties of point estimators</span>\n",
    "\n",
    "---\n",
    "\n",
    "Based on our preceding comments, we introduce in this section the main properties we would like to have in a good estimator for any parameter of a population $\\theta$. To simplify our analysis, we will consider only the cases when the parameters of the population to be studied are its mean $\\theta = \\mu$ and its variance $\\theta = \\sigma^2$. These values are simple to approximate, their estimators have nice theoretical properties and the values they provide are very useful in many practical situations.\n",
    "\n",
    "As estimators are random variables, we will pay special attention to properties that ensure that the basic numerical summaries of the values of these estimators (their mean and variance) behave as expected, that is, that their values are such that any estimates obtained from random samples are as close as possible to the population value of interest. The study of these properties must be carried out in a general setting, by defining some desirable <span style=\"color:brown\">theoretical</span> properties for any estimator and studying the behavior of these properties for our estimators of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5c271-d9aa-495e-b51c-39565639c32a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:brown\">Bias of an estimator</span>\n",
    "\n",
    "If we consider the <span style=\"color:brown\">*mean*</span> of the estimator, we would like its value to be as close as possible to the correct population value. For a random variable, taking many different possible values, this will mean that the center of all these values, its mean, should coincide with the value we wish to approximate.\n",
    "\n",
    "Formally, we wish our estimator $T$ to satisfy <span style=\"color:brown\">$E[T] = \\theta .$</span> When this condition is satisfied, we say that the estimator is <span style=\"color:brown\">unbiased.</span>\n",
    "\n",
    "Let $E[X_i] = \\mu$ and $\\text{Var} (X_i) = \\sigma^2$. Then, the <span style=\"color:brown\">sample mean</span> is always unbiased, as\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "E[\\bar X] & = & E\\left[ \\frac{1}{n} \\left( X_1 + \\cdots + X_n \\right) \\right] = \\frac{1}{n} E\\left[ X_1 + \\cdots + X_n \\right] = \\frac{1}{n} \\left( E[ X_1 ] + \\cdots + E [ X_n ] \\right) \\\\\n",
    "& = & \\frac{1}{n} \\left( \\mu + \\cdots + \\mu \\right) = \\mu \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "But the <span style=\"color:brown\">sample variance</span> is not unbiased, as\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "E[\\hat \\sigma^2] & = & E\\left[ \\frac{1}{n} \\sum_{i=1}^n \\left( X_i - \\bar X \\right)^2 \\right] = \\frac{1}{n} n \\left( E\\left[X_i^2 \\right] - 2E\\left[X_i \\bar X \\right] + E\\left[ \\bar X^2 \\right] \\right) \\\\\n",
    "& = & \\sigma^2 + \\mu^2 - \\frac{2}{n} \\sum_{j=1}^n E\\left[X_i X_j \\right] + \\frac{1}{n} \\sigma^2 + \\mu^2 \\\\\n",
    "& = & \\frac{n+1}{n} \\sigma^2 + 2 \\mu^2 - \\frac{2}{n} E\\left[X_i^2 \\right] - \\frac{2}{n} \\sum_{i\\not=j} E[X_i] E[ X_j] \\\\\n",
    "& = & \\frac{n+1}{n} \\sigma^2 + 2 \\mu^2 - \\frac{2}{n} \\sigma^2 - \\frac{2}{n} \\mu^2 - \\frac{2(n-1)}{n} \\mu^2 = \\frac{n-1}{n} \\sigma^2 \\not= \\sigma^2\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where we have used $E[X^2] = \\text{Var} (X) + E[X]^2$, and $E[X_i X_j] = E[X_i]E[X_j]$ when $i \\not= j$.\n",
    "   \n",
    "From this result, the <span style=\"color:brown\">quasivariance</span> $s^2$ is an unbiased estimator of the population variance, as $s^2 = \\frac{n}{n-1} \\hat \\sigma^2$.\n",
    "\n",
    "Also, the <span style=\"color:brown\">sample median</span> is not unbiased for asymmetric distributions, where its value is different from that of the mean, but it is unbiased for symmetric distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e795c075-161a-43f0-950e-e1acaa2cbdff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:brown\">Efficiency of an estimator</span>\n",
    "\n",
    "We would like all the values of an estimator to be close to the correct population value, implying that these values should present low variability. As a consequence, we would like the <span style=\"color:brown\">*variance*</span> of an estimator to be as small as possible.\n",
    "\n",
    "When we compare different estimators, we say that an estimator with smaller variance is more <span style=\"color:brown\">efficient</span> than another with larger variance.\n",
    "\n",
    "The efficiency of an estimator will in general increase with the sample size $n$. For example, for the <span style=\"color:brown\">sample mean</span> $\\bar X$ we have that\n",
    "\n",
    "$$\n",
    "\\mbox{Var}(\\bar X) = \\mbox{Var} \\left( \\frac{1}{n} \\left( X_1 + \\cdots + X_n \\right) \\right) = \\frac{1}{n^2} \\left( \\mbox{Var} (X_1) + \\cdots + \\mbox{Var} (X_n) \\right) = \\frac{n\\mbox{Var} (X)}{n^2} = \\frac{\\mbox{Var} (X)}{n} .\n",
    "$$\n",
    "\n",
    "This result shows that the variance of the sample mean becomes arbitrarily small when $n$ is very large, and the efficiency of this estimator improves (arbitrarily) with the sample size.\n",
    "\n",
    "The efficiency of an estimator is directly related to the size of the error associated with using that estimator. Estimators that are very efficient imply much smaller errors in the values of their estimates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a21951f-81dc-443b-96a9-5aa8087626fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### <span style=\"color:brown\">Mean squared error of an estimator</span> \n",
    "\n",
    "In many practical situations we may have several available estimators with different values of their properties, bias and efficiency. When trying to determine which estimator is best, we may find ourselves with situations where two estimators might be such that one of them has smaller bias than the other, but the second one is more efficient. To be able to compare different estimators in these situations, it seems reasonable to use a criterion based on a combination of both properties.\n",
    "\n",
    "The combination that is most commonly used is the <span style=\"color:brown\">mean squared error (MSE)</span> of the estimator, defined as\n",
    "\n",
    "$$\n",
    "\\mbox{MSE}[\\hat \\theta_X] = E\\left[ (\\hat \\theta_X - \\theta_X)^2 \\right] = \\mbox{Var}[\\hat \\theta_X] + \\left( \\mbox{Bias}[\\hat \\theta_X] \\right)^2 = \\mbox{Var}[\\hat \\theta_X] + \\left( E[\\hat \\theta_X] - \\theta_X \\right)^2\n",
    "$$\n",
    "\n",
    "Note that:\n",
    "- The mean squared error of an unbiased estimator is equal to its variance.\n",
    "- An estimator with a smaller MSE is better than another one with a larger MSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a640d420-2a11-4675-a92c-f33231711d14",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*A simple random sample of 15 processing times (in minutes) of clients in a supermarket were recorded:*\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccccccccccccccc}\n",
    "5 & 6.2 & 4.8 & 5.2 & 5.2 & 6.4 & 4.9 & 5.3 & 4.2 & 5 & 5.9 & 5.1 & 6 & 4.9 & 5\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- *Compute unbiased estimates for the population mean and variance of these processing times.*\n",
    "- *Obtain an estimate for the population proportion of processing times shorter than 5 minutes.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89daf73-a49b-4ef9-a8b4-11153142fb43",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "We will use as unbiased estimators for the population mean and variance the sample mean and the sample quasivariance, respectively.\n",
    "\n",
    "For the sample mean, we have\n",
    "\n",
    "$$\n",
    "\\bar x = \\frac{5 + 6.2 + \\cdots + 4.9 + 5}{15} = 5.2733\n",
    "$$\n",
    "\n",
    "and for the sample quasivariance,\n",
    "\n",
    "$$\n",
    "s_x^2 = \\frac{\\sum_i x_i^2 - n \\bar x^2}{n-1} = \\frac{5^2 + 6.2^2 + \\cdots + 4.9^2 + 5^2 - 15\\times 5.2733^2}{14} = 0.35495\n",
    "$$\n",
    "\n",
    "To estimate the population proportion we will use the sample proportion, given by\n",
    "\n",
    "$$\n",
    "\\hat p_x = \\frac{0 + 0 + 1 + 0 + \\cdots + 0 + 1 + 0}{15} = \\frac{4}{15} = 0.2667\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc2c9d-8d4c-4390-b2c2-3f87a7ff1e49",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*Let $\\hat \\mu = \\frac{1}{4}(X_1 + X_2 + X_{n-1} + X_n)$ be an estimator of the population mean defined for a s.r.s. of size $n > 4$, obtained from a population with $E[X] = \\mu$ and $\\text{Var} (X) = \\sigma^2$.*\n",
    "\n",
    "*Compare the bias and efficiency properties of this estimator $\\hat \\mu$, with those of the sample mean $\\bar X$.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0adcbe6-7cad-4899-97e8-4b7aae58e0e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "From previous subjects (Statistics I) we know that the sample mean $\\bar{X}$ is an unbiased estimator of $\\mu$, whose variance is given by $\\displaystyle \\frac{\\sigma^2}{n}$.\n",
    "\n",
    "For the proposed estimator, $\\hat \\mu$, making use of $E[X_i] = \\mu$ and $\\text{Var} (X_i) = \\sigma^2$ for any $i=1,\\ldots,n$, we have:\n",
    "\n",
    "- <span style=\"color:brown\">Bias.</span> As the expected value of a sum of random variables is the sum of their expected values, we obtain\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "E[\\hat \\mu ] & = & E \\left[ \\frac{1}{4}(X_1 + X_2 + X_{n-1} + X_n) \\right] = \\frac{1}{4} (E[X_1] + E[X_2] + E[X_{n-1}] + E[X_n]) \\\\\n",
    "& = & \\frac{1}{4} (\\mu + \\mu + \\mu + \\mu) = \\mu\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "  implying that $\\text{Bias} (\\hat \\mu ) = E[\\hat \\mu ] - \\mu = 0$, that is, $\\hat \\mu$ is unbiased.\n",
    "\n",
    "- <span style=\"color:brown\">Efficiency.</span> We use the properties that the variance of a sum of independent random variables is the sum of their variances, and that $\\text{Var} (aX) = a^2 \\text{Var} (X)$, to obtain\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{Var}(\\hat \\mu ) & = & \\text{Var} \\left( \\frac{1}{4} (X_1 + X_2 + X_{n-1} + X_n) \\right) = \\frac{1}{4^2} \\left( \\text{Var}(X_1) + \\text{Var}(X_2) + \\text{Var}(X_{n-1}) + \\text{Var}(X_n) \\right) \\\\\n",
    "& = & \\frac{1}{16} (\\sigma^2 + \\sigma^2 + \\sigma^2 + \\sigma^2) = \\frac{\\sigma^2}{4}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "  This value is also the MSE for $\\hat \\mu$.\n",
    "\n",
    "- <span style=\"color:brown\">Relative efficiency.</span> We can compute the relative efficiency of these two estimators by dividing their variances,\n",
    "\n",
    "$$\n",
    "\\mbox{Relative efficiency}(\\bar X,\\hat \\mu ) = \\frac{\\sigma^2/n}{\\sigma^2/4} = \\frac{4}{n} ,\n",
    "$$\n",
    "\n",
    "  and as this ratio is smaller than 1, we conclude that $\\bar X$ is a more efficient estimator for $\\mu$ than $\\hat \\mu$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c37d4e2-b3ff-40c1-bfcf-823fe8df0a53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:blue;\">Preparing R and the data</span>\n",
    "\n",
    "---\n",
    "\n",
    "To illustrate the concepts we have introduced, and to motivate possible choices of good estimators, we will consider specific examples, mostly based on real data, which we will process using <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span>.\n",
    "\n",
    "We start by preparing <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> to read and manipulate the data mentioned above. In the following <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> <span style=\"color:brown\">code cell</span> we:\n",
    "\n",
    "1. Load the <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> libraries we are going to need for our examples.\n",
    "2. Define a function, <span style=\"color:blue;font-family:monospace;font-size:90%;\">table_prnt</span>, specifying the format for the tables that will present the numerical results in this lesson.\n",
    "3. Introduce information to work with the available data sets.\n",
    "\n",
    "The <span style=\"color:brown;\">available data sets</span> and their identifying codes are:\n",
    "\n",
    "1. Hourly prices for the Iberian electricity market\n",
    "2. Grades for a Statistics subject in UC3M\n",
    "3. Share prices for a company (Iberdrola) from the IBEX index\n",
    "4. Simulated data from a N(80,30) distribution (var 1), an Exp(lambda=1/30) distribution (var 2) and a Binom(20,0.4) distribution (var 3)\n",
    "5. Data from the Sustainable Develpment Report 2021, with the scores by country for goals 1 and 2\n",
    "\n",
    "In order to add another data set to this collection, you should include information for each of the following variables: the <span style=\"color:blue;font-family:monospace;font-size:90%;\">.csv</span> file containing the data and a text with a short description for the data.\n",
    "\n",
    "It is also important to ensure that the <span style=\"color:brown;\">working directory</span> has been <span style=\"color:brown;\">selected correctly,</span> as the directory that includes all the data sets that could be used in this lesson.\n",
    "\n",
    "To execute the commands in the cell, select the cell by clicking on it, and then <span style=\"color:blue;\">press the **RUN** button</span> in the menu bar, or press <span style=\"color:blue;\">Shift-Enter.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6aaa3f-69b0-4029-8897-108a743bc633",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#options(jupyter.plot_mimetypes = c(\"text/plain\",\"image/png\"))\n",
    "\n",
    "# Load libraries with R functions\n",
    "\n",
    "suppressMessages(library(tidyverse))\n",
    "suppressMessages(library(huxtable))\n",
    "library(knitr)\n",
    "suppressMessages(library(kableExtra))\n",
    "library(IRdisplay)\n",
    "suppressMessages(library(gridExtra))\n",
    "suppressMessages(library(qqplotr))\n",
    "suppressMessages(library(GGally))\n",
    "suppressMessages(library(car))\n",
    "library(grid)\n",
    "\n",
    "# Define a function to format and print the results of interest\n",
    "\n",
    "outp.type = 0   # = 1 for html output, = 0 for Jupyter Books\n",
    "\n",
    "if (outp.type == 1) {\n",
    "    table_prnt <- function(p.df,p.capt) {\n",
    "    # A function to control the presentation of tables with numerical summaries\n",
    "    p.df %>% kable(\"html\",caption=paste0('<em>',p.capt,'</em>'),align='r') %>%\n",
    "    kable_styling(full_width = F, position = \"left\") %>% as.character() %>% display_html()\n",
    "    }\n",
    "    } else {\n",
    "    table_prnt <- function(p.df,p.capt) {\n",
    "    # A function to control the presentation of tables with numerical summaries\n",
    "    p.df %>% kable(\"simple\",caption=p.capt,align='r')\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff767eb-37c0-4941-828b-0690cd78f818",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <span style=\"color:blue;\">Examples based on selected data sets</span>\n",
    "\n",
    "---\n",
    "\n",
    "To illustrate the concepts we have introduced, and to motivate possible choices of good estimators, we will consider specific examples, mostly based on real data, which we will process using <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1af43-0dc7-4f4b-9775-cc233755bc5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Selecting and displaying the data set and the variable of interest</span>\n",
    "\n",
    "We select one of these data sets and the variable of interest in the following cell.\n",
    "\n",
    "1. We assign the corresponding number to the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">sel.data</span>, at the start of the following code cell.\n",
    "2. We read the file and include the data in a <span style=\"color:brown;\">data frame</span> with the name <span style=\"color:blue;font-family:monospace;font-size:90%;\">Data.fr</span>.\n",
    "3. We assign the number corresponding to the order of the variable of interest in the data set, to the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">sel.col</span>.\n",
    "4. We assign the values of the variable to an <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> data frame with the name <span style=\"color:blue;font-family:monospace;font-size:90%;\">data.sel</span>. This data frame will contain a single variable (column) with the name <span style=\"color:blue;font-family:monospace;font-size:90%;\">Val</span>.\n",
    "\n",
    "Finally, we print the names of the selected data set and variable, to check that these values are correct. Then we display some of the values from the <span style=\"color:blue;font-family:monospace;font-size:90%;\">.csv</span> file, keeping the same structure of the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293526d-2af4-458a-9ac7-8bcd0e94d5f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the data set of interest\n",
    "\n",
    "## Datasets that are available for this lesson\n",
    "\n",
    "v.pref = data.frame(file = c(\"Dat_PreciosOMIE.csv\",     # Name of the .csv data file\n",
    "                            \"Dat_Calificaciones.csv\",\n",
    "                            \"Dat_PreciosIBE_MC.csv\",\n",
    "                            \"Dat_SimulatedData.csv\",\n",
    "                            \"Dat_SDR21.csv\"))\n",
    "v.pref$title = c(\"Electricity prices\",         # Short title for the data\n",
    "                \"Grades\",\n",
    "                \"Share returns\",\n",
    "                \"Simulated data\",\n",
    "                \"SDG 2021 Scores\")\n",
    "\n",
    "## Indicate the data set and variable to select\n",
    "## These values can be modified\n",
    "\n",
    "sel.data = 5\n",
    "sel.col = 6\n",
    "\n",
    "## Read the data\n",
    "\n",
    "s.pref = v.pref[sel.data,]\n",
    "\n",
    "Data.fr = read.csv2(s.pref$file)\n",
    "data.sel = as.data.frame(Data.fr[,sel.col])\n",
    "colnames(data.sel) = c(\"Val\")\n",
    "\n",
    "## Summary of the selected data\n",
    "\n",
    "descr.df = as.data.frame(c(s.pref$title,colnames(Data.fr)[sel.col]))\n",
    "colnames(descr.df) <- c(\"Selection\")\n",
    "rownames(descr.df) <- c(\"Data set\",\"Variable\")\n",
    "\n",
    "Data.hux.0 <-\n",
    "  hux(descr.df) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "table_prnt(Data.hux.0[-1,],\"\")\n",
    "\n",
    "# Print a part of the data we have selected\n",
    "\n",
    "max.row.show = 8       # Max number of individual values to show\n",
    "max.col.show = 6       # Max number of variables to show\n",
    "\n",
    "n.row.show = min(nrow(Data.fr),max.row.show)\n",
    "n.col.show = min(ncol(Data.fr),max.col.show)\n",
    "\n",
    "Data.hux.1 <-\n",
    "  hux(Data.fr[1:n.row.show,1:n.col.show]) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "rownames(Data.hux.1) <- c(0:n.row.show)\n",
    "table_prnt(Data.hux.1[-1,],s.pref$title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33e775-06c4-475f-b302-7622f46049f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Summaries for the sample data</span>\n",
    "\n",
    "In the following cell we conduct some simple exploratory analysis of the data from the variable we have selected: we compute some of its most relevant numerical summaries, such as its mean, standard deviation and median.\n",
    "\n",
    "We also draw a boxplot of the sample data corresponding to this variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2723312-2dd3-4f01-ab8e-b6ea09e63900",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print summaries from the selected data set\n",
    "\n",
    "smp0.sz = nrow(data.sel)\n",
    "smp0.mn = mean(data.sel$Val)\n",
    "smp0.sd = sd(data.sel$Val)\n",
    "smp0.var = smp0.sd^2\n",
    "smp0.med = median(data.sel$Val)\n",
    "Sum.fr = as.data.frame(round(matrix(c(smp0.sz,smp0.mn,smp0.sd,smp0.med),4,1),3))\n",
    "\n",
    "Data.hux.2 <-\n",
    "  hux(Sum.fr) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux.2) <- c(\"\",\"Sample size\",\"Mean\",\"Standard deviation\", \"Median\")\n",
    "colnames(Data.hux.2) <- c(\"Values\")\n",
    "table_prnt(Data.hux.2[-1,],sprintf(\"%s summary\",s.pref$title))\n",
    "\n",
    "## Boxplot for the data\n",
    "\n",
    "plt.1 = data.sel %>% ggplot(aes(y=Val)) + geom_boxplot() +\n",
    "  ggtitle(sprintf(\"%s\",s.pref$title)) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  theme(axis.title.x = element_blank(),axis.text.x=element_blank(),axis.ticks.x=element_blank())\n",
    "plot(plt.1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39929382-bc6b-4d02-af87-914d6678c2e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:blue\">Estimating parameters from the data</span>\n",
    "\n",
    "To illustrate the properties of our estimators, and the quality of the results we obtain from them, we would need to compare these estimated values with the corresponding values for the population parameters. But when we work with real data, in nearly all cases we do not know these population values.\n",
    "\n",
    "To overcome this problem in some measure, we will conduct an experiment based on assuming that the data we have collected is all the information we care about regarding the values of the selected variable (our population). Based on this definition for our population, we will conduct different experiments based on comparing the results generated by the estimators obtained for many random subsamples, with the population value of interest.\n",
    "\n",
    "To simplify these comparisons, in each of them we will generate subsamples with the same size. And as we mentioned before, we will identify the value of the population parameter with the corresponding value estimated for the full sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699fd21-268d-4b19-a9d3-0aba81b1dc54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='Comparing_estimators'></a>\n",
    "\n",
    "### <span style=\"color:blue;\">Comparing different estimators</span>\n",
    "\n",
    "In our first experiment we aim to illustrate the main characteristics of different estimators. We would like to emphasize their different behavior when trying to approximate the correct value of the parameter, and to provide a starting point to discuss what characteristic of each of these random variables (the estimators) is more relevant to provide a good approximation.\n",
    "\n",
    "The experiment is based on the selection of a group of estimators and the generation of many values for these estimators, based on random samples of a fixed size. These random samples have been obtained by selecting observations in our data set with the same probability and independently of each other. To do this, we have used the <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> function <span style=\"color:blue;font-family:monospace;font-size:90%;\">sample</span>.\n",
    "\n",
    "The experiment is conducted in the <span style=\"color:blue;font-family:monospace;font-size:90%;\">R</span> code cell below. We will select a random collection of $m$ samples of size $n$ from our variable. We define our value of $m$ (<span style=\"color:brown\">the number of samples to generate</span>) in a variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">n.samples</span> defined at the start of the cell, jointly with a value for $n$ (<span style=\"color:brown\">the sample size of each sample</span>), which we introduce using another variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">smp.sz.prop</span>, indicating the proportion of the total observations that we include in each sample. \n",
    "\n",
    "From each sample we compute the following measures (estimates):\n",
    "1. To approximate the population mean:\n",
    "   - The sample mean\n",
    "   - The average of the $n/2$ central observations\n",
    "   - The average of the two most extreme observations\n",
    "   - The sample median\n",
    "2. To approximate the population variance:\n",
    "   - The sample variance\n",
    "   - The sample quasivariance\n",
    "   - The square of the sample MAD (median absolute deviation), corrected for consistency under normality\n",
    "   - The sample variance of the $n/2$ central observations, corrected for consistency under normality\n",
    "\n",
    "The choice of estimators indicated above is quite arbitrary. This experiment could be repeated with other definitions of approximations for the mean and the variance, although the general results should be similar.\n",
    "\n",
    "To analize their performance, for each one of the preceding estimators we draw a histogram using their values for all the samples we have generated. In that histogram we also plot the correct value (the population parameter) as a red vertical line, in order to compare the values provided by each estimator and to help assess the quality of their approximations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd438e51",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Histograms for different estimators\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "n.samples = 500\n",
    "smp.sz.prop = 0.2\n",
    "\n",
    "## Parameters\n",
    "\n",
    "smp.sz = floor(smp.sz.prop*smp0.sz)\n",
    "s.1 = floor(0.25*smp.sz)\n",
    "s.2 = ceiling(0.75*smp.sz)\n",
    "\n",
    "## Generate samples and estimates\n",
    "\n",
    "mn.smp = cmn.smp = xmn.smp = md.smp = NULL\n",
    "var.smp = qvar.smp = mad.smp = cvar.smp = NULL\n",
    "for (i in 1:n.samples) {\n",
    "    v.smp = sample(data.sel$Val, smp.sz, replace = FALSE)\n",
    "    v.srt = sort(v.smp)\n",
    "    vc.smp = v.srt[s.1:s.2]\n",
    "    \n",
    "    mn.smp = c(mn.smp,mean(v.smp))\n",
    "    cmn.smp = c(cmn.smp,mean(vc.smp))\n",
    "    xmn.smp = c(xmn.smp,(min(v.smp)+max(v.smp))/2)\n",
    "    md.smp = c(md.smp,median(v.smp))\n",
    "    \n",
    "    var.smp = c(var.smp,var(v.smp)*(smp.sz-1)/smp.sz)\n",
    "    qvar.smp = c(qvar.smp,var(v.smp))\n",
    "    mad.smp = c(mad.smp,mad(v.smp)^2)\n",
    "    cvar.smp = c(cvar.smp,var(vc.smp)/0.144)\n",
    "}\n",
    "\n",
    "s.mn.smp = as.data.frame(cbind(mn.smp,cmn.smp,xmn.smp,md.smp))\n",
    "colnames(s.mn.smp) = c(\"mean\",\"central\",\"extreme\",\"median\")\n",
    "\n",
    "s.var.smp = as.data.frame(cbind(var.smp,qvar.smp,mad.smp,cvar.smp))\n",
    "colnames(s.var.smp) = c(\"sv\",\"sqv\",\"mad\",\"central\")\n",
    "\n",
    "## Obtain the histograms\n",
    "\n",
    "x.mn = min(s.mn.smp)\n",
    "x.mx = max(s.mn.smp)\n",
    "\n",
    "n.bin.0 = 20\n",
    "n.bin.1 = floor(n.bin.0*(x.mx - x.mn)/(max(s.mn.smp$mean) - min(s.mn.smp$mean)))\n",
    "n.bin.2 = floor(n.bin.0*(x.mx - x.mn)/(max(s.mn.smp$central) - min(s.mn.smp$central)))\n",
    "n.bin.3 = floor(n.bin.0*(x.mx - x.mn)/(max(s.mn.smp$extreme) - min(s.mn.smp$extreme)))\n",
    "n.bin.4 = floor(n.bin.0*(x.mx - x.mn)/(max(s.mn.smp$median) - min(s.mn.smp$median)))\n",
    "\n",
    "plt.h.1 = s.mn.smp %>% ggplot(aes(x=mean)) + geom_histogram(bins = n.bin.1) +\n",
    "  ggtitle(\"Sample mean\") + xlim(x.mn,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"red\",linewidth=0.5)\n",
    "plt.h.2 = s.mn.smp %>% ggplot(aes(x=central)) + geom_histogram(bins = n.bin.2) +\n",
    "  ggtitle(\"Central mean\") + xlim(x.mn,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"red\",linewidth=0.5)\n",
    "plt.h.3 = s.mn.smp %>% ggplot(aes(x=extreme)) + geom_histogram(bins = n.bin.3) +\n",
    "  ggtitle(\"Extreme mean\") + xlim(x.mn,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"red\",linewidth=0.5)\n",
    "plt.h.4 = s.mn.smp %>% ggplot(aes(x=median)) + geom_histogram(bins = n.bin.4) +\n",
    "  ggtitle(\"Sample median\") + xlim(x.mn,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"red\",linewidth=0.5)\n",
    "\n",
    "x.mx = 0.75*max(s.var.smp)\n",
    "\n",
    "n.bin.0 = 20\n",
    "n.bin.1 = floor(n.bin.0*x.mx/(max(s.var.smp$sv) - min(s.var.smp$sv)))\n",
    "n.bin.2 = floor(n.bin.0*x.mx/(max(s.var.smp$sqv) - min(s.var.smp$sqv)))\n",
    "n.bin.3 = floor(n.bin.0*x.mx/(max(s.var.smp$mad) - min(s.var.smp$mad)))\n",
    "n.bin.4 = floor(n.bin.0*x.mx/(max(s.var.smp$central) - min(s.var.smp$central)))\n",
    "\n",
    "plt.h.5 = s.var.smp %>% ggplot(aes(x=sv)) + geom_histogram(bins = n.bin.1) +\n",
    "  ggtitle(\"Sample variance\") + xlim(0,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.var,color = \"red\",linewidth=0.5)\n",
    "plt.h.6 = s.var.smp %>% ggplot(aes(x=sqv)) + geom_histogram(bins = n.bin.2) +\n",
    "  ggtitle(\"Sample quasivariance\") + xlim(0,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.var,color = \"red\",linewidth=0.5)\n",
    "plt.h.7 = s.var.smp %>% ggplot(aes(x=mad)) + geom_histogram(bins = n.bin.3) +\n",
    "  ggtitle(\"MAD\") + xlim(0,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.var,color = \"red\",linewidth=0.5)\n",
    "plt.h.8 = s.var.smp %>% ggplot(aes(x=central)) + geom_histogram(bins = n.bin.4) +\n",
    "  ggtitle(\"Central variance\") + xlim(0,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.var,color = \"red\",linewidth=0.5)\n",
    "\n",
    "## Plot the histograms\n",
    "\n",
    "cat(sprintf('Sample size = %6.0f\\n',smp.sz))\n",
    "suppressWarnings(grid.arrange(plt.h.1,plt.h.2,plt.h.3,plt.h.4,nrow = 4,\n",
    "                              top=textGrob(\"Population mean estimators\",gp=gpar(fontsize=15,col=\"blue\"))))\n",
    "suppressWarnings(grid.arrange(plt.h.5,plt.h.6,plt.h.7,plt.h.8,nrow = 4,\n",
    "                              top=textGrob(\"Population variance estimators\",gp=gpar(fontsize=15,col=\"blue\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c5624-bd8c-4da5-9041-97e5c53cb7c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Take a look at these plots and answer the following questions:</span>\n",
    "- <span style=\"color:green\">Which characteristics of each histogram indicate if a given estimator provides a good approximation to the population value?</span>\n",
    "- <span style=\"color:green\">Which estimators are the best ones for each population value of interest?</span>\n",
    "- <span style=\"color:green\">How does the quality of the estimators change with the sample size? To do this, change the value of </span> <span style=\"color:blue;font-family:monospace;font-size:90%;\">smp.sz.prop</span> <span style=\"color:green\"> in the preceding cell, or duplicate the cell using different values for this variable</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de13ab2-ef4f-4825-b101-7b60aef6e161",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:blue;\">Examples of estimator bias</span>\n",
    "\n",
    "In the following cell we represent the histograms of different estimators, and we compare them with the known value of the corresponding population parameter.\n",
    "\n",
    "We wish to pay particular attention at the possible bias of these different estimators. To help with this, we have also represented in the corresponding plots the mean values, obtained from the generated samples, for these estimators.\n",
    "\n",
    "In the plots the correct population value is shown in red, while the value of the mean of the sample estimates is shown in blue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290e69e-af32-4cf1-96c2-f9a462171e1a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Histograms for different estimators (bias comparison)\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "n.samples = 500\n",
    "smp.sz.prop = 0.5\n",
    "\n",
    "## Parameters\n",
    "\n",
    "smp.sz = floor(smp.sz.prop*smp0.sz)\n",
    "\n",
    "## Generate samples and estimates\n",
    "\n",
    "mn.smp = md.smp = NULL\n",
    "for (i in 1:n.samples) {\n",
    "    v.smp = sample(data.sel$Val, smp.sz, replace = FALSE)\n",
    "    mn.smp = c(mn.smp,mean(v.smp))\n",
    "    md.smp = c(md.smp,median(v.smp))\n",
    "    xmn.smp = c(xmn.smp,(min(v.smp)+max(v.smp))/2)\n",
    "}\n",
    "\n",
    "s.mn.smp = as.data.frame(cbind(mn.smp,xmn.smp,md.smp))\n",
    "colnames(s.mn.smp) = c(\"mean\",\"extreme\",\"median\")\n",
    "\n",
    "## Obtain the histograms\n",
    "\n",
    "x.mn = min(s.mn.smp)\n",
    "x.mx = max(s.mn.smp)\n",
    "\n",
    "n.bin.0 = 20\n",
    "n.bin.1 = floor(n.bin.0*(x.mx - x.mn)/(max(s.mn.smp$mean) - min(s.mn.smp$mean)))\n",
    "n.bin.2 = floor(n.bin.0*(x.mx - x.mn)/(max(s.mn.smp$extreme) - min(s.mn.smp$extreme)))\n",
    "n.bin.3 = floor(n.bin.0*(x.mx - x.mn)/(max(s.mn.smp$median) - min(s.mn.smp$median)))\n",
    "\n",
    "plt.h.1 = s.mn.smp %>% ggplot(aes(x=mean)) + geom_histogram(bins = n.bin.1) +\n",
    "  ggtitle(\"Sample mean\") + xlim(x.mn,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"red\",linewidth=0.5) +\n",
    "  geom_vline(xintercept=mean(s.mn.smp$mean),color = \"blue\",linewidth=0.5)\n",
    "plt.h.2 = s.mn.smp %>% ggplot(aes(x=extreme)) + geom_histogram(bins = n.bin.2) +\n",
    "  ggtitle(\"Extreme mean\") + xlim(x.mn,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"red\",linewidth=0.5) +\n",
    "  geom_vline(xintercept=mean(s.mn.smp$extreme),color = \"blue\",linewidth=0.5)\n",
    "plt.h.3 = s.mn.smp %>% ggplot(aes(x=median)) + geom_histogram(bins = n.bin.3) +\n",
    "  ggtitle(\"Sample median\") + xlim(x.mn,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"red\",linewidth=0.5) +\n",
    "  geom_vline(xintercept=mean(s.mn.smp$median),color = \"blue\",linewidth=0.5)\n",
    "\n",
    "## Plot the histograms\n",
    "\n",
    "cat(sprintf('Sample size = %6.0f',smp.sz))\n",
    "suppressWarnings(grid.arrange(plt.h.1,plt.h.2,plt.h.3,nrow = 3,\n",
    "                              top=textGrob(\"Bias comparison for mean estimators\",gp=gpar(fontsize=15,col=\"blue\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5965a-5caf-4e1e-8daf-f6a1ccebf5b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Take a look at these plots and answer the following questions:</span>\n",
    "- <span style=\"color:green\">From this information, could you say that any of these estimators are unbiased/biased?</span>\n",
    "- <span style=\"color:green\">Which estimator seems to have the largest bias?</span>\n",
    "- <span style=\"color:green\">Is the bias affected by the sample size? You can change the value of </span> <span style=\"color:blue;font-family:monospace;font-size:90%;\">smp.sz.prop</span> <span style=\"color:green\">in the preceding cell, or duplicate the cell using different values for this variable</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55004325-ab8e-4672-824d-993e8b0e18d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:blue;\">Examples of estimator efficiency</span>\n",
    "\n",
    "The following cell presents the sample estimates obtained for different estimators, as well as the known value of the corresponding population parameter, in this case the population mean. As a difference with the preceding code cell, we wish to study now the behavior of the different estimators with respect to their efficiency.\n",
    "\n",
    "We represent the histogram of their values for the different samples, with the aim of comparing the spread of these values, which represents their different efficiencies. The scales of the different histograms have been chosen to be the same, to facilitate the comparisons of these spreads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0ae44-e044-4104-ab8c-8c8f6d5d106b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Histograms for different estimators (efficiency comparisons)\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "n.samples = 500\n",
    "smp.sz.prop = 0.2\n",
    "\n",
    "## Parameters\n",
    "\n",
    "smp.sz = floor(smp.sz.prop*smp0.sz)\n",
    "\n",
    "## Generate samples and estimates\n",
    "\n",
    "mn.smp = xmn.smp = NULL\n",
    "for (i in 1:n.samples) {\n",
    "    v.smp = sample(data.sel$Val, smp.sz, replace = FALSE)\n",
    "    mn.smp = c(mn.smp,mean(v.smp))\n",
    "    md.smp = c(md.smp,median(v.smp))\n",
    "    xmn.smp = c(xmn.smp,(min(v.smp)+max(v.smp))/2)\n",
    "}\n",
    "\n",
    "s.mn.smp = as.data.frame(cbind(mn.smp,xmn.smp,md.smp))\n",
    "colnames(s.mn.smp) = c(\"mean\",\"extreme\",\"median\")\n",
    "\n",
    "## Obtain the histograms\n",
    "\n",
    "x.mn = min(s.mn.smp)\n",
    "x.mx = max(s.mn.smp)\n",
    "\n",
    "n.bin.0 = 20\n",
    "n.bin.1 = floor(n.bin.0*(x.mx - x.mn)/(max(s.mn.smp$mean) - min(s.mn.smp$mean)))\n",
    "n.bin.2 = floor(n.bin.0*(x.mx - x.mn)/(max(s.mn.smp$extreme) - min(s.mn.smp$extreme)))\n",
    "n.bin.3 = floor(n.bin.0*(x.mx - x.mn)/(max(s.mn.smp$median) - min(s.mn.smp$median)))\n",
    "\n",
    "plt.h.1 = s.mn.smp %>% ggplot(aes(x=mean)) + geom_histogram(bins = n.bin.1) +\n",
    "  ggtitle(\"Sample mean\") + xlim(x.mn,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"red\",linewidth=0.5)\n",
    "plt.h.2 = s.mn.smp %>% ggplot(aes(x=extreme)) + geom_histogram(bins = n.bin.2) +\n",
    "  ggtitle(\"Extreme mean\") + xlim(x.mn,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"red\",linewidth=0.5)\n",
    "plt.h.3 = s.mn.smp %>% ggplot(aes(x=median)) + geom_histogram(bins = n.bin.3) +\n",
    "  ggtitle(\"Sample median\") + xlim(x.mn,x.mx) +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "  geom_vline(xintercept=smp0.mn,color = \"red\",linewidth=0.5)\n",
    "\n",
    "## Plot the histograms\n",
    "\n",
    "cat(sprintf('Sample size = %6.0f\\n',smp.sz))\n",
    "suppressWarnings(grid.arrange(plt.h.1,plt.h.2,plt.h.3,nrow = 3,\n",
    "                              top=textGrob(\"Efficiency comparison for mean estimators\",gp=gpar(fontsize=15,col=\"blue\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d66d9-4535-4b7d-9728-3901e5e09980",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Take a look at these plots and answer the following questions:</span>\n",
    "- <span style=\"color:green\">From this information, which estimator seems to be the most efficient?</span>\n",
    "- <span style=\"color:green\">Is the efficiency affected by the sample size? You can change the value of </span> <span style=\"color:blue;font-family:monospace;font-size:90%;\">smp.sz.prop</span> <span style=\"color:green\">in the preceding cell, or duplicate the cell using different values for this variable</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b758736-9776-450a-b3fa-450a20c61f81",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown;\">Defining good estimators</span>\n",
    "\n",
    "Based on the preceding description of the properties we would like to have when defining an estimator, it seems reasonable to ask if there exist general procedures to define estimators $T$ of a parameter $\\theta$ having these good properties.\n",
    "\n",
    "- In some situations, there exists an optimal estimator called the <span style=\"color:brown\">minimum variance unbiased estimator</span>, defined as the estimator with the smallest variance/MSE among all unbiased estimators. This would be our best option.\n",
    "   - For example, the sample mean is the minimum variance unbiased estimator for the population mean when we have normal data.\n",
    "- If we do not have such an estimator, different methods yield estimators with reasonably good properties. Examples of these methods are:\n",
    "   - Maximum likelihood estimation.\n",
    "   - The method of moments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a69cf-90b3-481d-9f57-3dc645abc8a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown;\">Examples of estimators with good properties</span>\n",
    "\n",
    "- Examples of population parameters, estimators and estimates. Estimators with low bias and high efficiency:\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\\begin{array}{llccc}\n",
    "\\text{Population parameter} & \\text{Sample value} & T(\\underline X_n) & \\text{Estimator} & \\text{Estimate} \\\\\n",
    "\\hline\n",
    "\\text{Mean } \\mu_X & \\text{Sample mean} & \\displaystyle \\frac{1}{n}(X_1 + \\cdots + X_n) & \\bar X = \\hat \\mu_X & \\bar x \\\\\n",
    "\\text{Proportion } p_X & \\text{Sample proportion} & \\displaystyle \\frac{1}{n} (\\# \\text{ favorable cases}) & \\hat p_X & \\hat p_x \\\\\n",
    "\\text{Variance } \\sigma^2_X & \\text{Sample quasivariance} & \\displaystyle \\frac{1}{n-1} (X_1^2 + \\cdots + X_n^2 - n \\bar X^2) & s_X^2 & s_x^2 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d034d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## <span style=\"color:brown\">Confidence intervals</span>\n",
    "\n",
    "---\n",
    "\n",
    "Point estimators should provide good approximations to the values of interest, the parameters of the population. But the random nature of the values of the estimator, a consequence of the random nature of our samples, implies that their values, the estimates, will in general be incorrect (they will include errors). From a practical point of view, it is very important to use estimators that have small errors asociated to their estimates, as we have already discussed. And it is also important to be able to provide information on the size of these errors.\n",
    "\n",
    "The errors will be a consequence of the variability in the approximations provided by a certain estimator for different random samples, obtained from our knowledge of the <span style=\"color:brown\">distribution</span> of the estimators. This use of distributions is significantly different from our treatment of the point estimators; it also implies that many of the definitions and properties we will introduce will depend on probabilities.\n",
    "\n",
    "The information about the errors can be presented in different ways; some of the most common are:\n",
    "- To provide an estimate of the variability of the estimator, from the values of the sample. The most usual estimate is the <span style=\"color:brown\">standard error,</span> that is, the standard deviation of the estimator.\n",
    "- To construct an interval, which will be referred to as a <span style=\"color:brown\">confidence interval,</span> giving a range of values containing the unknown population value, in most cases.\n",
    "\n",
    "This additional information does not aim to improve the error in our estimate; we are obtaining additional information from the inference process that in general is very useful when using our estimates for practical applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f024785-cf5d-40ff-a06b-fded4b276e2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### <span style=\"color:brown\">Definition of confidence intervals: a theoretical example</span>\n",
    "\n",
    "As our estimator is a random variable, it makes sense to compute an interval that will contain the possible values of this random variable with high probability, based on our knowledge of its distribution.\n",
    "\n",
    "For example, if we consider the sample mean $\\bar X$ as an estimator for the population mean $\\mu$, and if we can apply the CLT (we have a large enough sample), this result indicates that the sample mean (a sum of independent and identically distributed random variables) follows approximately a normal distribution, and we have\n",
    "\n",
    "$$\n",
    "\\bar X \\sim_{\\scriptsize \\text{approx.}} N\\left( \\mu,\\frac{\\sigma^2}{n} \\right)\n",
    "$$\n",
    "\n",
    "It also holds that\n",
    "\n",
    "$$\n",
    "\\frac{\\bar X - \\mu}{s/\\sqrt{n}} \\sim_{\\scriptsize \\text{approx.}} N(0,1)\n",
    "$$\n",
    "\n",
    "For any given probability $1 - \\alpha$ we can interpret this result as implying that\n",
    "\n",
    "$$\n",
    "\\Pr \\left( -z_{\\alpha} < \\frac{\\bar X - \\mu}{s/\\sqrt{n}} \\leq z_{\\alpha} \\right) \\approx 1 - \\alpha \n",
    "$$\n",
    "\n",
    "where $z_{\\alpha/2}$ is the $\\alpha/2$ right-quantile of a standard normal distribution, $\\Pr(Z > z_{\\alpha/2}) = \\alpha/2$. Thus, \n",
    "the interval $\\mu \\mp z_{\\alpha/2} s/\\sqrt{n}$ contains the values of $\\bar X$ for all simple random samples with probability $1 - \\alpha$ (approximately). We will refer to this probability $1 - \\alpha$ as the <span style=\"color:brown\">confidence level</span> of the interval; it measures how likely is it that the confidence interval will contain the correct (unknown) value.\n",
    "\n",
    "But as $\\mu$ is an unknown value, this is not the type of interval we wish to obtain. For our case of interest (inference) we know the values for a sample but we do not know the value of $\\mu$, which we would like to approximate. Fortunately, it is possible to obtain another interval for $\\mu$, given some estimate for $\\bar X$, using the formula for the preceding interval. We can rewrite it as\n",
    "\n",
    "$$\n",
    "   \\mu \\in \\left[ \\bar x - z_{\\alpha/2} \\frac{s}{\\sqrt{n}} \\; ; \\; \\bar x + z_{\\alpha/2} \\frac{s}{\\sqrt{n}} \\right]\n",
    "$$\n",
    "\n",
    "This would be an example of a confidence interval, as it provides an interval where the unknown value $\\mu$ can be found for a high proportion of different samples obtained from the same distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9e38d-6dfc-4daa-a389-ac4604e0373c",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*An industrial production line is supposed to fill out containers with a substance to a target weight of 16 grams. A quality control inspector selects a sample of forty containers, which yields a sample mean weight of $16.31$ grams. Its quasi-variance is $0.82$ grams${}^2$.*\n",
    "\n",
    "*Compute a confidence interval for the population mean with a confidence level of 90%*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ade7b-5fe6-457b-8031-763584102535",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "For the population of packages produced in this line, we define the continuous random variable $X =$ \"fill weight of a package\".\n",
    "\n",
    "We will compute the confidence interval for the population mean based on the statistic\n",
    "\n",
    "$$\n",
    "T = \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\sim_{\\scriptsize\\text{approx.}} N(0,1)\n",
    "$$\n",
    "\n",
    "We have selected it as we wish to approximate a population mean from information in a large sample ($n = 40$).\n",
    "\n",
    "For this statistic, the confidence interval corresponding to a confidence level $1 - \\alpha$ is given by\n",
    "\n",
    "$$\n",
    "\\text{CI}_{1-\\alpha} (\\mu) = \\left[ \\bar x - z_{\\alpha/2} \\frac{s}{\\sqrt{n}} \\; ; \\; \\bar x + z_{\\alpha/2} \\frac{s}{\\sqrt{n}} \\right]\n",
    "$$\n",
    "\n",
    "For our sample we have $\\bar x = 16.31$, $s^2 = 0.82$ and $n = 40$. Also, from the normal tables (or from R) we have that $z_{\\alpha/2} = z_{0.05} = 1.645$. Replacing these values we obtain the interval\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{CI}_{0.9} (\\mu) & = & \\left[ 16.31 - 1.645 \\sqrt{\\frac{0.82}{40}} \\; ; \\; 16.31 + 1.645 \\sqrt{\\frac{0.82}{40}} \\right] \\\\\n",
    "& = & \\left[ 16.0745 \\; ; \\; 16.5455 \\right]\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6097b8-80ac-42f5-9e74-3c9e19e7bab4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <span style=\"color:blue;\">Definition of confidence intervals: numerical example</span>\n",
    "\n",
    "For our selected data set, if we assume we can apply the CLT to a sample obtained from it (if $n$ is large enough), we can build the corresponding confidence interval using the preceding formula.\n",
    "\n",
    "The following code cell shows the results that we obtain if we repeat this process for many samples with the same sample size. The plot shows the intervals obtained for each one of a number of random samples, coded as a blue segment for those intervals that contain the correct value (in this case, the estimate from the full sample), and as a red segment when they do not contain it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d325d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Confidence intervals from the CLT\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "n.samples = 50\n",
    "smp.sz.prop = 0.2\n",
    "cf.lvl = 0.9\n",
    "\n",
    "## Parameters\n",
    "\n",
    "smp.sz = floor(smp.sz.prop*smp0.sz)\n",
    "sim.nq = qnorm(0.5+cf.lvl/2,lower.tail=T)\n",
    "\n",
    "## Generate samples and estimates\n",
    "\n",
    "sim.ci = as.data.frame(matrix(0,n.samples,4))\n",
    "for (i in 1:n.samples) {\n",
    "    v.smp = sample(data.sel$Val,smp.sz,replace = FALSE)\n",
    "    mn.smp = mean(v.smp)\n",
    "    sd.smp = sd(v.smp)\n",
    "    stderr.smp = sd.smp/sqrt(smp.sz)\n",
    "    sim.ci[i,1] = mn.smp - sim.nq*stderr.smp\n",
    "    sim.ci[i,2] = mn.smp + sim.nq*stderr.smp\n",
    "    if ((sim.ci[i,1] <= smp0.mn)&&(sim.ci[i,2] >= smp0.mn)) sim.ci[i,3] = 1\n",
    "    sim.ci[i,4] = mn.smp\n",
    "}\n",
    "    \n",
    "## Generate the resulting intervals\n",
    "\n",
    "names(sim.ci) = c(\"xs\",\"xe\",\"c\",\"center\")\n",
    "sim.ci$ys = seq(1,n.samples)\n",
    "aux.lbl = factor(c(0,1,sim.ci$c),labels=c(\"outside\",\"inside\"))\n",
    "sim.ci$cv = aux.lbl[-c(1,2)]\n",
    "  \n",
    "## Plot the intervals using a color code\n",
    "\n",
    "mn.x = 0.95*min(sim.ci$xs)\n",
    "mx.x = 1.05*max(sim.ci$xe)\n",
    "\n",
    "sim.t = sprintf(\"CLT Confidence intervals. Level %5.2f\",cf.lvl)\n",
    "\n",
    "sim.ci.plot <- sim.ci %>%\n",
    "  ggplot(aes(x=xs,y=ys,xend=xe,yend=ys,color=cv)) + geom_segment() +\n",
    "    geom_vline(xintercept=smp0.mn,color=\"brown\") +\n",
    "    xlim(mn.x,mx.x) +\n",
    "    annotate(geom=\"text\",label=\"Population mean\",x=smp0.mn,y=n.samples,vjust=-1,color=\"brown\") +\n",
    "    scale_color_manual(values = c(\"outside\" = \"red\", \"inside\" = \"blue\")) +\n",
    "    theme_bw() +\n",
    "    ggtitle(sim.t) +\n",
    "    xlab(\"Values\") + ylab(\"Intervals\") +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "plot(sim.ci.plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0109172-243d-4f70-baf2-193c006f6c2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Based on this plot, answer the following questions:</span>\n",
    "- <span style=\"color:green\">Which proportion of \"correct\" intervals would you expect to observe?</span>\n",
    "- <span style=\"color:green\">If you repeat this procedure with different samples (by running again the preceding cell), does the proportion of \"correct\" intervals change by much?</span>\n",
    "- <span style=\"color:green\">Why would you think that the proportion of correct intervals observed may differ from the value indicated by the theory?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531f5ca6-d0b7-491b-b502-cc188ecd7d6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### <span style=\"color:brown\">Definition of confidence intervals: a general procedure</span>\n",
    "\n",
    "We wish to derive a general procedure, following an scheme based on the one presented in the preceding example, but applicable to any parameter and any sample/population properties which might hold for our data. In this cell we describe the general steps we would need to follow to obtain our estimate for a confidence interval in this general setting.\n",
    "\n",
    "1. We start by identifying <span style=\"color:brown\">the parameter of interest $\\theta$</span>, that is, the population value we would like to approximate. For example, we might be interested in approximating the population mean, the population proportion, the population variance, etc.\n",
    "2. Identify an <span style=\"color:brown\">estimator $V$ </span> for the parameter $\\theta$, with good properties of bias and efficiency as commented in our discussion for point estimators. For example, the sample proportion to approximate the population proportion.\n",
    "   - You must <span style=\"color:brown\">know the distribution</span> of this estimator\n",
    "3. Define a statistic as a function of this estimator, with the property that the statistic $T$ depends on the value of the parameter $\\theta$, $T = T(\\theta;V)$, but its distribution $F$ (related to the distribution of $V$) does not depend on it\n",
    "   - The estimator $T$ must have an inverse with respect to $\\theta$, to ensure that we can solve for $\\theta$ any condition we impose on the value of the estimator.\n",
    "4. Select a <span style=\"color:brown\">confidence level, $1 - \\alpha$,</span> for the interval. This confidence level will introduce a condition on the probability of the estimator for the interval containing the correct value of the parameter.\n",
    "5. From the distribution of the estimator, <span style=\"color:brown\">find two right quantiles, $w_{\\alpha/2}$ and $w_{1 - \\alpha/2}$,</span> defined as $F(w_{\\alpha/2}) = 1 - \\alpha/2$ and $F(w_{1-\\alpha/2}) = \\alpha/2$.\n",
    "   - These quantiles will be used to define an <span style=\"color:brown\">interval for the estimator with the desired coverage</span>, that is, these values define an interval $[w_{1 - \\alpha/2} ; w_{\\alpha/2}]$ with the property that $\\Pr(w_{1 - \\alpha/2} < T(\\theta;V) \\leq w_{\\alpha/2}) = 1 - \\alpha)$.\n",
    "6. From this interval for the estimator we <span style=\"color:brown\">compute an interval for the parameter</span>.\n",
    "\n",
    "   If $T^{-1}(w)$ denotes the inverse of $T(\\theta)$ with respect to $\\theta$, that is, $w = T(\\theta)$, then if $T$ were a decreasing function of $\\theta$ we could obtain the endpoints of the confidence interval from $w_{1 - \\alpha/2} < T(\\theta) \\leq w_{\\alpha/2}$ as $T^{-1} (w_{1-\\alpha/2})$ and $T^{-1} (w_{\\alpha/2})$. \n",
    "   \n",
    "   The confidence interval would then be given by\n",
    "\n",
    "$$\n",
    "\\mbox{CI}_{1-\\alpha}(\\theta) = \\left[ T^{-1} (w_{\\alpha/2}) \\; ;\\; T^{-1} (w_{1-\\alpha/2}) \\right] .\n",
    "$$\n",
    "\n",
    "As an example of the construction of this interval based on the use of the inverse function $T^{-1}$, if $T(\\mu) = (\\bar X - \\mu)/(S_X/\\sqrt{n})$ then $T(\\mu)$ in this case is a decreasing function of $\\mu$ and we have $T^{-1} (w) = \\bar X - w S_X / \\sqrt{n}$. As a consequence, we obtain the interval\n",
    "\n",
    "$$\n",
    "\\mbox{CI}_{1-\\alpha}(\\theta) = \\left[ \\bar X - w_{\\alpha/2} \\frac{S_X}{\\sqrt{n}} \\; ;\\; \\bar X - w_{1-\\alpha/2} \\frac{S_X}{\\sqrt{n}} \\right] .\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbe6ba-d0e5-43b7-8c2b-ecfc9da42fe8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <span style=\"color:brown\">Confidence intervals for the population mean</span>\n",
    "\n",
    "Consider the case when $\\theta = \\mu$, that is, when we are interested in a confidence interval for the population mean (step 1 of the general procedure). We will work with a confidence level of $1 - \\alpha$, and our reference estimator will be the sample mean.\n",
    "\n",
    "We will consider two cases for which we have a known distribution for the sample mean $\\bar X$:\n",
    "\n",
    "1. When we have a sample that is large enough to allow for the application of the Central Limit Theorem.\n",
    "2. When we have normal data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3ee62-2475-4ec1-9baa-d0569a4cd923",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <span style=\"color:brown\">Central limit theorem approximation</span>\n",
    "\n",
    "To simplify the characterizaton of its distribution, we start by rewriting out estimator. From the CLT we have that\n",
    "\n",
    "$$\n",
    "    T \\equiv \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\sim_{\\scriptsize \\text{approx.}} N(0,1)\n",
    "$$\n",
    "\n",
    "For step 5 in the general procedure, we compute the quantiles $z_{\\alpha/2}$ and $z_{1-\\alpha/2}$ from a standard normal distribution. For this distribution (and in general for symmetric distributions with zero mean) it holds that $z_{1-\\alpha/2} = - z_{\\alpha/2}$, so we only need to compute one of the two quantiles. For a confidence level of $1 - \\alpha$ the condition in step 5 would be\n",
    "\n",
    "$$\n",
    "\\Pr \\left( -z_{\\alpha/2} < \\frac{\\bar X - \\mu}{s/\\sqrt{n}} \\leq z_{\\alpha/2} \\right) \\approx 1 - \\alpha \n",
    "$$\n",
    "\n",
    "For example, if $1-\\alpha = 0.95$ then $z_{0.025} = 1.96$ and $z_{0.975} = -1.96$.\n",
    "\n",
    "Finally, step 6 requires that we solve the inequalities for $\\mu$, the parameter of interest. Using the values in the sample to obtain the corresponding point estimates we have,\n",
    "\n",
    "$$\n",
    "    -z_{\\alpha/2} < \\frac{\\bar x - \\mu}{s/\\sqrt{n}} \\leq z_{\\alpha/2} \\ \\Leftrightarrow \\ \\bar x - z_{\\alpha/2} \\frac{s}{\\sqrt{n}} < \\mu \\leq \\bar x + z_{\\alpha/2} \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "That is,\n",
    "\n",
    "$$\n",
    "    \\mbox{CI}_{1-\\alpha}(\\mu) = \\left[ \\bar x - z_{\\alpha/2} \\frac{s}{\\sqrt{n}} \\; ; \\; \\bar x + z_{\\alpha/2} \\frac{s}{\\sqrt{n}} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd8bd3e-10e2-47f2-a3a5-ce21a6d1d8cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <span style=\"color:blue;\">Central limit theorem approximation. Numerical example</span>\n",
    "\n",
    "Assume that the data we have considered in this lesson satisfies the assumptions we have specified, that is, that we wish to determine a confidence interval for the population mean based on <span style=\"color:blue\">sz.smp</span> randomly selected observations in our sample, and that this sample size is large enough to apply the CLT. \n",
    "\n",
    "The following cell illustrates the computations required to obtain this confidence interval, providing the values of the confidence intervals for different confidence levels. The red line in the plot indicates the value of the sample mean (the center of the confidence interval).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc79ad2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Confidence interval based on the Central Limit Theorem\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "smp.sz = 50\n",
    "\n",
    "## Parameters\n",
    "\n",
    "sz.smp = max(30,smp.sz)\n",
    "\n",
    "cf.lvl = c(0.9,0.925,0.95,0.975,0.99,0.999)\n",
    "sim.nq = qnorm(0.5+cf.lvl/2,lower.tail=T)\n",
    "\n",
    "## Compute relevant sample summaries\n",
    "\n",
    "ix.smp = sample(smp0.sz,sz.smp)\n",
    "\n",
    "data.smp = data.sel$Val[ix.smp]\n",
    "smp.sm = sum(data.smp)\n",
    "smp.sm2 = sum(data.smp^2)\n",
    "smp.mn = mean(data.smp)\n",
    "smp.sd = sd(data.smp)\n",
    "Sum.fr.4 = as.data.frame(round(matrix(c(sz.smp,smp.sm,smp.sm2,smp.mn,smp.sd),5,1),3))\n",
    "\n",
    "Data.hux.4 <-\n",
    "  hux(Sum.fr.4) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux.4) <- c(\"\",\"Sample size\",\"Sum of values\",\"Sum of squares\",\"Sample mean\",\"Sample quasi-std dev\")\n",
    "colnames(Data.hux.4) <- c(\"Values\")\n",
    "table_prnt(Data.hux.4[-1,],\"Sample summary\")\n",
    "\n",
    "lim.low = smp.mn - sim.nq*smp.sd/sqrt(sz.smp)\n",
    "lim.high = smp.mn + sim.nq*smp.sd/sqrt(sz.smp)\n",
    "val.5 = cbind(cf.lvl,lim.low,lim.high)\n",
    "Sum.fr.5 = as.data.frame(round(val.5,3))\n",
    "colnames(Sum.fr.5) <- c(\"CL\",\"Llim\",\"Hlim\")\n",
    "\n",
    "Data.hux.5 <-\n",
    "  hux(Sum.fr.5) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux.5) <- c(\"\",\"CI 1\",\"CI 2\",\"CI 3\",\"CI 4\",\"CI 5\",\"CI 6\")\n",
    "colnames(Data.hux.5) <- c(\"Confidence level\",\"Lower limit\",\"Higher limit\")\n",
    "table_prnt(Data.hux.5[-1,],\"Confidence intervals\")\n",
    "\n",
    "## Plot the intervals\n",
    "\n",
    "Sum.fr.5$y = seq(1,3)\n",
    "sim.ci.plot <- Sum.fr.5 %>%\n",
    "  ggplot(aes(x=Llim,y=CL,xend=Hlim,yend=CL)) + geom_segment(color=\"blue\") +\n",
    "    geom_vline(xintercept=smp.mn,color=\"brown\") +\n",
    "    theme_bw() +\n",
    "    ggtitle(\"Confidence intervals using the CLT\") +\n",
    "    xlab(\"Values\") + ylab(\"Intervals\") +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "plot(sim.ci.plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca280b-0785-4199-88f8-c8126ff475a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">From the values indicated in the preceding cell:</span>\n",
    "- <span style=\"color:green\">Repeat the computations by hand based on the first $n$ observations in our data</span>\n",
    "> To do this, you can replace the instruction <span style=\"color:blue;font-family:monospace;font-size:90%;\">ix.smp = sample(smp0.sz,sz.smp)</span> in the preceding cell with <span style=\"color:blue;font-family:monospace;font-size:90%;\">ix.smp = 1:sz.smp</span>\n",
    "- <span style=\"color:green\">What is the relationship between the size of the confidence interval and the confidence level?</span>\n",
    "- <span style=\"color:green\">Are the confidence intervals reasonable for the data we are considering?</span>\n",
    "- <span style=\"color:green\">Can you suggest an explanation for any discrepancies?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115177a9-137d-45bd-95c7-99b8574e0120",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:brown\">Central limit theorem approximation for the population proportion</span>\n",
    "\n",
    "We are now interested in approximating a population proportion using a confidence interval. As our statistic we will use the sample proportion. \n",
    "\n",
    "To obtain a distribution for this statistic, we observe that the proportion of observations in a sample that satisfy a certain condition can be obtained as the mean of a collection of Bernoulli random variables $Y_k$ that take the value 1 when an individual in the sample satisfies the condition. Note that this mean is the same as the number of individuals satisfying the condition in the sample divided by the total number of individuals, that is, the proportion of interest. Also, the population proportion is the value of the parameter for this Bernoulli random variable, which is also the mean of this random variable.\n",
    "\n",
    "Thus, the sample proportion is the sample mean of the Bernoulli random variables, and if the sample size is large enough we can apply the CLT to have that\n",
    "\n",
    "$$\n",
    "T \\equiv \\frac{\\hat P - p}{s_Y/\\sqrt{n}} \\sim_{\\scriptsize \\text{approx.}} N(0,1) ,\n",
    "$$\n",
    "\n",
    "where $\\hat P$ denotes the sample proportion, $p$ is the population proportion (the parameter of the Bernoulli random variable) and $s_Y$ is the sample estimate for the standard deviation of one of the Bernoulli random variables $Y_k$. One last observation is that in a Bernoulli random variable the values of the mean and the standard deviation are related, as the distribution has only one parameter and both values depend on it. In particular, if $Y \\sim \\mbox{Ber} (p)$ then $E[Y] = p$ and $\\mbox{SD}(Y) = p(1-p)$. One consequence is that we can write $s_Y$, the estimate for the sample standard deviation of $Y$, in terms of the estimated parameter $\\hat p$ as $\\sqrt{\\hat p (1 - \\hat p)}$. The statistic we will use is\n",
    "\n",
    "$$\n",
    "T \\equiv \\frac{\\hat P - p}{\\sqrt{\\hat P(1 - \\hat P)/n}} \\sim_{\\scriptsize \\text{approx.}} N(0,1) ,\n",
    "$$\n",
    "\n",
    "The remaining steps are similar to those we followed in the preceding case. From step 5 in the general procedure, we compute the quantiles $z_{\\alpha/2}$ and $z_{1-\\alpha/2}$ for a standard normal distribution, with $z_{1-\\alpha/2} = - z_{\\alpha/2}$. For a confidence level of $1 - \\alpha$ the condition in step 5 would be\n",
    "\n",
    "$$\n",
    "\\Pr \\left( -z_{\\alpha/2} < \\frac{\\hat P - p}{\\sqrt{\\hat P(1 - \\hat P)/n}} \\leq z_{\\alpha/2} \\right) \\approx 1 - \\alpha \n",
    "$$\n",
    "\n",
    "For example, if $1-\\alpha = 0.90$ then $z_{0.05} = 1.645$ and $z_{0.95} = -1.645$.\n",
    "\n",
    "\n",
    "Finally, to apply step 6 we solve for $p$, the parameter of interest. Using the values in the sample to obtain the corresponding point estimates we have,\n",
    "\n",
    "$$\n",
    "    -z_{\\alpha/2} < \\frac{\\hat p - p}{\\sqrt{\\hat p(1-\\hat p)/n}} \\leq z_{\\alpha/2} \\ \\Leftrightarrow \\ \\hat p - z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1 - \\hat p)}{n}} < p \\leq \\hat p + z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1 - \\hat p)}{n}}\n",
    "$$\n",
    "\n",
    "That is, the confidence interval is given by\n",
    "\n",
    "$$\n",
    "    \\mbox{CI}_{1-\\alpha}(p) = \\left[ \\hat p - z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1 - \\hat p)}{n}} \\; ; \\; \\hat p + z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1 - \\hat p)}{n}} \\right]\n",
    "$$\n",
    "\n",
    "As a final comment, the usual criteria used to assume that a sample is large enough to apply the CLT  in the case of Bernoulli r.v.'s is that $n \\geq 30$. But we also require that $p$ and $1-p$ are not too small. In addition to the preceding condition, we also ask that both $np \\geq 5$ and $n(1-p) \\geq 5$ should hold. These criteria are empirical ones, based on the practical results obtained in these cases; the specific reference values would depend on the desired quality of the approximation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5318e-033b-438c-b714-95f515d17e9c",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*In 2019 the Internal Revenue Service (IRS) reviewed a random sample of 2000 companies and their balance sheets and found that 58 of them had some sort of miscalculation error.*\n",
    "\n",
    "*Estimate a confidence interval for the population proportion of companies with miscalculation errors, using a significance level of 99%.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b8165-8e16-4fe7-997a-98bc16925290",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "Our population will be the companies that reported to the IRS in 2019, and we define a Bernoulli random variable $X$ taking the value 1 if a company made a miscalculation error in their report, and 0 otherwise.\n",
    "\n",
    "We will compute the confidence interval for the population proportion based on the statistic\n",
    "\n",
    "$$\n",
    "T = \\frac{\\hat P - p}{\\sqrt{\\hat P(1 - \\hat P)/n}} \\sim_{\\scriptsize\\text{approx.}} N(0,1)\n",
    "$$\n",
    "\n",
    "where $\\hat P$ denotes the sample proportion (the sample mean of the $X$ variables), our estimator for the population proportion. We have selected this statistic as we wish to approximate a population proportion from information collected from a large sample ($n = 2000$).\n",
    "\n",
    "For this statistic, the confidence interval corresponding to a confidence level $1 - \\alpha$ is given by\n",
    "\n",
    "$$\n",
    "\\text{CI}_{1-\\alpha} (p) = \\left[ \\hat p - z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1-\\hat p)}{n}} \\; ; \\; \\hat p + z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1-\\hat p)}{n}} \\right]\n",
    "$$\n",
    "\n",
    "For our sample we have $\\hat p = 58/2000 = 0.026$ and $n = 2000$. Also, from the normal tables (or from R) we have that $z_{\\alpha/2} = z_{0.005} = 2.576$. Replacing these values we obtain the interval\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{CI}_{0.99} (p) & = & \\left[ 0.026 - 2.576 \\sqrt{\\frac{0.026\\times 0.974}{2000}} \\; ; \\; 0.026 + 2.576 \\sqrt{\\frac{0.026\\times 0.974}{2000}} \\right] \\\\\n",
    "& = & \\left[ 0.0168 \\; ; \\; 0.0352 \\right]\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa600ade-e29c-41d3-9cf9-d59b6b4b62ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <span style=\"color:blue;\">Population proportion. Numerical example</span>\n",
    "\n",
    "We wish to determine a confidence interval for the population proportion of the observations in our data that are above a certain value, <span style=\"color:blue\">ref.val</span>, based on <span style=\"color:blue\">sz.smp</span> random observations selected from our sample. We assume that the data we are considering satisfies the assumptions we have specified before. \n",
    "\n",
    "The following cell carries out the computations to obtain this confidence interval. It presents the values we have used to conduct these computations, as well as the results obtained for different confidence levels. The red line represents the value of the sample proportion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f76d7b-e746-4648-8c3f-819b7715962e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Confidence interval for a proportion based on the Central Limit Theorem\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "pct.val = 0.75\n",
    "smp.sz = 50\n",
    "\n",
    "## Parameters\n",
    "\n",
    "ref.val = quantile(data.sel$Val,pct.val)\n",
    "sz.smp = max(30,smp.sz)\n",
    "\n",
    "cf.lvl = c(0.9,0.925,0.95,0.975,0.99,0.999)\n",
    "sim.nq = qnorm(0.5+cf.lvl/2,lower.tail=T)\n",
    "\n",
    "## Compute relevant sample summaries\n",
    "\n",
    "ix.smp = sample(smp0.sz,sz.smp)\n",
    "\n",
    "data.smp = as.numeric(data.sel$Val[ix.smp] > ref.val)\n",
    "smp.ct = sum(data.smp)\n",
    "smp.pr = mean(data.smp)\n",
    "smp.sd = smp.pr*(1 - smp.pr)\n",
    "Sum.fr.4 = as.data.frame(round(matrix(c(sz.smp,ref.val,smp.ct,smp.pr,smp.sd),5,1),3))\n",
    "\n",
    "Data.hux.4 <-\n",
    "  hux(Sum.fr.4) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux.4) <- c(\"\",\"Sample size\",\"Reference value\",\"Count of values\",\"Sample proportion\",\"Sample quasi-std dev\")\n",
    "colnames(Data.hux.4) <- c(\"Values\")\n",
    "table_prnt(Data.hux.4[-1,],\"Sample summary\")\n",
    "\n",
    "lim.low = smp.pr - sim.nq*smp.sd/sqrt(sz.smp)\n",
    "lim.high = smp.pr + sim.nq*smp.sd/sqrt(sz.smp)\n",
    "val.5 = cbind(cf.lvl,lim.low,lim.high)\n",
    "Sum.fr.5 = as.data.frame(round(val.5,3))\n",
    "colnames(Sum.fr.5) <- c(\"CL\",\"Llim\",\"Hlim\")\n",
    "\n",
    "Data.hux.5 <-\n",
    "  hux(Sum.fr.5) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux.5) <- c(\"\",\"CI 1\",\"CI 2\",\"CI 3\",\"CI 4\",\"CI 5\",\"CI 6\")\n",
    "colnames(Data.hux.5) <- c(\"Confidence level\",\"Lower limit\",\"Higher limit\")\n",
    "table_prnt(Data.hux.5[-1,],\"Confidence intervals\")\n",
    "\n",
    "## Plot the intervals\n",
    "\n",
    "Sum.fr.5$y = seq(1,3)\n",
    "sim.ci.plot <- Sum.fr.5 %>%\n",
    "  ggplot(aes(x=Llim,y=CL,xend=Hlim,yend=CL)) + geom_segment(color=\"blue\") +\n",
    "    geom_vline(xintercept=smp.pr,color=\"brown\") +\n",
    "    theme_bw() +\n",
    "    ggtitle(\"Confidence intervals for a proportion\") +\n",
    "    xlab(\"Values\") + ylab(\"Intervals\") +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "plot(sim.ci.plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da9d5d1-d244-4675-9b9f-2266e824abc2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">From the values indicated in the preceding cell:</span>\n",
    "- <span style=\"color:green\">Repeat the computations by hand based on the first $n$ observations in our data</span>\n",
    "- <span style=\"color:green\">Are these confidence intervals reasonable for the data we are considering?</span>\n",
    "- <span style=\"color:green\">Can you suggest an explanation for any discrepancies?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0b9be-faf8-4f62-b2bf-350266d23e4f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:brown\">Normal data</span>\n",
    "\n",
    "In the preceding cases we have made use of the CLT to derive an estimator with a known distribution that we used to apply the general procedure. But the CLT requires that we have a sufficiently large sample, and in some practical cases the size of the available sample might be small.\n",
    "\n",
    "Under certain assumptions on our data, there exist estimators with known distributions, even for small samples. The most common situation when this is possible corresponds to normal data, that is, if we can assume that the population we are studying follows a normal distribution. In this case it can be shown that\n",
    "\n",
    "$$\n",
    "T \\equiv \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\sim t_{n-1} ,\n",
    "$$\n",
    "\n",
    "where $t_{n-1}$ denotes a Student t distribution with $n-1$ degrees of freedom. This distribution is described in some detail in [Appendix 1](#App1_1_Std), and the theoretical results justifying that our estimator follows this distribution are given in [Appendix 2](#App1_2).\n",
    "\n",
    "This estimator is defined in a way that is very similar to the ones we have introduced for the preceding cases, with the main difference being the distribution of the estimator.\n",
    "\n",
    "We will use the property that the Student t distribution is symmetric around zero. We will need to compute its quantiles, and this can be done using the R function <span style=\"color:blue;font-family:monospace;font-size:90%;\">qt</span>, as we will see in the following code cell.\n",
    "\n",
    "To follow the general procedure, in step 5 we compute the quantiles $t_{n-1;\\alpha/2}$ and $t_{n-1;1-\\alpha/2}$ from a Student t distribution with $n-1$ degrees of freedom, $T_{n-1}$, where $\\Pr(T_{n-1} > t_{n-1;\\alpha/2}) = \\alpha/2$. From the symmetry of the distribution it holds that $t_{n-1;1-\\alpha/2} = - t_{n-1;\\alpha/2}$, so we only need to compute one of the two quantiles. For a confidence level of $1 - \\alpha$ the condition in step 5 would be\n",
    "\n",
    "$$\n",
    "\\Pr \\left( -t_{n-1;\\alpha/2} < \\frac{\\bar X - \\mu}{s/\\sqrt{n}} \\leq t_{n-1;\\alpha/2} \\right) = 1 - \\alpha \n",
    "$$\n",
    "\n",
    "For example, if $n = 15$ and $1-\\alpha = 0.95$ then $t_{14;0.025} = 2.145$.\n",
    "\n",
    "As our last step, we solve for $\\mu$, the parameter of interest. Using the values in the sample to obtain the corresponding point estimates we have,\n",
    "\n",
    "$$\n",
    "-t_{n-1;\\alpha/2} < \\frac{\\bar x - \\mu}{s/\\sqrt{n}} \\leq t_{n-1;\\alpha/2} \\ \\Leftrightarrow \\ \\bar x - t_{n-1;\\alpha/2} \\frac{s}{\\sqrt{n}} < \\mu \\leq \\bar x + t_{n-1;\\alpha/2} \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "That is,\n",
    "\n",
    "$$\n",
    "\\mbox{CI}_{1-\\alpha}(\\mu) = \\left[ \\bar x - t_{n-1;\\alpha/2} \\frac{s}{\\sqrt{n}} \\; ; \\; \\bar x + t_{n-1;\\alpha/2} \\frac{s}{\\sqrt{n}} \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ded8c-3a6a-4313-a33c-7a493f036714",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*The time required to process the purchases of a client in a supermarket follows a normal distribution. For a simple random sample of 15 clients, the following processing times (in minutes) were recorded:*\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccccccccccccccc}\n",
    "5 & 6.2 & 4.8 & 5.2 & 5.2 & 6.4 & 4.9 & 5.3 & 4.2 & 5 & 5.9 & 5.1 & 6 & 4.9 & 5\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "*Find a confidence interval at 95% for the population mean time required to process one client.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17605ae5-a523-449f-ab61-ea55f044b4a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "For the population of packages produced in this line, we define the continuous random variable $X =$ \"processing time of one client (in minutes)\".\n",
    "\n",
    "We will compute the confidence interval for the population mean based on the statistic\n",
    "\n",
    "$$\n",
    "T = \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\sim t_{n-1}\n",
    "$$\n",
    "\n",
    "We have selected it as we wish to approximate a population mean when our population is assumed to follow a normal distribution.\n",
    "\n",
    "For this statistic, the confidence interval corresponding to a confidence level $1 - \\alpha$ is given by\n",
    "\n",
    "$$\n",
    "\\text{CI}_{1-\\alpha} (\\mu) = \\left[ \\bar x - t_{n-1;\\alpha/2} \\frac{s}{\\sqrt{n}} \\; ; \\; \\bar x + t_{n-1;\\alpha/2} \\frac{s}{\\sqrt{n}} \\right]\n",
    "$$\n",
    "\n",
    "For the given sample we have $\\bar x = 5.2733$, $s^2 = 0.35495$ and $n = 15$. Also, from the tables for the Student t distribution (or from R) we have that $t_{n-1;\\alpha/2} = t_{14;0.025} = 2.145$. Replacing these values we obtain the interval\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{CI}_{0.95} (\\mu) & = & \\displaystyle \\left[ 5.2733 - 2.145 \\sqrt{\\frac{0.35495}{15}} \\; ; \\; 5.2733 + 2.145 \\sqrt{\\frac{0.35495}{15}} \\right] \\\\\n",
    "& = & \\left[ 4.9433  \\; ; \\; 5.6033 \\right]\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b882a-407c-498c-ba09-3ebfc3edfd6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <span style=\"color:blue;\">Mean of normal data. Numerical example</span>\n",
    "\n",
    "We wish to determine a confidence interval for the population mean of the values in the sample, based on <span style=\"color:blue;font-family:monospace;font-size:90%;\">sz.smp</span> random observations in our sample. We assume that the data we are considering satisfies the assumptions we have specified before, and in particular that the population follows a normal distribution. \n",
    "\n",
    "The following cell carries out the computations to obtain this confidence interval. We show the value of the quantities required to obtain a confidence interval for the selected sample, as well as the confidence intervals for several confidence levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae7f36f-9846-409f-920d-2feb52e2fb31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Confidence interval for the mean for normal data\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "smp.sz = 20\n",
    "\n",
    "## Parameters\n",
    "\n",
    "cf.lvl = c(0.9,0.925,0.95,0.975,0.99,0.999)\n",
    "sim.nq = qt(0.5+cf.lvl/2,smp.sz-1,lower.tail=T)\n",
    "\n",
    "## Compute relevant sample summaries\n",
    "\n",
    "ix.smp = sample(smp0.sz,sz.smp)\n",
    "\n",
    "data.smp = data.sel$Val[ix.smp]\n",
    "smp.sm = sum(data.smp)\n",
    "smp.sm2 = sum(data.smp^2)\n",
    "smp.mn = mean(data.smp)\n",
    "smp.sd = sd(data.smp)\n",
    "Sum.fr.4 = as.data.frame(round(matrix(c(smp.sz,smp.sm,smp.sm2,smp.mn,smp.sd),5,1),3))\n",
    "\n",
    "Data.hux.4 <-\n",
    "  hux(Sum.fr.4) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux.4) <- c(\"\",\"Sample size\",\"Sum of values\",\"Sum of squares\",\"Sample mean\",\"Sample quasi-std dev\")\n",
    "colnames(Data.hux.4) <- c(\"Values\")\n",
    "table_prnt(Data.hux.4[-1,],\"Sample summary\")\n",
    "\n",
    "lim.low = smp.mn - sim.nq*smp.sd/sqrt(sz.smp)\n",
    "lim.high = smp.mn + sim.nq*smp.sd/sqrt(sz.smp)\n",
    "val.5 = cbind(cf.lvl,lim.low,lim.high)\n",
    "Sum.fr.5 = as.data.frame(round(val.5,3))\n",
    "colnames(Sum.fr.5) <- c(\"CL\",\"Llim\",\"Hlim\")\n",
    "\n",
    "Data.hux.5 <-\n",
    "  hux(Sum.fr.5) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux.5) <- c(\"\",\"CI 1\",\"CI 2\",\"CI 3\",\"CI 4\",\"CI 5\",\"CI 6\")\n",
    "colnames(Data.hux.5) <- c(\"Confidence level\",\"Lower limit\",\"Higher limit\")\n",
    "table_prnt(Data.hux.5[-1,],\"Confidence intervals\")\n",
    "\n",
    "## Plot the intervals\n",
    "\n",
    "Sum.fr.5$y = seq(1,3)\n",
    "sim.ci.plot <- Sum.fr.5 %>%\n",
    "  ggplot(aes(x=Llim,y=CL,xend=Hlim,yend=CL)) + geom_segment(color=\"blue\") +\n",
    "    geom_vline(xintercept=smp.mn,color=\"brown\") +\n",
    "    theme_bw() +\n",
    "    ggtitle(\"Confidence intervals using the CLT\") +\n",
    "    xlab(\"Values\") + ylab(\"Intervals\") +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "plot(sim.ci.plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ea67d5-0942-4980-ba90-d890df81dde4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">From the values indicated in the preceding cell:</span>\n",
    "- <span style=\"color:green\">Repeat the computations by hand based on the first $n$ observations in our data</span>\n",
    "- <span style=\"color:green\">Are these confidence intervals reasonable for the data we are considering?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08920569-e929-4486-834f-1a129fb231a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <span style=\"color:blue;\">Mean of normal data. Numerical example (ii)</span>\n",
    "\n",
    "In the following cell we show different confidence intervals for the mean of the population, obtained from different samples randomly selected from our data and using the formula based on the assumption of normality. The intervals are plotted in different colors, depending on the interval containing the correct value (a blue interval) or not (a red interval).\n",
    "\n",
    "In order to compute these intervals we have assumed that we have normal data, but this assumption may not hold for real data. We also check, using a QQ-plot, if this normality assumption is reasonable in our case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68124b-3f0b-4100-9380-634984b7d5ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Confidence interval for the mean for normal data\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "n.samples = 50\n",
    "smp.sz = 20\n",
    "cf.lvl = 0.9\n",
    "\n",
    "## Parameters\n",
    "\n",
    "sim.nq.1 = qnorm(0.5+cf.lvl/2, lower.tail=T)\n",
    "\n",
    "## Generate samples and estimates\n",
    "\n",
    "sim.ci = as.data.frame(matrix(0,n.samples,4))\n",
    "for (i in 1:n.samples) {\n",
    "    v.smp = sample(data.sel$Val,smp.sz,replace = FALSE)\n",
    "    mn.smp = mean(v.smp)\n",
    "    sd.smp = sd(v.smp)\n",
    "    sim.ci[i,1] = mn.smp - sim.nq.1*sd.smp/sqrt(smp.sz)\n",
    "    sim.ci[i,2] = mn.smp + sim.nq.1*sd.smp/sqrt(smp.sz)\n",
    "    if ((sim.ci[i,1] <= smp0.mn)&&(sim.ci[i,2] >= smp0.mn)) sim.ci[i,3] = 1\n",
    "    sim.ci[i,4] = mn.smp\n",
    "}\n",
    "    \n",
    "## Generate the resulting intervals\n",
    "\n",
    "names(sim.ci) = c(\"xs\",\"xe\",\"c\",\"center\")\n",
    "sim.ci$ys = seq(1,n.samples)\n",
    "aux.lbl = factor(c(0,1,sim.ci$c),labels=c(\"outside\",\"inside\"))\n",
    "sim.ci$cv = aux.lbl[-c(1,2)]\n",
    "  \n",
    "## Plot the intervals using a color code\n",
    "\n",
    "mn.x = 0.95*min(sim.ci$xs)\n",
    "mx.x = 1.05*max(sim.ci$xe)\n",
    "\n",
    "sim.t = sprintf(\"Confidence intervals for the mean. Level %5.2f\",cf.lvl)\n",
    "\n",
    "sim.ci.plot <- sim.ci %>%\n",
    "  ggplot(aes(x=xs,y=ys,xend=xe,yend=ys,color=cv)) + geom_segment() +\n",
    "    geom_vline(xintercept=smp0.mn,color=\"brown\") +\n",
    "    xlim(mn.x,mx.x) +\n",
    "    annotate(geom=\"text\",label=\"Population mean\",x=smp0.mn,y=n.samples,vjust=-1,color=\"brown\") +\n",
    "    scale_color_manual(values = c(\"outside\" = \"red\", \"inside\" = \"blue\")) +\n",
    "    theme_bw() +\n",
    "    ggtitle(sim.t) +\n",
    "    xlab(\"Values\") + ylab(\"Intervals\") +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "plot(sim.ci.plot)\n",
    "\n",
    "## Are the observations normal?\n",
    "\n",
    "data.sel %>% ggplot(aes(sample = Val)) +\n",
    "  stat_qq_band() + stat_qq_line(color=\"red\") + stat_qq_point() +\n",
    "  ggtitle(\"Normal QQ-plot\") +\n",
    "  xlab(\"Theoretical quantiles\") + ylab(\"Sample quantiles\") +\n",
    "  theme(plot.title = element_text(color=\"blue\", size=13, face=\"bold.italic\", hjust=0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206bfb7d-312b-4615-9a6e-578dc8ec7ee2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">From the plots shown in the preceding cell:</span>\n",
    "- <span style=\"color:green\">Are the confidence levels shown for these confidence intervals close to the theoretical ones?</span>\n",
    "- <span style=\"color:green\">Would you think it would be reasonable to consider this data as normal?</span>\n",
    "- <span style=\"color:green\">Can you suggest an explanation for any differences between the theoretical and the observed confidence levels?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e357ff8d-cccd-43a4-9544-eddb9ae361c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:brown\">Confidence intervals for the population variance</span>\n",
    "\n",
    "We now consider the case when $\\theta = \\sigma^2$, that is, we are interested in a confidence interval for the population variance (step 1 of the general procedure). Our estimator will be the sample quasivariance $S^2$, which is an unbiased estimator for the population variance.\n",
    "\n",
    "In this case, the CLT is not very useful to derive a distribution for our estimator $S^2$, and we will only consider the particular case when we have normal data.\n",
    "\n",
    "<h4 style=\"color:brown\">Normal data</h4>\n",
    "\n",
    "To derive its distribution, we rewrite out estimator $S^2$ as\n",
    "\n",
    "$$\n",
    "T \\equiv \\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2_{n-1}\n",
    "$$\n",
    "\n",
    "where under the assumption that $X \\sim N(\\mu,\\sigma)$ it holds that $T$ follows a chi squared distribution with $n-1$ degrees of freedom. This distribution is described in some detail in [Appendix 1](#App1_1_Csq), and the theoretical results justifying that our estimator follows this distribution are given in [Appendix 2](#App1_2).\n",
    "\n",
    "Assume we are given a confidence level $1 - \\alpha$. We note that this distribution takes only nonnegative values and it is not symmetric. Thus, we will need to compute two quantiles for this confidence level, which can be done by using the R function <span style=\"color:blue;font-family:monospace;font-size:90%;\">qchisq</span>.\n",
    "\n",
    "For step 5 in the general procedure, as the distribution is not symmetric, for a confidence level of $1 - \\alpha$ we need to obtain the quantiles $\\chi^2_{n-1;\\alpha/2}$ and $\\chi^2_{n-1;1-\\alpha/2}$ from a chi squared distribution with $n-1$ degrees of freedom, that is, we need to find two values satisfying $\\Pr (\\chi^2_{n-1} > \\chi^2_{n-1;\\alpha/2} ) = \\alpha/2$ and $\\Pr (\\chi^2_{n-1} > \\chi^2_{n-1;1-\\alpha/2} ) = 1-\\alpha/2$, so that\n",
    "\n",
    "$$\n",
    "\\Pr \\left( \\chi^2_{n-1;1-\\alpha/2} < \\frac{(n-1)S^2}{\\sigma^2} \\leq \\chi^2_{n-1;\\alpha/2} \\right) = 1 - \\alpha \n",
    "$$\n",
    "\n",
    "Then, in step 6 we solve for $\\sigma^2$, the parameter of interest. Using the values in the sample to obtain the corresponding point estimates we have,\n",
    "\n",
    "$$\n",
    "\\chi^2_{n-1;1-\\alpha/2} < \\frac{(n-1)s^2}{\\sigma^2} \\leq \\chi^2_{n-1;\\alpha/2} \\ \\Leftrightarrow \\ \\frac{(n-1)s^2}{\\chi^2_{n-1;\\alpha/2} } < \\sigma^2 \\leq \\frac{(n-1)s^2}{\\chi^2_{n-1;1-\\alpha/2} }\n",
    "$$\n",
    "\n",
    "That is,\n",
    "\n",
    "$$\n",
    "\\mbox{CI}_{1-\\alpha}(\\sigma^2) = \\left[ \\frac{(n-1)s^2}{\\chi^2_{n-1;\\alpha/2}} \\; ; \\; \\frac{(n-1)s^2}{\\chi^2_{n-1;1-\\alpha/2}} \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa795f-af73-4462-b77f-172975307701",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*A survey was conducted to determine the variability in the number of study hours per week required by the students of a certain course. We assume this number follows a normal distribution. A simple random sample of 10 students provided the following values:*\n",
    "\n",
    "$$\n",
    "\\begin{array}{cccccccccc}\n",
    "28 & 5 & 6 & 30 & 25 & 15 & 12 & 25 & 20 & 18\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "*Construct a confidence interval at the 95% level for the standard deviation of the weekly study hours.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3607e8ea-3648-4bc1-bfd9-87805a11119c",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "Define the continuous random variable $X =$ \"weekly study hours of a student\". We will compute the requested confidence interval for the population standard deviation by obtaining first the corresponding interval for the population variance. We will use the statistic\n",
    "\n",
    "$$\n",
    "T = \\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2_{n-1}\n",
    "$$\n",
    "\n",
    "We have selected it as we wish to approximate a population variance when we assume that we have normal data.\n",
    "\n",
    "From the sample data we compute the sample mean $\\bar{x} = (28 + \\cdots + 18)/10 = 18.4$, and estimate the population variance $\\sigma^2$ using its unbiased estimator, the sample quasi-variance. We obtain\n",
    "$$\n",
    "s^2 = \\frac{1}{n-1} \\left( \\sum_{i=1}^n x_i^2 - n \\bar x^2 \\right) = \\frac{1}{9} \\left( 28^2 + \\cdots + 18 - 10\\times 18.4^2 \\right) = 78.044.\n",
    "$$\n",
    "\n",
    "A confidence interval at the $1-\\alpha$ level for $\\sigma^2$ will be given by\n",
    "\n",
    "$$\n",
    "\\text{CI}_{1-\\alpha} (\\sigma^2) = \\left[ \\frac{(n-1) s^2}{\\chi_{n-1, \\alpha/2}^2}, \\frac{(n-1) s^2}{\\chi_{n-1, 1-\\alpha/2}^2} \\right].\n",
    "$$\n",
    "\n",
    "Replacing the values $n = 10$, $s^2 = 78.044$, $\\alpha = 0.05$, and obtaining the values $\\chi_{9; 0.025}^2 = 19.023$ and $\\chi_{9; 0.975}^2 = 2.70$ from R (or from the chi squared table), we compute the following confidence interval for $\\sigma^2$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{CI}_{1-\\alpha} (\\sigma^2) & = & \\left[ \\displaystyle \\frac{9\\times 78.044}{19.023}, \\frac{9\\times 78.044}{2.70} \\right] \\\\\n",
    "& = & [36.924 \\, ; \\, 260.11]\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Taking the square roots of the end points for the preceding interval, we obtain the following interval for $\\sigma$:\n",
    "\n",
    "$$\n",
    "\\text{CI}_{1-\\alpha} (\\sigma) = [6.077 \\, ; \\, 16.128].\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9731b-de37-4663-9669-4dc05e356592",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Variance of normal data - Numerical example</span>\n",
    "\n",
    "We wish to determine a confidence interval for the population variance of the values in the sample, based on the first <span style=\"color:blue;font-family:monospace;font-size:90%;\">sz.smp</span> observations in our sample. We assume that the data we are considering satisfies the assumptions we have specified before, and in particular that the population follows a normal distribution. \n",
    "\n",
    "The following cell carries out the computations to obtain this confidence interval. We show the values required to obtain a confidence interval for the selected sample, as well as the confidence intervals for several confidence levels. Observe the assymmetry of the intervals in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c74fa-3596-4633-811d-65da7ca06e26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Confidence interval for the variance for normal data\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "smp.sz = 20\n",
    "\n",
    "## Parameters\n",
    "\n",
    "cf.lvl = c(0.9,0.925,0.95,0.975,0.99,0.999)\n",
    "sim.nq1 = qchisq(0.5-cf.lvl/2,smp.sz-1,lower.tail=T)\n",
    "sim.nq2 = qchisq(0.5+cf.lvl/2,smp.sz-1,lower.tail=T)\n",
    "\n",
    "## Compute relevant sample summaries\n",
    "\n",
    "ix.smp = sample(smp0.sz,smp.sz)\n",
    "\n",
    "data.smp = data.sel$Val[ix.smp]\n",
    "smp.sm = sum(data.smp)\n",
    "smp.sm2 = sum(data.smp^2)\n",
    "smp.mn = mean(data.smp)\n",
    "smp.var = var(data.smp)\n",
    "Sum.fr.4 = as.data.frame(round(matrix(c(smp.sz,smp.sm,smp.sm2,smp.mn,smp.sd),5,1),3))\n",
    "\n",
    "Data.hux.4 <-\n",
    "  hux(Sum.fr.4) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux.4) <- c(\"\",\"Sample size\",\"Sum of values\",\"Sum of squares\",\"Sample mean\",\"Sample quasi-std dev\")\n",
    "colnames(Data.hux.4) <- c(\"Values\")\n",
    "table_prnt(Data.hux.4[-1,],\"Sample summary\")\n",
    "\n",
    "lim.low = (smp.sz - 1)*smp.var/sim.nq2\n",
    "lim.high = (smp.sz - 1)*smp.var/sim.nq1\n",
    "val.5 = cbind(cf.lvl,lim.low,lim.high)\n",
    "Sum.fr.5 = as.data.frame(round(val.5,4))\n",
    "colnames(Sum.fr.5) <- c(\"CL\",\"Llim\",\"Hlim\")\n",
    "\n",
    "Data.hux.5 <-\n",
    "  hux(Sum.fr.5) %>%\n",
    "  set_bold(row = 1, value = T) %>%\n",
    "  set_all_borders(TRUE)\n",
    "\n",
    "rownames(Data.hux.5) <- c(\"\",\"CI 1\",\"CI 2\",\"CI 3\",\"CI 4\",\"CI 5\",\"CI 6\")\n",
    "colnames(Data.hux.5) <- c(\"Confidence level\",\"Lower limit\",\"Higher limit\")\n",
    "table_prnt(Data.hux.5[-1,],\"Confidence intervals\")\n",
    "\n",
    "## Plot the intervals\n",
    "\n",
    "Sum.fr.5$y = seq(1,3)\n",
    "sim.ci.plot <- Sum.fr.5 %>%\n",
    "  ggplot(aes(x=Llim,y=CL,xend=Hlim,yend=CL)) + geom_segment(color=\"blue\") +\n",
    "    geom_vline(xintercept=smp.var,color=\"brown\") +\n",
    "    theme_bw() +\n",
    "    ggtitle(\"Confidence intervals using the CLT\") +\n",
    "    xlab(\"Values\") + ylab(\"Intervals\") +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "plot(sim.ci.plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f130eea-2493-47b0-8c35-c57c1202a35e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">From the values indicated in the preceding cell:</span>\n",
    "- <span style=\"color:green\">Repeat the computations by hand based on the first $n$ observations in the data</span>\n",
    "- <span style=\"color:green\">Are these confidence intervals reasonable for the data we are considering?</span>\n",
    "- <span style=\"color:green\">Can you suggest an explanation for any discrepancies?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c718bf53-cfb2-4ec1-ac45-7430def05f48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### <span style=\"color:blue;\">Variance of normal data - Numerical example (ii)</span>\n",
    "\n",
    "In the following cell we compute different confidence intervals for the variance of the population, obtained from different samples randomly selected from our data and assuming that we have normal data. The intervals are plotted in different colors, depending on the interval containing the correct value (a blue interval) or not (a red interval).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c5aec-1e8c-4b77-8fab-854a41281733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Confidence intervals for the variance assuming normal data\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "n.samples = 50\n",
    "smp.sz = 20\n",
    "cf.lvl = 0.9\n",
    "\n",
    "## Parameters\n",
    "\n",
    "sim.nq.1 = qchisq(0.5-cf.lvl/2, df = smp.sz - 1, lower.tail=T)\n",
    "sim.nq.2 = qchisq(0.5+cf.lvl/2, df = smp.sz - 1, lower.tail=T)\n",
    "\n",
    "## Generate samples and estimates\n",
    "\n",
    "sim.ci = as.data.frame(matrix(0,n.samples,4))\n",
    "for (i in 1:n.samples) {\n",
    "    v.smp = sample(data.sel$Val,smp.sz,replace = FALSE)\n",
    "    var.smp = var(v.smp)\n",
    "    sim.ci[i,1] = (smp.sz - 1)*var.smp/sim.nq.2\n",
    "    sim.ci[i,2] = (smp.sz - 1)*var.smp/sim.nq.1\n",
    "    if ((sim.ci[i,1] <= smp0.var)&&(sim.ci[i,2] >= smp0.var)) sim.ci[i,3] = 1\n",
    "    sim.ci[i,4] = var.smp\n",
    "}\n",
    "    \n",
    "## Generate the resulting intervals\n",
    "\n",
    "names(sim.ci) = c(\"xs\",\"xe\",\"c\",\"center\")\n",
    "sim.ci$ys = seq(1,n.samples)\n",
    "aux.lbl = factor(c(0,1,sim.ci$c),labels=c(\"outside\",\"inside\"))\n",
    "sim.ci$cv = aux.lbl[-c(1,2)]\n",
    "  \n",
    "## Plot the intervals using a color code\n",
    "\n",
    "mn.x = 0.95*min(sim.ci$xs)\n",
    "mx.x = 1.05*max(sim.ci$xe)\n",
    "\n",
    "sim.t = sprintf(\"Confidence intervals for the variance. Level %5.2f\",cf.lvl)\n",
    "\n",
    "sim.ci.plot <- sim.ci %>%\n",
    "  ggplot(aes(x=xs,y=ys,xend=xe,yend=ys,color=cv)) + geom_segment() +\n",
    "    geom_vline(xintercept=smp0.var,color=\"brown\") +\n",
    "    xlim(mn.x,mx.x) +\n",
    "    annotate(geom=\"text\",label=\"Population variance\",x=smp0.var,y=n.samples,vjust=-1,color=\"brown\") +\n",
    "    scale_color_manual(values = c(\"outside\" = \"red\", \"inside\" = \"blue\")) +\n",
    "    theme_bw() +\n",
    "    ggtitle(sim.t) +\n",
    "    xlab(\"Values\") + ylab(\"Intervals\") +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "plot(sim.ci.plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10b9ce-b251-4f91-abc6-2010af3f71cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Based on this plot, answer the following questions:</span>\n",
    "- <span style=\"color:green\">If you repeat this procedure with different samples (by running again the preceding cell), does the proportion of \"correct\" intervals change in a noticeable manner?</span>\n",
    "- <span style=\"color:green\">Why would you think that the proportion of correct intervals observed may differ from the value indicated by the theory?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4243867-5f41-4813-b56a-652e4022eabf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## <span style=\"color:brown\">Confidence interval length and sample sizes</span>\n",
    "\n",
    "---\n",
    "\n",
    "In general, we would prefer to obtain shorter confidence intervals, which would imply a smaller error in our estimates. The length of a confidence interval in general will depend on:\n",
    "\n",
    "- The <span style=\"color:brown\">variability in our data:</span> the larger it is, the longer the confidence interval.\n",
    "- The <span style=\"color:brown\">confidence level:</span> the higher the confidence level, the longer the confidence interval.\n",
    "- The <span style=\"color:brown\">sample size:</span> the larger the sample size, the shorter the confidence interval.\n",
    "\n",
    "In the preceding comments we assume all other values remain the same.\n",
    "\n",
    "In practice, the only value we can change to obtain a meaningful reduction in the confidence interval length is the sample size, as the variability is a property of the data and decreases in the confidence level imply both a reduction of the length of the interval and a decrease in our confidence on getting the correct value in the interval. In the particular case of confidence intervals for the population mean, the length of the interval depends (mostly) on the square root of the sample size. We could use the formulas for these confidence intervals to obtain a sample size that would yield a desired interval length.\n",
    "\n",
    "For example, if $L$ denotes this desired interval (half) length, and we consider the case of a confidence interval for the population mean obtained using the CLT, the value of the sample size $n$ that would provide the desired interval length would be given by\n",
    "\n",
    "$$\n",
    "\\text{Interval length} = 2 z_{\\alpha/2} \\frac{s}{\\sqrt{n}} = 2L \\quad \\Rightarrow \\quad n = \\left( \\frac{z_{\\alpha/2} s}{L} \\right)^2\n",
    "$$\n",
    "\n",
    "It is important to note that this sample size will only be approximate, as the value of $s$ depends on the sample.\n",
    "\n",
    "The following cell presents two plots of the confidence interval lengths associated to different sample sizes, for the cases when we have normal data and we wish to approximate the population mean or the population variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86e382-c6e3-4489-adb4-43249401c34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confidence intervals for different sample sizes\n",
    "\n",
    "## These values can be modified\n",
    "\n",
    "smp.sz = seq(15,120,3)\n",
    "cf.lvl = c(0.9,0.95,0.99)\n",
    "\n",
    "## Interval sizes\n",
    "\n",
    "l.smp.sz = length(smp.sz)\n",
    "cil.mn = cil.var = cil.sz = cil.cl = NULL\n",
    "for (cf.v in cf.lvl) {\n",
    "    for (s.sz in smp.sz) {\n",
    "        q.t.1 = qt(0.5+cf.v/2, df = s.sz - 1, lower.tail=T)\n",
    "        q.chi.1 = qchisq(0.5-cf.v/2, df = s.sz - 1, lower.tail=T)\n",
    "        q.chi.2 = qchisq(0.5+cf.v/2, df = s.sz - 1, lower.tail=T)\n",
    "        data.smp = sample(data.sel$Val,s.sz,replace = FALSE)\n",
    "        s.smp = sd(data.smp)\n",
    "        cil.mn = c(cil.mn,2*q.t.1*s.smp/sqrt(s.sz))\n",
    "        cil.var = c(cil.var,(s.sz-1)*s.smp^2*(1/q.chi.1 - 1/q.chi.2))\n",
    "    }\n",
    "    cil.sz = c(cil.sz,smp.sz)\n",
    "    cil.cl = c(cil.cl,rep(cf.v,l.smp.sz))\n",
    "}\n",
    "cil.df = data.frame(valm = cil.mn, vals = cil.var, size = cil.sz, conflvl = as.factor(cil.cl))\n",
    "\n",
    "## Generate plots\n",
    "\n",
    "cil.plot.m <- cil.df %>%\n",
    "  ggplot(aes(x = size, y = valm, group = conflvl)) +\n",
    "  geom_line(aes(linetype = conflvl, color = conflvl)) +\n",
    "    theme_bw() +\n",
    "    ggtitle(\"Confidence interval lengths for the mean (normal data)\") +\n",
    "    ylab(\"Length\") + xlab(\"Sample size\") +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "cil.plot.s <- cil.df %>%\n",
    "  ggplot(aes(x = size, y = vals, group = conflvl)) +\n",
    "  geom_line(aes(linetype = conflvl, color = conflvl)) +\n",
    "    theme_bw() +\n",
    "    ggtitle(\"Confidence interval lengths for the variance (normal data)\") +\n",
    "    ylab(\"Length\") + xlab(\"Sample size\") +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5))\n",
    "\n",
    "suppressWarnings(grid.arrange(cil.plot.m,cil.plot.s,nrow = 2,\n",
    "                              top=textGrob(\"Lengths of confidence intervals\",gp=gpar(fontsize=15,col=\"blue\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e4666-fabc-41fe-8e9f-223de7eeb03e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### <span style=\"color:green;\">Questions</span>\n",
    "\n",
    "<span style=\"color:green\">Comment on these statements regarding the length of confidence intervals and its relationship to sample sizes:</span>\n",
    "- <span style=\"color:green\">Are the preceding formulas for sample sizes applicable to all the cases considered in the lesson? For example, what would be the formula for the sample size required to attain a certain confidence interval length in the case of intervals for population proportions?</span>\n",
    "- <span style=\"color:green\">Given a desired interval length, how could you compute a value for $n$ in the case of normal data and an interval for the population mean? And for the population variance?</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d12e9-dc85-4e55-b4c0-678dbdbb84cc",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\">Exercise</span>\n",
    "\n",
    "*In 2019 the Internal Revenue Service (IRS) looked at a random sample of 2000 companies and their balance sheets and found that 58 of them had some sort of miscalculation error.*\n",
    "\n",
    "*Assuming that the value of the sample proportion would not change significantly when the sample size is increased, determine the smallest sample size ensuring that the half-length of the confidence interval for the population proportion, at a significance level of 99%, would be smaller than $0.005$.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438241e-5b46-403f-b005-9708e5445fe6",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### <span style=\"color:red\">Exercise. Solution</span>\n",
    "\n",
    "Our population will be the companies that reported to the IRS in 2019, and we define a Bernoulli random variable $X$ taking the value 1 if a company made a miscalculation error in their report, and 0 otherwise. Our statistic to obtain a confidence interval for the population proportion will be\n",
    "\n",
    "$$\n",
    "T = \\frac{\\hat P - p}{\\sqrt{\\hat P(1 - \\hat P)/n}} \\sim_{\\scriptsize\\text{approx.}} N(0,1)\n",
    "$$\n",
    "\n",
    "where $\\hat P$ denotes the sample proportion.\n",
    "\n",
    "For this statistic, the confidence interval corresponding to a confidence level $1 - \\alpha$ is given by\n",
    "\n",
    "$$\n",
    "\\text{CI}_{1-\\alpha} (p) = \\left[ \\hat p - z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1-\\hat p)}{n}} \\; ; \\; \\hat p + z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1-\\hat p)}{n}} \\right]\n",
    "$$\n",
    "\n",
    "For our sample we have $\\hat p = 58/2000 = 0.026$ and $n = 2000$. Also, from the normal tables (or from R) we have that $z_{\\alpha/2} = z_{0.005} = 2.576$. Replacing these values we obtain the interval\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{CI}_{0.99} (p) & = & \\displaystyle \\left[ 0.026 - 2.576 \\sqrt{\\frac{0.026\\times 0.974}{2000}} \\; ; \\; 0.026 + 2.576 \\sqrt{\\frac{0.026\\times 0.974}{2000}} \\right] \\\\\n",
    "& = & \\left[ 0.0168 \\; ; \\; 0.0352 \\right]\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "In general, the half-length of this interval is the difference between its upper limit and its center,\n",
    "\n",
    "$$\n",
    "\\text{half-length} = \\hat p + z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1-\\hat p)}{n}} - \\hat p = z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1-\\hat p)}{n}}\n",
    "$$\n",
    "\n",
    "and for our particular sample this half-length takes the value $0.0352 - 0.026 = 0.0092$. As this value is larger than the requested size ($0.0092 > 0.005$), we must increase the sample size to a new value $n'$. \n",
    "\n",
    "Using a prime symbol to denote the values corresponding to the new sample, imposing the condition that the new half-length (as a function of $n'$) is equal to the desired value, and assuming that $\\hat p' \\approx \\hat p$, we obtain\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "& & \\text{half-length} = \\displaystyle z_{\\alpha/2} \\sqrt{\\frac{\\hat p'(1-\\hat p')}{n'}} \\approx \\displaystyle z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1-\\hat p)}{n'}} = 0.005 \\\\\n",
    "& \\Rightarrow & n' = \\displaystyle \\left( z_{\\alpha/2} \\frac{\\sqrt{\\hat p(1-\\hat p)}}{0.005} \\right)^2 = \\left( 2.576 \\frac{\\sqrt{0.026\\times 0.974}}{0.005} \\right)^2 = 6721.78\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "implying that for a sample size approximately equal to 6720 we should get a half-length of our confidence interval very close to $0.005$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7c07b-1f89-4af7-b7fe-937aa514bd82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## <span style=\"color:brown\">Estimators and confidence intervals. Summary</span>\n",
    "\n",
    "---\n",
    "\n",
    "- The confidence intervals we have introduced in the preceding paragraphs can be summarized as:\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\\begin{array}{llccc}\n",
    "\\text{Parameter} & \\text{Estimator} & \\text{Statistic} & \\text{Distribution} & \\text{Confidence interval} \\\\[3pt]\n",
    "\\hline\n",
    "\\text{Mean } \\mu & \\text{Sample mean } \\bar X & \\frac{\\bar X - \\mu}{S/\\sqrt{n}} & N(0,1) & \\left[ \\bar x - z_{\\alpha/2} \\frac{s}{\\sqrt{n}} \\; ; \\; \\bar x + z_{\\alpha/2} \\frac{s}{\\sqrt{n}} \\right] \\\\\n",
    "& & \\frac{\\bar X - \\mu}{S/\\sqrt{n}} & t_{n-1} & \\left[ \\bar x - t_{n-1;\\alpha/2} \\frac{s}{\\sqrt{n}} \\; ; \\; \\bar x + t_{n-1;\\alpha/2} \\frac{s}{\\sqrt{n}} \\right] \\\\[3pt]\n",
    "\\hline\n",
    "\\text{Proportion } p & \\text{Sample proportion } \\hat P & \\frac{\\hat P - p}{\\sqrt{\\hat P(1 - \\hat P)/n}} & N(0,1) & \\left[ \\hat p - z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1 - \\hat p)}{n}} \\; ; \\; \\hat p + z_{\\alpha/2} \\sqrt{\\frac{\\hat p(1 - \\hat p)}{n}} \\right] \\\\[3pt]\n",
    "\\hline\n",
    "\\text{Variance } \\sigma^2 & \\text{Sample quasivariance } S^2 & \\frac{(n-1)S^2}{\\sigma^2} & \\chi^2_{n-1} & \\left[ \\frac{(n-1)s^2}{\\chi^2_{n-1;\\alpha/2}} \\; ; \\; \\frac{(n-1)s^2}{\\chi^2_{n-1;1-\\alpha/2}} \\right] \\\\[3pt]\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- The assumptions we require to hold in order to use the preceding formulas are:\n",
    "\n",
    "| Parameter | Assumptions |\n",
    "| --- | --- |\n",
    "| Mean | Large sample size |\n",
    "|   | Normal data |\n",
    "| Proportion | Large sample size |\n",
    "| Variance | Normal data |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9692fef3-c661-475f-a87d-66e5b89e870c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## <span style=\"color:orange\">Appendix 1: Distributions associated to the normal</span>\n",
    "\n",
    "---\n",
    "\n",
    "In the preceding results, and in particular in those based on the assumption of normal data, we have used statistics that follow distributions different from, although related to, the normal distribution. In the following paragraphs we provide some descriptive information about these distributions.\n",
    "\n",
    "<a id='App1_1_Csq'></a>\n",
    "\n",
    "### <span style=\"color:orange\">The chi squared distribution</span>\n",
    "\n",
    "The variance and quasivariance of a sample are defined as a sum (an average) of squares of the differences between the values of the observations and the sample mean. When the data follow a normal distribution, each of these differences is also normal, and it can be shown that (a certain number of) these variables are independent. We define the chi squared distribution as the distribution of the sum of the squares of $n$ independent standard normal random variables. Assume that $X_1,\\ldots,X_n$ are independent standard normal random variables, then we define\n",
    "\n",
    "$$\n",
    "   Y \\equiv X_1^2 + \\cdots + X_n^2 ,\n",
    "$$\n",
    "\n",
    "and we say that $Y$, the sum of the squares of the $X_i$ variables, follows a chi squared distribution with $n$ degrees of freedom, $Y \\sim \\chi^2_n$. This distribution is useful for example when studying the variance of a sample of normal random variables.\n",
    "\n",
    "As this distribution is defined from a sum of squares, it takes values in $[0,\\infty)$. Also, it is not symmetric around its mean and, due to this asymmetry, its median is smaller than its mean.\n",
    "\n",
    "<a id='App1_1_Std'></a>\n",
    "\n",
    "### <span style=\"color:orange\">The Student t distribution</span>\n",
    "\n",
    "The estimator for the mean of a normal population, based on the sample mean, is defined as the ratio of two random variables, the sample mean and the sample quasi-standard deviation. This ratio is commonly found when working with normal random variables, as it is associated with the standardization of a normal random variable. A specific distribution has been introduced to represent this ratio of random variables. If we have $Y$ defined as before, following a chi squared distribution with $n$ degrees of freedom, and $X$ is a standard normal random variable independent of the variables $X_1,\\ldots,X_n$ used in the definition of $Y$, then we define\n",
    "\n",
    "$$\n",
    "   W \\equiv \\frac{X}{\\sqrt{Y/n}} ,\n",
    "$$\n",
    "\n",
    "and we say that $W$, given by the ratio of these two variables, follows a Student t distribution with $n$ degrees of freedom, $W \\sim t_n$. This distribution is particularly useful when working with the mean of a sample of normal random variables with unknown population variance, which we approximate using the sample quasivariance, for example.\n",
    "\n",
    "It corresponds to a normal random variable scaled using a positive random value, so it takes values in $[-\\infty,\\infty)$. It is symmetric around its mean, equal to the mean of $X$, which is 0. Its appearance is very similar to that of a standard normal distribution, but with heavier tails. When $n \\rightarrow \\infty$, a Student t distribution converges to a standard normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03118bf3-2880-444b-b251-2312e9682982",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### <span style=\"color:orange\">Summary of statistics for these distributions</span>\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\\begin{array}{lcccccc}\n",
    "\\text{Distribution} & \\text{Deg freedom} & \\text{Domain} & \\text{Mean} & \\text{Median} & \\text{Variance} & \\text{Asymmetry} \\\\\n",
    "\\hline\n",
    "\\text{Student t} & n & (-\\infty , \\infty) & 0 & 0 & \\frac{n}{n-2}, \\text{ for } n > 2 & 0, \\text{ for } n > 3 \\\\\n",
    "\\text{Chi squared} & n & [0 , \\infty) & n & \\approx n\\left( 1 - \\frac{2}{9n} \\right)^3 & 2n & \\sqrt{\\frac{8}{n}}\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c80f4-be1a-45cf-9e7d-5685a34fba17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <span style=\"color:orange;\">Graphical representation of their density functions</span>\n",
    "\n",
    "The following cell shows some plots with the densities for these two distributions, for different values of their degrees of freedom. You can select these numbers of degrees of freedom used in the plots by modifying the values of the variable <span style=\"color:blue;font-family:monospace;font-size:90%;\">deg.fr</span>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c6a42-f8f0-40cf-9e13-b3245cb522c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Graphical representations of the Student t and chi squared densities\n",
    "\n",
    "## These values can be modified\n",
    "## Numbers of degrees of freedom for the densities to be plotted (include between 1 and 6 values)\n",
    "\n",
    "deg.fr = c(3,8,15)\n",
    "\n",
    "## Plot the densities\n",
    "\n",
    "mx.df = 6\n",
    "l.df = length(deg.fr)\n",
    "if (l.df > mx.df) {\n",
    "    deg.fr = deg.fr[1:mx.df]\n",
    "    l.df = mx.df\n",
    "}\n",
    "\n",
    "col.v.gen = c(\"#619CFF\", \"#00BFC4\", \"#00BF7D\", \"#33CCCC\", \"#33FFCC\", \"#99CCFF\")\n",
    "col.v = col.v.gen[1:l.df]\n",
    "\n",
    "xlm.u = 2.5\n",
    "xlm.l = -xlm.u\n",
    "\n",
    "plot.f1 <- data.frame(x = c(xlm.l, xlm.u), c.fn = factor(1))\n",
    "\n",
    "plt.t = ggplot(NULL, aes(x = x, color = c.fn)) + stat_function(data = plot.f1, fun = dt, args=list(df=deg.fr[1])) +\n",
    "    stat_function(data = plot.f1, fun = dnorm, color=\"red\") +\n",
    "    annotate(geom=\"text\",label=c(\"Normal density\"),color=\"red\",\n",
    "             x=c(xlm.l + 0.8),y=c(0.02),vjust = -1) +\n",
    "    ggtitle(\"Density of a Student t distribution\") +\n",
    "    xlab(\"Value\") + ylab(\"Density\") +\n",
    "    scale_colour_manual(\"df\", values = col.v, labels = deg.fr) +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "    labs(fill = \"df\")\n",
    "\n",
    "if (l.df > 1) {\n",
    "    for (i in 2:l.df) {\n",
    "        plot.fi <- data.frame(x = c(xlm.l, xlm.u), c.fn = factor(i))\n",
    "        plt.t = plt.t + stat_function(data = plot.fi, fun = dt, args=list(df=deg.fr[i]))\n",
    "    }\n",
    "}\n",
    "\n",
    "xlm.l = 0\n",
    "xlm.u = 0.9*max(10,max(deg.fr))\n",
    "\n",
    "plot.f1 <- data.frame(x = c(xlm.l, xlm.u), c.fn = factor(1))\n",
    "\n",
    "plt.c = ggplot(NULL, aes(x = x, color = c.fn)) + stat_function(data = plot.f1, fun = dchisq, args=list(df=deg.fr[1])) +\n",
    "    stat_function(data = plot.f1, fun = dchisq, args=list(df=10), color=\"red\") +\n",
    "    annotate(geom=\"text\",label=c(\"ChiSq 10 df\"),color=\"red\",\n",
    "             x=c(xlm.l + 1),y=c(0.01),vjust = -1) +\n",
    "    ggtitle(\"Density of a Chi squared distribution\") +\n",
    "    xlab(\"Value\") + ylab(\"Density\") +\n",
    "    scale_colour_manual(\"df\", values = col.v, labels = deg.fr, ) +\n",
    "    theme(plot.title = element_text(color=\"blue\", size=14, face=\"bold.italic\", hjust=0.5)) +\n",
    "    labs(fill = \"df\")\n",
    "\n",
    "if (l.df > 1) {\n",
    "    for (i in 2:l.df) {\n",
    "        plot.fi <- data.frame(x = c(xlm.l, xlm.u), c.fn = factor(i))\n",
    "        plt.c = plt.c + stat_function(data = plot.fi, fun = dchisq, args=list(df=deg.fr[i]))\n",
    "    }\n",
    "}\n",
    "\n",
    "suppressWarnings(grid.arrange(plt.t,plt.c,nrow = 2,\n",
    "                              top=textGrob(\"Densities of normal related distributions\",gp=gpar(fontsize=15,col=\"blue\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80086d3-20ea-4bc6-be22-a9f4efa50ddb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<a id='App1_2'></a>\n",
    "\n",
    "## <span style=\"color:orange;\">Appendix 2: Justification of test statistics distributions</span>\n",
    "\n",
    "---\n",
    "\n",
    "In this appendix we present results to justify some of the distributions we have introduced in this lesson, for the case of <span style=\"color:brown\">normal populations.</span> In what follows we will assume that $X_i \\sim N(\\mu , \\sigma^2)$ and all the $X_i$ are independent.\n",
    "\n",
    "### <span style=\"color:orange;\">Distribution of the statistic for the population variance</span>\n",
    "\n",
    "<span style=\"color:brown\">The following derivation makes use of results from matrix algebra and multivariate statistics.</span>\n",
    "  \n",
    "We wish to study the distribution of the statistic\n",
    "\n",
    "$$\n",
    "T_{\\sigma^2} = \\frac{(n-1) S^2}{\\sigma^2}\n",
    "$$\n",
    "  \n",
    "Using matrix notation, we can write the sample quasivariance $S^2$ as\n",
    "\n",
    "$$\n",
    "S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar X) = \\frac{1}{n-1} Y^T Y , \\qquad Y \\equiv (I - \\frac{1}{n} e e^T ) X \\equiv M X\n",
    "$$\n",
    "\n",
    "where $X$ denotes the vector with components $(X_i)$, and $e$ denotes the vector with all components equal to 1.\n",
    "  \n",
    "The covariance of $Y$ is given by\n",
    "\n",
    "$$\n",
    "\\text{Var}(Y) = \\text{Var}(M X) = M \\text{Var}(X) M^T = \\left( I - \\frac{1}{n} e e^T \\right) \\sigma^2 I \\left( I - \\frac{1}{n} e e^T \\right)^T = \\sigma^2 \\left( I - \\frac{1}{n} e e^T \\right)\n",
    "$$\n",
    "\n",
    "But note that the variables $Y$ are not independent, as the elements outside the diagonal of their covariance matrix (the covariances between pairs of variables) are not equal to zero. Note that for pairs of normal random variables a necessary and sufficient condition for them to be independent is that they are uncorrelated.\n",
    "  \n",
    "Define an orthogonal matrix $Q \\in \\mathbb{R}^{n\\times (n-1)}$ with columns corresponding to an orthonormal basis for the subspace of dimension $n-1$ orthogonal to $e$ (such that $Q^T e = 0$). Also, let $\\hat Q = \\left( \\begin{array}{cc} Q & e/\\sqrt{n} \\end{array} \\right)$.\n",
    "  \n",
    "Define a new set of $n-1$ variables $W_i$ as the components of $W \\equiv Q^T Y \\in \\mathbb{R}^{n-1}$; these variables are linear combinations of the normal random variables $Y_i$, and as a consequence they follow a normal distribution. we have $\\text{Var} (W) = \\text{Var} (Q^T Y) = Q^T \\text{Var} (Y) Q = \\sigma^2 I$. Also, as $E[Y_i] = \\mu - \\mu = 0$, $W_i \\sim N(0,\\sigma^2)$. Finally, these variables $W_i$ are independent of each other, as their covariance matrix is diagonal.\n",
    "  \n",
    "It holds that\n",
    "\n",
    "$$\n",
    "e^T Y = \\sum_i Y_i = \\sum_i X_i - n \\bar X = 0\n",
    "$$\n",
    "\n",
    "and as $\\hat Q \\hat Q^T = I$, we have that\n",
    "\n",
    "$$\n",
    "Y^T Y = Y^T \\hat Q \\hat Q^T Y = Y^T Q Q^T Y + Y^T \\frac{1}{\\sqrt{n}} e \\frac{1}{\\sqrt{n}} e^T Y = Y^T Q Q^T Y = W^T W \n",
    "$$\n",
    "\n",
    "Thus, as our statistic is given by a sum of squares of $n-1$ independent standard normal random variables,\n",
    "\n",
    "$$\n",
    "S^2 = \\frac{1}{n-1} W^T W = \\frac{1}{n-1} \\sum_{i=1}^{n-1} W_i^2 , \\quad \\Rightarrow \\quad T_{\\sigma^2} = \\frac{(n-1) S^2}{\\sigma^2} = \\sum_{i=1}^{n-1} \\frac{W_i^2}{\\sigma^2} \\sim \\chi^2_{n-1}\n",
    "$$\n",
    "\n",
    "### <span style=\"color:orange;\">Distribution of the statistic for the population mean</span>\n",
    "\n",
    "We wish to justify the distribution for the statistic we use to conduct inference on the population mean,\n",
    "\n",
    "$$\n",
    "T_{\\mu} = \\frac{\\bar X - \\mu}{S/\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "We have that $\\bar X \\sim N(\\mu , \\sigma^2/n )$, and we can write\n",
    "\n",
    "$$\n",
    "T_{\\mu} = \\frac{\\displaystyle \\frac{\\bar X - \\mu}{\\sigma/\\sqrt{n}}}{\\displaystyle \\sqrt{\\frac{(n-1)S^2/\\sigma^2}{n-1}}}\n",
    "$$\n",
    "\n",
    "which is a ratio of a standard normal random variable and the square root of a chi squared distribution with $n-1$ degrees of freedom, implying that\n",
    "\n",
    "$$\n",
    "T_{\\mu} \\sim t_{n-1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf3b3c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  },
  "rise": {
   "font-size": "0.5em",
   "theme": "sky"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
